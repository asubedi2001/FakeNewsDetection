{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOAmkFIK8CablGT+5NK74Vs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asubedi2001/FakeNewsDetection/blob/BiLSTM/BiLSTMwithHyperparameters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"GRUwithRelabling(11).ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1vBZZ-V5_C9Cu1wS4yWpAGUceU8s033H1\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import nltk\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "import torch.optim as optim\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import random\n",
        "import pprint\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "random.seed(184)\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt')\n",
        "\n",
        "\"\"\"## Read in data\"\"\"\n",
        "\n",
        "peek = 20\n",
        "def present_list_like(name, list_like, peek=peek):\n",
        "    print(f\"{name} peek:\")\n",
        "    print('  ' + '\\n  '.join( str(v) for v in list_like[:peek]))\n",
        "\n",
        "columns = [\n",
        "    'id', 'label', 'claim', 'subject', 'speaker', 'speaker_job_title', 'state_info',\n",
        "    'party_affiliation', 'barely_true_counts', 'false_counts',\n",
        "    'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context'\n",
        "]\n",
        "present_list_like(f\"Dataset columns({len(columns)} in total)\", columns, len(columns))\n",
        "def load_data(split):\n",
        "    df = pd.read_csv(f\"./data/{split}.tsv\", sep='\\t', names=columns)\n",
        "    df = df.drop(index=[\n",
        "        idx for idx in df.index if type(df[\"claim\"][idx]) == type(None) or not len(df[\"claim\"][idx])\n",
        "    ])\n",
        "    print(\"The training dataset:\")\n",
        "    df.info()\n",
        "    print(\"\\nData peek:\")\n",
        "    print(df.head(peek))\n",
        "    print()\n",
        "    return df\n",
        "\n",
        "\"\"\"##Tokenize the data\"\"\"\n",
        "\n",
        "pad_tkn = \"<PAD>\"\n",
        "\n",
        "def tokenize_text(input_text, known_vector_size=None, token_to_idx={}):\n",
        "    def preprocess_text(text)->str:\n",
        "        #Letter-level cleaning\n",
        "        text = text.lower()\n",
        "        valid_asciis = {9, *range(32, 127)}\n",
        "        text = ''.join(filter(lambda x: ord(x) in valid_asciis, text))\n",
        "\n",
        "        #Word/sequence-level cleaning\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = re.sub(r'http\\S+', '', text)\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        text = ' '.join(word for word in text.split() if word not in stop_words)\n",
        "        return text\n",
        "\n",
        "    #Preprocess the text\n",
        "    for i in range(len(input_text)):\n",
        "        input_text[i] = preprocess_text(input_text[i])\n",
        "\n",
        "    #Tokenize\n",
        "    final_tokens = input_tokens = [nltk.word_tokenize(text) for text in input_text]\n",
        "    total_tokens = sum(len(tkns) for tkns in final_tokens)\n",
        "\n",
        "    # Make all token sets the same length\n",
        "    forced_tkn_set_size = (\n",
        "        known_vector_size if known_vector_size\n",
        "        else int(np.percentile([len(tkns) for tkns in final_tokens], 80))\n",
        "    )\n",
        "    final_tokens = [\n",
        "        tkns[:forced_tkn_set_size] + [pad_tkn]*(forced_tkn_set_size - len(tkns))\n",
        "        for tkns in final_tokens\n",
        "    ]\n",
        "\n",
        "    # Present results\n",
        "    present_list_like(f\"Tokenized sentences({len(final_tokens)} sentences, {total_tokens} total tokens)\", final_tokens)\n",
        "\n",
        "    #Index the tokens\n",
        "    # Map each token to its frequency in the dataset\n",
        "    if not len(token_to_idx):\n",
        "        flat_tokens = [word for token_set in final_tokens for word in token_set]\n",
        "        frequencies = Counter(flat_tokens)\n",
        "        token_to_idx = {}\n",
        "        for idx, (word, _) in enumerate(frequencies.most_common()):\n",
        "            if idx >= 10000:\n",
        "                break\n",
        "            token_to_idx[word] = idx + 1\n",
        "        if pad_tkn not in token_to_idx:\n",
        "            token_to_idx[pad_tkn] = len(token_to_idx) + 1\n",
        "    vocab_size = len(token_to_idx)\n",
        "    print()\n",
        "    print(vocab_size, \"unique tokens\")\n",
        "    present_list_like(\"Unique tokens\", list(token_to_idx.keys()))\n",
        "\n",
        "    # Index the tokens\n",
        "    freq_indexed = [\n",
        "        [(token_to_idx[token] if token in token_to_idx else 0) for token in token_set]\n",
        "        for token_set in final_tokens\n",
        "    ]\n",
        "\n",
        "    # Present results\n",
        "    present_list_like(f\"\\nFinal Index Sets(Set_Size = {forced_tkn_set_size}, {len(freq_indexed)} index sets)\", freq_indexed)\n",
        "\n",
        "    return freq_indexed, token_to_idx\n",
        "\n",
        "def get_freq_indexed_and_labels(split, known_vector_size=None, token_to_idx={}):\n",
        "    df = load_data(split)\n",
        "    input_text = df[\"claim\"].to_numpy()\n",
        "    #Augment input text with the other columns\n",
        "    other_cols = {\n",
        "        \"context\",\n",
        "        \"subject\",\n",
        "        \"speaker\",\n",
        "        \"speaker_job_title\",\n",
        "        \"state_info\",\n",
        "        \"party_affiliation\",\n",
        "    }\n",
        "    for i in range(len(input_text)):\n",
        "        extra_data = [f\"{col}: {df[col].values[i]}\" for col in other_cols if df[col].values[i]]\n",
        "        input_text[i] += \" | \\n\"*(len(extra_data) > 0) + \" | \\n\".join(extra_data)\n",
        "    input_labels = df[\"label\"].to_numpy()\n",
        "    code_switch = \"\"\"\"\"\"\n",
        "    #Fuse some labels\n",
        "    input_labels = np.array([\n",
        "        \"false\" if x in (\"false\", \"half-true\", \"barely-true\", \"pants-fire\")\n",
        "        else \"true\" if x in (\"true\", \"mostly-true\")\n",
        "        else x\n",
        "        for x in input_labels\n",
        "    ])\n",
        "    #\"\"\"\n",
        "    freq_indexed, token_to_idx = tokenize_text(input_text, known_vector_size, token_to_idx)\n",
        "\n",
        "    return freq_indexed, token_to_idx, input_labels\n",
        "\n",
        "\"\"\"##Turn the data into tensors\"\"\"\n",
        "\n",
        "def as_tensors(split, label_encoder=None, known_vector_size=None, token_to_idx={}):\n",
        "    freq_indexed, token_to_idx, input_labels = get_freq_indexed_and_labels(split, known_vector_size, token_to_idx)\n",
        "    X = torch.tensor(freq_indexed, dtype=torch.long)\n",
        "    label_encoder_existed = (type(label_encoder) != type(None))\n",
        "    label_encoder = (LabelEncoder() if not label_encoder_existed else label_encoder)\n",
        "    y = (\n",
        "        label_encoder.fit_transform(input_labels) if not label_encoder_existed\n",
        "        else label_encoder.transform(input_labels)\n",
        "    )\n",
        "    y = torch.tensor(y, dtype=torch.long)\n",
        "    print(f\"{split.upper()} SPLIT:\", X.size(0), \"overall samples:\", X.shape)\n",
        "\n",
        "    return X, token_to_idx, label_encoder, input_labels, y\n",
        "\n",
        "\"\"\"##Training\"\"\"\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "X_train, token_to_idx, label_encoder, train_input_labels, y_train = as_tensors(\"train\")\n",
        "label_to_idx = {l: i for i, l in enumerate(label_encoder.classes_)}\n",
        "train_vocab_size = len(token_to_idx)\n",
        "input_vector_size = X_train.shape[1]\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "train_label_counts = pd.DataFrame({\"label\": train_input_labels})[\"label\"].value_counts(normalize=True)\n",
        "print(train_label_counts.shape[0], \"labels\\n\")\n",
        "print(train_label_counts)\n",
        "\n",
        "code_switch = \"\\\"\"\"\"\"\n",
        "#Balance if necessary\n",
        "print(f\"TRAIN SPLIT(pre-balancing):\", X_train.size(0), \"overall samples:\", X_train.shape)\n",
        "X_train, y_train = SMOTE(random_state=42).fit_resample(X_train, y_train)\n",
        "X_train = torch.tensor(X_train, dtype=torch.long)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "print()\n",
        "print(f\"TRAIN SPLIT(post-balancing):\", X_train.size(0), \"overall samples:\", X_train.shape)\n",
        "print(pd.DataFrame({\"label\": [label_encoder.classes_[y] for y in y_train]})[\"label\"].value_counts())\n",
        "#\"\"\"\n",
        "\n",
        "def train_model(model, dataloader, optimizer, criterion, device, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        epoch_tps = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(inputs)\n",
        "            loss = criterion(predictions, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item() #Track total loss\n",
        "            #Track total accuracy\n",
        "            _, predicted_classes = torch.max(predictions, 1)\n",
        "            epoch_tps += (predicted_classes == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {epoch_loss/len(dataloader):.4f} | Accuracy: {epoch_tps/total_samples:.4f}\")\n",
        "\n",
        "\"\"\"### The BiLSTM model\"\"\"\n",
        "\n",
        "#Define the model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BiLSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        super(BiLSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=token_to_idx[pad_tkn])\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, batch_first=True, dropout=dropout, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # Multiply by 2 for bidirectional\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, (hidden, cell) = self.lstm(embedded)\n",
        "        # Concatenate the final forward and backward hidden states\n",
        "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
        "        return self.fc(hidden)\n",
        "\n",
        "#Setup to train\n",
        "\n",
        "# Model and training structure\n",
        "INPUT_DIM = train_vocab_size + 1\n",
        "EMBEDDING_DIM = 1000 #Current best: 1000\n",
        "HIDDEN_DIM = 128\n",
        "OUTPUT_DIM = train_label_counts.shape[0]\n",
        "N_LAYERS = 2\n",
        "DROPOUT = 0.3 #Current best: .3\n",
        "EPOCHS = 8 #Current best: 8\n",
        "\n",
        "# Make the model\n",
        "bilstm_model = BiLSTMModel(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, DROPOUT)\n",
        "print(\"Model:\", bilstm_model)\n",
        "\n",
        "# Move model to GPU if possible\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# Check if CUDA (GPU support) is available\n",
        "if torch.cuda.is_available():\n",
        "    # Get the number of available GPUs\n",
        "    num_gpus = torch.cuda.device_count()\n",
        "    print(f\"Number of available GPUs: {num_gpus}\")\n",
        "\n",
        "    # Get the name of each GPU\n",
        "    for i in range(num_gpus):\n",
        "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "\n",
        "    # Verify if a T4 GPU is available\n",
        "    t4_available = any(\"t4\" in torch.cuda.get_device_name(i).lower() for i in range(num_gpus))\n",
        "    print(f\"Is a T4 GPU available? {t4_available}\")\n",
        "\n",
        "    # Set the device to the first available GPU (if any)\n",
        "    device = torch.device('cuda:0')\n",
        "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"No GPU available, using CPU.\")\n",
        "    device = torch.device('cpu')\n",
        "bilstm_model = bilstm_model.to(device)\n",
        "\n",
        "# Optimization & loss setup\n",
        "optimizer = torch.optim.AdamW(bilstm_model.parameters(), lr=0.001)\n",
        "code_switch1 = \"\"\"\"\"\"\n",
        "class_weights = [1 for _ in range(OUTPUT_DIM)]\n",
        "class_weights[label_to_idx['true']] = 1\n",
        "class_weights[label_to_idx['false']] = 2\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.float32).to(device))\n",
        "code_switch2 = \"\"\"\n",
        "criterion = nn.CrossEntropyLoss() #Current best: no weights\n",
        "#\"\"\"\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "#Train the model\n",
        "train_model(bilstm_model, train_loader, optimizer, criterion, device, EPOCHS)\n",
        "\n",
        "\"\"\"## Save Model Weights\"\"\"\n",
        "\n",
        "#Save the model weights\n",
        "torch.save(bilstm_model.state_dict(), \"bilstm_model_weights.pth\")\n",
        "print(\"Model weights saved to 'bilstm_model_weights.pth'\")\n",
        "\n",
        "\"\"\"## Evaluate Model\"\"\"\n",
        "\n",
        "#Evaluation functions\n",
        "import typing as tp\n",
        "\n",
        "# Get predictions\n",
        "def get_predictions(\n",
        "    test_loader, model, num_samples,\n",
        "    pred_type: tp.Literal['model', 'baseline', 'random'] = 'model',\n",
        "    device=None,\n",
        "    label_ordering=None, orig_label_counts=None,\n",
        "    num_classes=None\n",
        "):\n",
        "    predictions = []\n",
        "    y_eval = []\n",
        "\n",
        "    if pred_type == 'model':\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in test_loader:\n",
        "                y_eval.extend(batch_y)\n",
        "\n",
        "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "                batch_size = batch_X.size(0)\n",
        "\n",
        "                outputs = model(batch_X)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                predictions.extend(predicted.cpu())\n",
        "        y_eval = torch.tensor(y_eval, dtype=torch.long)\n",
        "    elif pred_type == 'baseline':\n",
        "        orig_label_counts = orig_label_counts.sort_index(key=lambda idx: orig_label_counts[idx], inplace=False, ascending=False)\n",
        "        majority_class = list(label_ordering).index(orig_label_counts.index[0])\n",
        "        predictions += [majority_class for _ in range(num_samples)]\n",
        "    else:\n",
        "        predictions += [random.randint(0, num_classes - 1) for _ in range(num_samples)]\n",
        "\n",
        "    predictions = torch.tensor(predictions, dtype=torch.long)\n",
        "    if pred_type == 'model':\n",
        "        return predictions, y_eval\n",
        "    return predictions\n",
        "\n",
        "# Calculate per-class metrics\n",
        "def per_class_metrics(labels, predictions, num_classes, label_ordering):\n",
        "    # Ensure labels and predictions are on CPU\n",
        "    labels = labels.cpu().numpy()\n",
        "    predictions = predictions.cpu().numpy()\n",
        "\n",
        "    precision_per_class = precision_score(labels, predictions, average=None, labels=np.arange(num_classes), zero_division=0)\n",
        "    recall_per_class = recall_score(labels, predictions, average=None, labels=np.arange(num_classes), zero_division=0)\n",
        "    f1_per_class = f1_score(labels, predictions, average=None, labels=np.arange(num_classes), zero_division=0)\n",
        "\n",
        "    results = []\n",
        "    for metrics in [precision_per_class, recall_per_class, f1_per_class]:\n",
        "        results.append({label_ordering[i]: metrics[i] for i in range(len(metrics))})\n",
        "    return tuple(results)\n",
        "\n",
        "# Calculate Macro metrics\n",
        "def macro_metrics(labels, predictions):\n",
        "    # Ensure labels and predictions are on CPU\n",
        "    labels = labels.cpu().numpy()\n",
        "    predictions = predictions.cpu().numpy()\n",
        "\n",
        "    precision_macro = precision_score(labels, predictions, average='macro', zero_division=0)\n",
        "    recall_macro = recall_score(labels, predictions, average='macro', zero_division=0)\n",
        "    f1_macro = f1_score(labels, predictions, average='macro', zero_division=0)\n",
        "\n",
        "    return precision_macro, recall_macro, f1_macro\n",
        "\n",
        "# Calculate Micro metrics\n",
        "def micro_metrics(labels, predictions):\n",
        "    # Ensure labels and predictions are on CPU\n",
        "    labels = labels.cpu().numpy()\n",
        "    predictions = predictions.cpu().numpy()\n",
        "\n",
        "    precision_micro = precision_score(labels, predictions, average='micro', zero_division=0)\n",
        "    recall_micro = recall_score(labels, predictions, average='micro', zero_division=0)\n",
        "    f1_micro = f1_score(labels, predictions, average='micro', zero_division=0)\n",
        "\n",
        "    return precision_micro, recall_micro, f1_micro\n",
        "\n",
        "# Get evaluations\n",
        "def evaluate(labels, num_classes, model_pred, baseline_pred, random_pred, label_ordering):\n",
        "    results = {}\n",
        "\n",
        "    for pred_type, predictions in [('Model', model_pred), ('Baseline', baseline_pred), ('Random', random_pred)]:\n",
        "        curr_results = results[pred_type] = {}\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = (predictions == labels).sum().item() / labels.size(0)\n",
        "        precision_per_class, recall_per_class, f1_per_class = per_class_metrics(labels, predictions, num_classes, label_ordering)\n",
        "        precision_macro, recall_macro, f1_macro = macro_metrics(labels, predictions)\n",
        "        precision_micro, recall_micro, f1_micro = micro_metrics(labels, predictions)\n",
        "\n",
        "        # Save all metrics\n",
        "        curr_results[\"Accuracy\"] = accuracy\n",
        "        curr_results[\"Per-Class Precision\"] = precision_per_class\n",
        "        curr_results[\"Per-Class Recall\"] = recall_per_class\n",
        "        curr_results[\"Per-Class F1\"] = f1_per_class\n",
        "\n",
        "        curr_results[\"Macro Precision\"] = precision_macro\n",
        "        curr_results[\"Macro Recall\"] = recall_macro\n",
        "        curr_results[\"Macro F1\"] = f1_macro\n",
        "\n",
        "        curr_results[\"Micro Precision\"] = precision_micro\n",
        "        curr_results[\"Micro Recall\"] = recall_micro\n",
        "        curr_results[\"Micro F1\"] = f1_micro\n",
        "\n",
        "    return results\n",
        "\n",
        "def evaluate_data(model, loader, num_classes, num_instances, label_ordering, orig_label_counts, device):\n",
        "    # Get model, baseline, and random predictions\n",
        "    # Use model predictions to get the labels since the\n",
        "    # loader might shuffle its values and might not be in the same order as y upon iteration\n",
        "    model_pred, labels = get_predictions(loader, model, num_instances, pred_type='model', device=device)\n",
        "    # Get other prediction types as normal\n",
        "    baseline_pred = get_predictions(\n",
        "        loader, model, num_instances, pred_type='baseline',\n",
        "        label_ordering=label_ordering, orig_label_counts=orig_label_counts\n",
        "    )\n",
        "    random_pred = get_predictions(loader, model, num_instances, pred_type='random', num_classes=num_classes)\n",
        "\n",
        "    print()\n",
        "\n",
        "    # Move tensors to CPU before passing to sklearn functions\n",
        "    labels = labels.cpu()\n",
        "    model_pred = model_pred.cpu()\n",
        "    baseline_pred = baseline_pred.cpu()\n",
        "    random_pred = random_pred.cpu()\n",
        "\n",
        "    # Print evaluation results\n",
        "    pprint.pprint(evaluate(labels, num_classes, model_pred, baseline_pred, random_pred, label_ordering))\n",
        "\n",
        "    # Generate confusion matrix and move to CPU\n",
        "    conf_matrix = confusion_matrix(labels.cpu(), model_pred.cpu())\n",
        "    class_labels = label_ordering\n",
        "\n",
        "    # Plot the confusion matrix as a heatmap\n",
        "    def plot_confusion_matrix(conf_matrix, class_labels):\n",
        "        sns.heatmap(\n",
        "            conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
        "            xticklabels=class_labels, yticklabels=class_labels\n",
        "        )\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.xlabel('Predicted Labels')\n",
        "        plt.ylabel('True Labels')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    print(\"\\n\")\n",
        "    plot_confusion_matrix(conf_matrix, class_labels)\n",
        "\n",
        "\"\"\"###Val Set Results\"\"\"\n",
        "\n",
        "X_val, _, _, _, y_val = as_tensors(\"valid\", label_encoder, input_vector_size, token_to_idx)\n",
        "val_dataset = TensorDataset(X_val, y_val)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "evaluate_data(bilstm_model, val_loader, OUTPUT_DIM, y_val.size(0), label_encoder.classes_, train_label_counts, device)\n",
        "\n",
        "\"\"\"###Test Set Results\"\"\"\n",
        "\n",
        "X_test, _, _, _, y_test = as_tensors(\"test\", label_encoder, input_vector_size, token_to_idx)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "evaluate_data(bilstm_model, test_loader, OUTPUT_DIM, y_test.size(0), label_encoder.classes_, train_label_counts, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CBErGbGDk-uc",
        "outputId": "0a985a4c-4782-47c8-df81-a5c22eb195d2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset columns(14 in total) peek:\n",
            "  id\n",
            "  label\n",
            "  claim\n",
            "  subject\n",
            "  speaker\n",
            "  speaker_job_title\n",
            "  state_info\n",
            "  party_affiliation\n",
            "  barely_true_counts\n",
            "  false_counts\n",
            "  half_true_counts\n",
            "  mostly_true_counts\n",
            "  pants_on_fire_counts\n",
            "  context\n",
            "The training dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10240 entries, 0 to 10239\n",
            "Data columns (total 14 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   id                    10240 non-null  object \n",
            " 1   label                 10240 non-null  object \n",
            " 2   claim                 10240 non-null  object \n",
            " 3   subject               10238 non-null  object \n",
            " 4   speaker               10238 non-null  object \n",
            " 5   speaker_job_title     7342 non-null   object \n",
            " 6   state_info            8030 non-null   object \n",
            " 7   party_affiliation     10238 non-null  object \n",
            " 8   barely_true_counts    10238 non-null  float64\n",
            " 9   false_counts          10238 non-null  float64\n",
            " 10  half_true_counts      10238 non-null  float64\n",
            " 11  mostly_true_counts    10238 non-null  float64\n",
            " 12  pants_on_fire_counts  10238 non-null  float64\n",
            " 13  context               10138 non-null  object \n",
            "dtypes: float64(5), object(9)\n",
            "memory usage: 1.1+ MB\n",
            "\n",
            "Data peek:\n",
            "            id        label  \\\n",
            "0    2635.json        false   \n",
            "1   10540.json    half-true   \n",
            "2     324.json  mostly-true   \n",
            "3    1123.json        false   \n",
            "4    9028.json    half-true   \n",
            "5   12465.json         true   \n",
            "6    2342.json  barely-true   \n",
            "7     153.json    half-true   \n",
            "8    5602.json    half-true   \n",
            "9    9741.json  mostly-true   \n",
            "10   7115.json  mostly-true   \n",
            "11   4148.json    half-true   \n",
            "12   5947.json        false   \n",
            "13   8616.json  mostly-true   \n",
            "14   8705.json  barely-true   \n",
            "15  10683.json    half-true   \n",
            "16    620.json         true   \n",
            "17   3863.json  barely-true   \n",
            "18  12372.json    half-true   \n",
            "19  12385.json  mostly-true   \n",
            "\n",
            "                                                claim  \\\n",
            "0   Says the Annies List political group supports ...   \n",
            "1   When did the decline of coal start? It started...   \n",
            "2   Hillary Clinton agrees with John McCain \"by vo...   \n",
            "3   Health care reform legislation is likely to ma...   \n",
            "4   The economic turnaround started at the end of ...   \n",
            "5   The Chicago Bears have had more starting quart...   \n",
            "6   Jim Dunnam has not lived in the district he re...   \n",
            "7   I'm the only person on this stage who has work...   \n",
            "8   However, it took $19.5 million in Oregon Lotte...   \n",
            "9   Says GOP primary opponents Glenn Grothman and ...   \n",
            "10  For the first time in history, the share of th...   \n",
            "11  Since 2000, nearly 12 million Americans have s...   \n",
            "12  When Mitt Romney was governor of Massachusetts...   \n",
            "13  The economy bled $24 billion due to the govern...   \n",
            "14  Most of the (Affordable Care Act) has already ...   \n",
            "15  In this last election in November, ... 63 perc...   \n",
            "16  McCain opposed a requirement that the governme...   \n",
            "17  U.S. Rep. Ron Kind, D-Wis., and his fellow Dem...   \n",
            "18  Water rates in Manila, Philippines, were raise...   \n",
            "19  Almost 100,000 people left Puerto Rico last year.   \n",
            "\n",
            "                                      subject  \\\n",
            "0                                    abortion   \n",
            "1          energy,history,job-accomplishments   \n",
            "2                              foreign-policy   \n",
            "3                                 health-care   \n",
            "4                                economy,jobs   \n",
            "5                                   education   \n",
            "6                        candidates-biography   \n",
            "7                                      ethics   \n",
            "8                                        jobs   \n",
            "9   energy,message-machine-2014,voting-record   \n",
            "10                                  elections   \n",
            "11    economy,jobs,new-hampshire-2012,poverty   \n",
            "12                       history,state-budget   \n",
            "13         economy,federal-budget,health-care   \n",
            "14                                health-care   \n",
            "15                                  elections   \n",
            "16                             federal-budget   \n",
            "17                             federal-budget   \n",
            "18  financial-regulation,foreign-policy,water   \n",
            "19              bankruptcy,economy,population   \n",
            "\n",
            "                                        speaker  \\\n",
            "0                                  dwayne-bohac   \n",
            "1                                scott-surovell   \n",
            "2                                  barack-obama   \n",
            "3                                  blog-posting   \n",
            "4                                 charlie-crist   \n",
            "5                                     robin-vos   \n",
            "6                        republican-party-texas   \n",
            "7                                  barack-obama   \n",
            "8                                oregon-lottery   \n",
            "9                                 duey-stroebel   \n",
            "10                              robert-menendez   \n",
            "11                                     bernie-s   \n",
            "12                                  mitt-romney   \n",
            "13                                   doonesbury   \n",
            "14                                  george-will   \n",
            "15                                     bernie-s   \n",
            "16                                 barack-obama   \n",
            "17  national-republican-congressional-committee   \n",
            "18                                   gwen-moore   \n",
            "19                                     jack-lew   \n",
            "\n",
            "                    speaker_job_title         state_info party_affiliation  \\\n",
            "0                State representative              Texas        republican   \n",
            "1                      State delegate           Virginia          democrat   \n",
            "2                           President           Illinois          democrat   \n",
            "3                                 NaN                NaN              none   \n",
            "4                                 NaN            Florida          democrat   \n",
            "5          Wisconsin Assembly speaker          Wisconsin        republican   \n",
            "6                                 NaN              Texas        republican   \n",
            "7                           President           Illinois          democrat   \n",
            "8                                 NaN                NaN      organization   \n",
            "9                State representative          Wisconsin        republican   \n",
            "10                       U.S. Senator         New Jersey          democrat   \n",
            "11                       U.S. Senator            Vermont       independent   \n",
            "12                    Former governor      Massachusetts        republican   \n",
            "13                                NaN                NaN              none   \n",
            "14                          Columnist           Maryland         columnist   \n",
            "15                       U.S. Senator            Vermont       independent   \n",
            "16                          President           Illinois          democrat   \n",
            "17                                NaN                NaN        republican   \n",
            "18  U.S. House member -- 4th District          Wisconsin          democrat   \n",
            "19                Treasury secretary   Washington, D.C.           democrat   \n",
            "\n",
            "    barely_true_counts  false_counts  half_true_counts  mostly_true_counts  \\\n",
            "0                  0.0           1.0               0.0                 0.0   \n",
            "1                  0.0           0.0               1.0                 1.0   \n",
            "2                 70.0          71.0             160.0               163.0   \n",
            "3                  7.0          19.0               3.0                 5.0   \n",
            "4                 15.0           9.0              20.0                19.0   \n",
            "5                  0.0           3.0               2.0                 5.0   \n",
            "6                  3.0           1.0               1.0                 3.0   \n",
            "7                 70.0          71.0             160.0               163.0   \n",
            "8                  0.0           0.0               1.0                 0.0   \n",
            "9                  0.0           0.0               0.0                 1.0   \n",
            "10                 1.0           3.0               1.0                 3.0   \n",
            "11                18.0          12.0              22.0                41.0   \n",
            "12                34.0          32.0              58.0                33.0   \n",
            "13                 0.0           0.0               2.0                 4.0   \n",
            "14                 7.0           6.0               3.0                 5.0   \n",
            "15                18.0          12.0              22.0                41.0   \n",
            "16                70.0          71.0             160.0               163.0   \n",
            "17                18.0           9.0               8.0                 5.0   \n",
            "18                 3.0           4.0               4.0                 3.0   \n",
            "19                 0.0           1.0               0.0                 1.0   \n",
            "\n",
            "    pants_on_fire_counts                                   context  \n",
            "0                    0.0                                  a mailer  \n",
            "1                    0.0                           a floor speech.  \n",
            "2                    9.0                                    Denver  \n",
            "3                   44.0                            a news release  \n",
            "4                    2.0                       an interview on CNN  \n",
            "5                    1.0                 a an online opinion-piece  \n",
            "6                    1.0                          a press release.  \n",
            "7                    9.0  a Democratic debate in Philadelphia, Pa.  \n",
            "8                    1.0                                a website   \n",
            "9                    0.0                           an online video  \n",
            "10                   0.0                                  a speech  \n",
            "11                   0.0                                   a tweet  \n",
            "12                  19.0                an interview with CBN News  \n",
            "13                   0.0   a Doonesbury strip in the Sunday comics  \n",
            "14                   1.0             comments on \"Fox News Sunday\"  \n",
            "15                   0.0              a town hall in Austin, Texas  \n",
            "16                   9.0                                a radio ad  \n",
            "17                   8.0                            a news release  \n",
            "18                   1.0                   a congressional hearing  \n",
            "19                   0.0          an interview with Bloomberg News  \n",
            "\n",
            "Tokenized sentences(10240 sentences, 442958 total tokens) peek:\n",
            "  ['says', 'annies', 'list', 'political', 'group', 'supports', 'third-trimester', 'abortions', 'demand', '.', '|', 'state_info', ':', 'texas', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'dwayne-bohac', '|', 'subject', ':', 'abortion', '|', 'context', ':', 'mailer', '|', 'speaker_job_title', ':', 'state', 'representative', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['decline', 'coal', 'start', '?', 'started', 'natural', 'gas', 'took', 'started', 'begin', '(', 'president', 'george', 'w.', ')', 'bushs', 'administration', '.', '|', 'state_info', ':', 'virginia', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'scott-surovell', '|', 'subject', ':', 'energy', ',', 'history', ',', 'job-accomplishments', '|', 'context', ':', 'floor', 'speech', '.', '|', 'speaker_job_title', ':', 'state', 'delegate']\n",
            "  ['hillary', 'clinton', 'agrees', 'john', 'mccain', '``', 'by', 'voting', 'give', 'george', 'bush', 'benefit', 'doubt', 'iran', '.', \"''\", '|', 'state_info', ':', 'illinois', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'barack-obama', '|', 'subject', ':', 'foreign-policy', '|', 'context', ':', 'denver', '|', 'speaker_job_title', ':', 'president', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['health', 'care', 'reform', 'legislation', 'likely', 'mandate', 'free', 'sex', 'change', 'surgeries', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'blog-posting', '|', 'subject', ':', 'health-care', '|', 'context', ':', 'news', 'release', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['economic', 'turnaround', 'started', 'end', 'term', '.', '|', 'state_info', ':', 'florida', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'charlie-crist', '|', 'subject', ':', 'economy', ',', 'jobs', '|', 'context', ':', 'interview', 'cnn', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['chicago', 'bears', 'starting', 'quarterbacks', 'last', '10', 'years', 'total', 'number', 'tenured', '(', 'uw', ')', 'faculty', 'fired', 'last', 'two', 'decades', '.', '|', 'state_info', ':', 'wisconsin', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'robin-vos', '|', 'subject', ':', 'education', '|', 'context', ':', 'online', 'opinion-piece', '|', 'speaker_job_title', ':', 'wisconsin', 'assembly', 'speaker', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['jim', 'dunnam', 'lived', 'district', 'represents', 'years', 'now', '.', '|', 'state_info', ':', 'texas', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'republican-party-texas', '|', 'subject', ':', 'candidates-biography', '|', 'context', ':', 'press', 'release', '.', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['i', \"'m\", 'person', 'stage', 'worked', 'actively', 'last', 'year', 'passing', ',', 'along', 'russ', 'feingold', ',', 'toughest', 'ethics', 'reform', 'since', 'watergate', '.', '|', 'state_info', ':', 'illinois', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'barack-obama', '|', 'subject', ':', 'ethics', '|', 'context', ':', 'democratic', 'debate', 'philadelphia', ',', 'pa.', '|', 'speaker_job_title', ':', 'president', '<PAD>']\n",
            "  ['however', ',', 'took', '$', '19.5', 'million', 'oregon', 'lottery', 'funds', 'port', 'newport', 'eventually', 'land', 'new', 'noaa', 'marine', 'operations', 'center-pacific', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'organization', '|', 'speaker', ':', 'oregon-lottery', '|', 'subject', ':', 'jobs', '|', 'context', ':', 'website', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['says', 'gop', 'primary', 'opponents', 'glenn', 'grothman', 'joe', 'leibham', 'cast', 'compromise', 'vote', 'cost', '$', '788', 'million', 'higher', 'electricity', 'costs', '.', '|', 'state_info', ':', 'wisconsin', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'duey-stroebel', '|', 'subject', ':', 'energy', ',', 'message-machine-2014', ',', 'voting-record', '|', 'context', ':', 'online', 'video', '|', 'speaker_job_title', ':', 'state', 'representative']\n",
            "  ['first', 'time', 'history', ',', 'share', 'national', 'popular', 'vote', 'margin', 'smaller', 'latino', 'vote', 'margin', '.', '|', 'state_info', ':', 'new', 'jersey', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'robert-menendez', '|', 'subject', ':', 'elections', '|', 'context', ':', 'speech', '|', 'speaker_job_title', ':', 'u.s.', 'senator', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['since', '2000', ',', 'nearly', '12', 'million', 'americans', 'slipped', 'middle', 'class', 'poverty', '.', '|', 'state_info', ':', 'vermont', '|', 'party_affiliation', ':', 'independent', '|', 'speaker', ':', 'bernie-s', '|', 'subject', ':', 'economy', ',', 'jobs', ',', 'new-hampshire-2012', ',', 'poverty', '|', 'context', ':', 'tweet', '|', 'speaker_job_title', ':', 'u.s.', 'senator', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['mitt', 'romney', 'governor', 'massachusetts', ',', 'didnt', 'slow', 'rate', 'growth', 'government', ',', 'actually', 'cut', 'it', '.', '|', 'state_info', ':', 'massachusetts', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'mitt-romney', '|', 'subject', ':', 'history', ',', 'state-budget', '|', 'context', ':', 'interview', 'cbn', 'news', '|', 'speaker_job_title', ':', 'former', 'governor', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['economy', 'bled', '$', '24', 'billion', 'due', 'government', 'shutdown', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'doonesbury', '|', 'subject', ':', 'economy', ',', 'federal-budget', ',', 'health-care', '|', 'context', ':', 'doonesbury', 'strip', 'sunday', 'comics', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['(', 'affordable', 'care', 'act', ')', 'already', 'sense', 'waived', 'otherwise', 'suspended', '.', '|', 'state_info', ':', 'maryland', '|', 'party_affiliation', ':', 'columnist', '|', 'speaker', ':', 'george-will', '|', 'subject', ':', 'health-care', '|', 'context', ':', 'comments', '``', 'fox', 'news', 'sunday', \"''\", '|', 'speaker_job_title', ':', 'columnist', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['last', 'election', 'november', ',', '...', '63', 'percent', 'american', 'people', 'chose', 'vote', ',', '...', '80', 'percent', 'young', 'people', ',', '(', 'and', ')', '75', 'percent', 'low-income', 'workers', 'chose', 'vote', '.', '|', 'state_info', ':', 'vermont', '|', 'party_affiliation', ':', 'independent', '|', 'speaker', ':', 'bernie-s', '|', 'subject', ':', 'elections', '|', 'context', ':', 'town', 'hall']\n",
            "  ['mccain', 'opposed', 'requirement', 'government', 'buy', 'american-made', 'motorcycles', '.', 'said', 'buy-american', 'provisions', 'quote', \"'disgraceful\", '.', \"'\", '|', 'state_info', ':', 'illinois', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'barack-obama', '|', 'subject', ':', 'federal-budget', '|', 'context', ':', 'radio', 'ad', '|', 'speaker_job_title', ':', 'president', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['u.s.', 'rep.', 'ron', 'kind', ',', 'd-wis.', ',', 'fellow', 'democrats', 'went', 'spending', 'spree', 'credit', 'card', 'maxed', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'national-republican-congressional-committee', '|', 'subject', ':', 'federal-budget', '|', 'context', ':', 'news', 'release', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['water', 'rates', 'manila', ',', 'philippines', ',', 'raised', '845', 'percent', 'subsidiary', 'world', 'bank', 'became', 'partial', 'owner', '.', '|', 'state_info', ':', 'wisconsin', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'gwen-moore', '|', 'subject', ':', 'financial-regulation', ',', 'foreign-policy', ',', 'water', '|', 'context', ':', 'congressional', 'hearing', '|', 'speaker_job_title', ':', 'u.s.', 'house', 'member', '--', '4th']\n",
            "  ['almost', '100,000', 'people', 'left', 'puerto', 'rico', 'last', 'year', '.', '|', 'state_info', ':', 'washington', ',', 'd.c.', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'jack-lew', '|', 'subject', ':', 'bankruptcy', ',', 'economy', ',', 'population', '|', 'context', ':', 'interview', 'bloomberg', 'news', '|', 'speaker_job_title', ':', 'treasury', 'secretary', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "\n",
            "10000 unique tokens\n",
            "Unique tokens peek:\n",
            "  <PAD>\n",
            "  |\n",
            "  :\n",
            "  ,\n",
            "  .\n",
            "  speaker\n",
            "  state_info\n",
            "  party_affiliation\n",
            "  subject\n",
            "  context\n",
            "  speaker_job_title\n",
            "  republican\n",
            "  nan\n",
            "  democrat\n",
            "  says\n",
            "  u.s.\n",
            "  none\n",
            "  interview\n",
            "  new\n",
            "  state\n",
            "\n",
            "Final Index Sets(Set_Size = 49, 10240 index sets) peek:\n",
            "  [15, 8935, 1182, 201, 326, 516, 6415, 766, 1978, 5, 2, 7, 3, 21, 2, 8, 3, 12, 2, 6, 3, 8936, 2, 9, 3, 100, 2, 10, 3, 356, 2, 11, 3, 20, 62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [2580, 1333, 1183, 479, 783, 1431, 407, 247, 783, 2393, 37, 28, 333, 784, 38, 1704, 232, 5, 2, 7, 3, 69, 2, 8, 3, 14, 2, 6, 3, 8937, 2, 9, 3, 79, 4, 63, 4, 124, 2, 10, 3, 192, 33, 5, 2, 11, 3, 20, 1492]\n",
            "  [170, 130, 4384, 238, 314, 24, 4385, 438, 456, 333, 227, 1381, 4386, 547, 5, 27, 2, 7, 3, 61, 2, 8, 3, 14, 2, 6, 3, 73, 2, 9, 3, 76, 2, 10, 3, 1046, 2, 11, 3, 28, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [57, 68, 329, 385, 866, 867, 580, 868, 540, 5156, 5, 2, 7, 3, 13, 2, 8, 3, 17, 2, 6, 3, 581, 2, 9, 3, 31, 2, 10, 3, 40, 53, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [365, 5157, 783, 557, 813, 5, 2, 7, 3, 22, 2, 8, 3, 14, 2, 6, 3, 522, 2, 9, 3, 25, 4, 29, 2, 10, 3, 18, 121, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [1334, 4387, 1979, 6416, 108, 151, 59, 705, 303, 6417, 37, 5158, 38, 2581, 1705, 108, 209, 1231, 5, 2, 7, 3, 34, 2, 8, 3, 12, 2, 6, 3, 2230, 2, 9, 3, 39, 2, 10, 3, 410, 8938, 2, 11, 3, 34, 501, 6, 1, 1, 1]\n",
            "  [889, 8939, 2795, 127, 1882, 59, 517, 5, 2, 7, 3, 21, 2, 8, 3, 12, 2, 6, 3, 2796, 2, 9, 3, 54, 2, 10, 3, 50, 53, 5, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [606, 1626, 654, 2103, 890, 3811, 108, 64, 2231, 4, 1627, 1287, 1288, 4, 3812, 200, 329, 99, 8940, 5, 2, 7, 3, 61, 2, 8, 3, 14, 2, 6, 3, 73, 2, 9, 3, 200, 2, 10, 3, 117, 46, 847, 4, 1493, 2, 11, 3, 28, 1]\n",
            "  [6418, 4, 247, 26, 8941, 71, 104, 1794, 624, 3061, 4388, 4389, 848, 19, 6419, 3813, 1795, 8942, 5, 2, 7, 3, 13, 2, 8, 3, 149, 2, 6, 3, 6420, 2, 9, 3, 29, 2, 10, 3, 150, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1]\n",
            "  [15, 442, 493, 3364, 1706, 6421, 466, 8943, 1707, 3365, 229, 230, 26, 8944, 71, 337, 2394, 357, 5, 2, 7, 3, 34, 2, 8, 3, 12, 2, 6, 3, 8945, 2, 9, 3, 79, 4, 814, 4, 185, 2, 10, 3, 410, 187, 2, 11, 3, 20, 62]\n",
            "  [129, 138, 63, 4, 1382, 102, 1140, 229, 2232, 1708, 2582, 229, 2232, 5, 2, 7, 3, 19, 84, 2, 8, 3, 14, 2, 6, 3, 2233, 2, 9, 3, 55, 2, 10, 3, 33, 2, 11, 3, 16, 32, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [99, 977, 4, 208, 548, 71, 152, 8946, 538, 607, 159, 5, 2, 7, 3, 371, 2, 8, 3, 202, 2, 6, 3, 418, 2, 9, 3, 25, 4, 29, 4, 558, 4, 159, 2, 10, 3, 173, 2, 11, 3, 16, 32, 1, 1, 1, 1, 1, 1]\n",
            "  [293, 246, 35, 134, 4, 457, 5159, 141, 451, 110, 4, 298, 145, 290, 5, 2, 7, 3, 134, 2, 8, 3, 12, 2, 6, 3, 204, 2, 9, 3, 63, 4, 52, 2, 10, 3, 18, 8947, 40, 2, 11, 3, 111, 35, 1, 1, 1, 1, 1]\n",
            "  [25, 8948, 26, 1141, 93, 767, 110, 1980, 5, 2, 7, 3, 13, 2, 8, 3, 17, 2, 6, 3, 3062, 2, 9, 3, 25, 4, 48, 4, 31, 2, 10, 3, 3062, 1981, 372, 5160, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [37, 639, 68, 300, 38, 467, 3063, 4390, 4391, 4392, 5, 2, 7, 3, 447, 2, 8, 3, 448, 2, 6, 3, 1232, 2, 9, 3, 31, 2, 10, 3, 118, 24, 90, 40, 372, 27, 2, 11, 3, 448, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [108, 373, 1563, 4, 97, 3366, 30, 161, 60, 2583, 229, 4, 97, 640, 30, 655, 60, 4, 37, 753, 38, 1289, 30, 2104, 88, 2583, 229, 5, 2, 7, 3, 371, 2, 8, 3, 202, 2, 6, 3, 418, 2, 9, 3, 55, 2, 10, 3, 366, 419]\n",
            "  [314, 683, 2395, 110, 549, 8949, 6422, 5, 91, 8950, 2234, 2584, 8951, 5, 139, 2, 7, 3, 61, 2, 8, 3, 14, 2, 6, 3, 73, 2, 9, 3, 48, 2, 10, 3, 92, 42, 2, 11, 3, 28, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [16, 345, 1184, 1233, 4, 8952, 4, 1982, 239, 388, 166, 4393, 754, 1709, 3367, 2, 7, 3, 13, 2, 8, 3, 12, 2, 6, 3, 721, 2, 9, 3, 48, 2, 10, 3, 40, 53, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [330, 389, 8953, 4, 6423, 4, 439, 6424, 30, 8954, 205, 1001, 755, 5161, 869, 5, 2, 7, 3, 34, 2, 8, 3, 14, 2, 6, 3, 1628, 2, 9, 3, 395, 4, 76, 4, 330, 2, 10, 3, 310, 360, 2, 11, 3, 16, 49, 186, 157, 1494]\n",
            "  [304, 706, 60, 582, 3368, 4394, 108, 64, 5, 2, 7, 3, 120, 4, 198, 2, 8, 3, 14, 2, 6, 3, 6425, 2, 9, 3, 800, 4, 25, 4, 285, 2, 10, 3, 18, 3064, 40, 2, 11, 3, 2105, 305, 1, 1, 1, 1, 1, 1, 1]\n",
            "TRAIN SPLIT: 10240 overall samples: torch.Size([10240, 49])\n",
            "2 labels\n",
            "\n",
            "label\n",
            "false    0.644727\n",
            "true     0.355273\n",
            "Name: proportion, dtype: float64\n",
            "Model: BiLSTMModel(\n",
            "  (embedding): Embedding(10001, 1000, padding_idx=1)\n",
            "  (lstm): LSTM(1000, 128, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
            "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
            ")\n",
            "Number of available GPUs: 1\n",
            "GPU 0: Tesla T4\n",
            "Is a T4 GPU available? True\n",
            "Using GPU: Tesla T4\n",
            "Epoch 1/8 | Loss: 0.5195 | Accuracy: 0.6443\n",
            "Epoch 2/8 | Loss: 0.4367 | Accuracy: 0.7029\n",
            "Epoch 3/8 | Loss: 0.2529 | Accuracy: 0.8626\n",
            "Epoch 4/8 | Loss: 0.1065 | Accuracy: 0.9482\n",
            "Epoch 5/8 | Loss: 0.0536 | Accuracy: 0.9769\n",
            "Epoch 6/8 | Loss: 0.0271 | Accuracy: 0.9894\n",
            "Epoch 7/8 | Loss: 0.0218 | Accuracy: 0.9905\n",
            "Epoch 8/8 | Loss: 0.0207 | Accuracy: 0.9909\n",
            "Model weights saved to 'bilstm_model_weights.pth'\n",
            "The training dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1284 entries, 0 to 1283\n",
            "Data columns (total 14 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   id                    1284 non-null   object\n",
            " 1   label                 1284 non-null   object\n",
            " 2   claim                 1284 non-null   object\n",
            " 3   subject               1284 non-null   object\n",
            " 4   speaker               1284 non-null   object\n",
            " 5   speaker_job_title     939 non-null    object\n",
            " 6   state_info            1005 non-null   object\n",
            " 7   party_affiliation     1284 non-null   object\n",
            " 8   barely_true_counts    1284 non-null   int64 \n",
            " 9   false_counts          1284 non-null   int64 \n",
            " 10  half_true_counts      1284 non-null   int64 \n",
            " 11  mostly_true_counts    1284 non-null   int64 \n",
            " 12  pants_on_fire_counts  1284 non-null   int64 \n",
            " 13  context               1272 non-null   object\n",
            "dtypes: int64(5), object(9)\n",
            "memory usage: 140.6+ KB\n",
            "\n",
            "Data peek:\n",
            "            id        label  \\\n",
            "0   12134.json  barely-true   \n",
            "1     238.json   pants-fire   \n",
            "2    7891.json        false   \n",
            "3    8169.json    half-true   \n",
            "4     929.json    half-true   \n",
            "5    9416.json        false   \n",
            "6    6861.json         true   \n",
            "7    1122.json        false   \n",
            "8   13138.json         true   \n",
            "9    1880.json    half-true   \n",
            "10  12803.json    half-true   \n",
            "11   5409.json        false   \n",
            "12   7313.json    half-true   \n",
            "13   4809.json         true   \n",
            "14   1671.json  barely-true   \n",
            "15   4348.json    half-true   \n",
            "16   6225.json    half-true   \n",
            "17   7675.json  mostly-true   \n",
            "18   2255.json  barely-true   \n",
            "19   9827.json   pants-fire   \n",
            "\n",
            "                                                claim  \\\n",
            "0   We have less Americans working now than in the...   \n",
            "1   When Obama was sworn into office, he DID NOT u...   \n",
            "2   Says Having organizations parading as being so...   \n",
            "3      Says nearly half of Oregons children are poor.   \n",
            "4   On attacks by Republicans that various program...   \n",
            "5   Says when armed civilians stop mass shootings ...   \n",
            "6   Says Tennessee is providing millions of dollar...   \n",
            "7   The health care reform plan would set limits s...   \n",
            "8   Says Donald Trump started his career back in 1...   \n",
            "9   Bill White has a long history of trying to lim...   \n",
            "10  John McCains chief economic adviser during the...   \n",
            "11  Says 21,000 Wisconsin residents got jobs in 20...   \n",
            "12  State revenue projections have missed the mark...   \n",
            "13  The median income of a middle class family wen...   \n",
            "14  Every citizen is entitled to the freedom of sp...   \n",
            "15  Rick Perry has advocated abandoning Social Sec...   \n",
            "16  Two thirds to three quarters of people without...   \n",
            "17  Congress has spent 66 of the first 100 days of...   \n",
            "18  Mark Sharpe has lowered property taxes by 17 p...   \n",
            "19  Says Iowa Gov. Terry Branstad chartered a plan...   \n",
            "\n",
            "                                      subject                 speaker  \\\n",
            "0                                economy,jobs          vicky-hartzler   \n",
            "1            obama-birth-certificate,religion             chain-email   \n",
            "2             campaign-finance,congress,taxes         earl-blumenauer   \n",
            "3                                     poverty         jim-francesconi   \n",
            "4                            economy,stimulus            barack-obama   \n",
            "5                                        guns              jim-rubens   \n",
            "6                      education,state-budget              andy-berke   \n",
            "7                                 health-care             club-growth   \n",
            "8      candidates-biography,diversity,housing         hillary-clinton   \n",
            "9                                    military  republican-party-texas   \n",
            "10                                    economy               tim-kaine   \n",
            "11            job-accomplishments,jobs,states       kathleen-vinehout   \n",
            "12                               state-budget            steve-henson   \n",
            "13                  income,new-hampshire-2012               joe-biden   \n",
            "14                          gays-and-lesbians          david-dewhurst   \n",
            "15             medicaid,social-security,taxes        margaret-carlson   \n",
            "16  health-care,poverty,public-health,welfare       elizabeth-roberts   \n",
            "17                                   congress             john-barrow   \n",
            "18                 candidates-biography,taxes             mark-sharpe   \n",
            "19                                immigration             chain-email   \n",
            "\n",
            "                                speaker_job_title            state_info  \\\n",
            "0                             U.S. Representative              Missouri   \n",
            "1                                             NaN                   NaN   \n",
            "2                             U.S. representative                Oregon   \n",
            "3   Member of the State Board of Higher Education                Oregon   \n",
            "4                                       President              Illinois   \n",
            "5                            Small business owner         New Hampshire   \n",
            "6                        Lawyer and state senator             Tennessee   \n",
            "7                                             NaN                   NaN   \n",
            "8                          Presidential candidate              New York   \n",
            "9                                             NaN                 Texas   \n",
            "10                                   U.S. Senator              Virginia   \n",
            "11                                            NaN                   NaN   \n",
            "12                                  State Senator               Georgia   \n",
            "13                                   U.S. senator              Delaware   \n",
            "14                            Lieutenant governor                 Texas   \n",
            "15                                      Columnist  District of Columbia   \n",
            "16                            Lieutenant Governor          Rhode Island   \n",
            "17                                    Congressman               Georgia   \n",
            "18               Hillsborough County commissioner               Florida   \n",
            "19                                            NaN                   NaN   \n",
            "\n",
            "   party_affiliation  barely_true_counts  false_counts  half_true_counts  \\\n",
            "0         republican                   1             0                 1   \n",
            "1               none                  11            43                 8   \n",
            "2           democrat                   0             1                 1   \n",
            "3               none                   0             1                 1   \n",
            "4           democrat                  70            71               160   \n",
            "5         republican                   1             1                 0   \n",
            "6           democrat                   0             0                 0   \n",
            "7               none                   4             5                 4   \n",
            "8           democrat                  40            29                69   \n",
            "9         republican                   3             1                 1   \n",
            "10          democrat                   8             3                15   \n",
            "11          democrat                   1             1                 1   \n",
            "12          democrat                   0             0                 1   \n",
            "13          democrat                  11            10                21   \n",
            "14        republican                   8             8                10   \n",
            "15              none                   0             0                 1   \n",
            "16          democrat                   1             0                 2   \n",
            "17          democrat                   0             0                 1   \n",
            "18        republican                   1             0                 0   \n",
            "19              none                  11            43                 8   \n",
            "\n",
            "    mostly_true_counts  pants_on_fire_counts  \\\n",
            "0                    0                     0   \n",
            "1                    5                   105   \n",
            "2                    1                     0   \n",
            "3                    1                     0   \n",
            "4                  163                     9   \n",
            "5                    1                     0   \n",
            "6                    0                     0   \n",
            "7                    2                     0   \n",
            "8                   76                     7   \n",
            "9                    3                     1   \n",
            "10                  15                     0   \n",
            "11                   1                     0   \n",
            "12                   0                     0   \n",
            "13                  16                     4   \n",
            "14                   5                     5   \n",
            "15                   0                     0   \n",
            "16                   0                     0   \n",
            "17                   1                     0   \n",
            "18                   0                     0   \n",
            "19                   5                   105   \n",
            "\n",
            "                                              context  \n",
            "0                        an interview with ABC17 News  \n",
            "1                                                 NaN  \n",
            "2                       a U.S. Ways and Means hearing  \n",
            "3                                  an opinion article  \n",
            "4                             interview with CBS News  \n",
            "5         in an interview at gun shop in Hudson, N.H.  \n",
            "6   a letter to state Senate education committee c...  \n",
            "7                                             a TV ad  \n",
            "8                       the first presidential debate  \n",
            "9                                           an e-mail  \n",
            "10  a speech at the Democratic National Convention...  \n",
            "11                                            remarks  \n",
            "12                                    a press release  \n",
            "13  speaking at New Hampshires Plymouth State Uni...  \n",
            "14                                    a press release  \n",
            "15                                 a politics column.  \n",
            "16        a panel discussion on \"A Lively Experiment\"  \n",
            "17                                           a letter  \n",
            "18                                  a campaign mailer  \n",
            "19                                      a chain email  \n",
            "\n",
            "Tokenized sentences(1284 sentences, 55513 total tokens) peek:\n",
            "  ['less', 'americans', 'working', '70s', '.', '|', 'state_info', ':', 'missouri', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'vicky-hartzler', '|', 'subject', ':', 'economy', ',', 'jobs', '|', 'context', ':', 'interview', 'abc17', 'news', '|', 'speaker_job_title', ':', 'u.s.', 'representative', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['obama', 'sworn', 'office', ',', 'use', 'holy', 'bible', ',', 'instead', 'kuran', '(', 'their', 'equivalency', 'bible', ',', 'different', 'beliefs', ')', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'chain-email', '|', 'subject', ':', 'obama-birth-certificate', ',', 'religion', '|', 'context', ':', 'nan', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['says', 'organizations', 'parading', 'social', 'welfare', 'organizations', 'involved', 'political', 'combat', 'harkens', 'back', 'statute', 'hundred', 'years', 'ago', 'said', 'prohibited', '.', '|', 'state_info', ':', 'oregon', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'earl-blumenauer', '|', 'subject', ':', 'campaign-finance', ',', 'congress', ',', 'taxes', '|', 'context', ':', 'u.s.', 'ways', 'means', 'hearing', '|', 'speaker_job_title', ':', 'u.s.']\n",
            "  ['says', 'nearly', 'half', 'oregons', 'children', 'poor', '.', '|', 'state_info', ':', 'oregon', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'jim-francesconi', '|', 'subject', ':', 'poverty', '|', 'context', ':', 'opinion', 'article', '|', 'speaker_job_title', ':', 'member', 'state', 'board', 'higher', 'education', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['attacks', 'republicans', 'various', 'programs', 'economic', 'stimulus', 'plan', 'stimulative', ',', '``', 'if', 'add', 'stuff', 'up', ',', 'accounts', 'less', '1', 'percent', 'overall', 'package', '.', \"''\", '|', 'state_info', ':', 'illinois', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'barack-obama', '|', 'subject', ':', 'economy', ',', 'stimulus', '|', 'context', ':', 'interview', 'cbs', 'news', '|', 'speaker_job_title']\n",
            "  ['says', 'armed', 'civilians', 'stop', 'mass', 'shootings', 'guns', ',', 'average', '2.5', 'people', 'die', ';', 'otherwise', ',', 'average', '18', 'people', 'die', '.', '|', 'state_info', ':', 'new', 'hampshire', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'jim-rubens', '|', 'subject', ':', 'guns', '|', 'context', ':', 'interview', 'gun', 'shop', 'hudson', ',', 'n.h.', '|', 'speaker_job_title', ':']\n",
            "  ['says', 'tennessee', 'providing', 'millions', 'dollars', 'virtual', 'school', 'company', 'results', 'bottom', 'bottom', '.', '|', 'state_info', ':', 'tennessee', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'andy-berke', '|', 'subject', ':', 'education', ',', 'state-budget', '|', 'context', ':', 'letter', 'state', 'senate', 'education', 'committee', 'chairwoman', 'dolores', 'gresham', '.', '|', 'speaker_job_title', ':', 'lawyer', 'state', 'senator', '<PAD>']\n",
            "  ['health', 'care', 'reform', 'plan', 'would', 'set', 'limits', 'similar', 'socialized', 'system', 'britain', ',', 'people', 'allowed', 'die', 'treatment', 'would', 'cost', '$', '22,000', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'club-growth', '|', 'subject', ':', 'health-care', '|', 'context', ':', 'tv', 'ad', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['says', 'donald', 'trump', 'started', 'career', 'back', '1973', 'sued', 'justice', 'department', 'racial', 'discrimination', 'would', 'rent', 'apartments', 'one', 'developments', 'african-americans', '.', '|', 'state_info', ':', 'new', 'york', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'hillary-clinton', '|', 'subject', ':', 'candidates-biography', ',', 'diversity', ',', 'housing', '|', 'context', ':', 'first', 'presidential', 'debate', '|', 'speaker_job_title', ':']\n",
            "  ['bill', 'white', 'long', 'history', 'trying', 'limit', 'even', 'disenfranchise', 'military', 'voters', '.', '|', 'state_info', ':', 'texas', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'republican-party-texas', '|', 'subject', ':', 'military', '|', 'context', ':', 'e-mail', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['john', 'mccains', 'chief', 'economic', 'adviser', '08', 'race', 'estimated', 'trumps', 'promises', 'would', 'cause', 'america', 'lose', '3.5', 'million', 'jobs', '.', '|', 'state_info', ':', 'virginia', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'tim-kaine', '|', 'subject', ':', 'economy', '|', 'context', ':', 'speech', 'democratic', 'national', 'convention', 'philadelphia', '|', 'speaker_job_title', ':', 'u.s.', 'senator', '<PAD>', '<PAD>']\n",
            "  ['says', '21,000', 'wisconsin', 'residents', 'got', 'jobs', '2011', ',', '18,000', 'states', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'kathleen-vinehout', '|', 'subject', ':', 'job-accomplishments', ',', 'jobs', ',', 'states', '|', 'context', ':', 'remarks', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['state', 'revenue', 'projections', 'missed', 'mark', 'month', 'month', '.', '|', 'state_info', ':', 'georgia', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'steve-henson', '|', 'subject', ':', 'state-budget', '|', 'context', ':', 'press', 'release', '|', 'speaker_job_title', ':', 'state', 'senator', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['median', 'income', 'middle', 'class', 'family', 'went', '$', '2,100', '2001', '2007', '.', '|', 'state_info', ':', 'delaware', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'joe-biden', '|', 'subject', ':', 'income', ',', 'new-hampshire-2012', '|', 'context', ':', 'speaking', 'new', 'hampshires', 'plymouth', 'state', 'university', '|', 'speaker_job_title', ':', 'u.s.', 'senator', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['every', 'citizen', 'entitled', 'freedom', 'speech', ',', 'one', 'right', 'use', 'government', 'funds', 'institutions', 'portray', 'acts', 'morally', 'reprehensible', 'vast', 'majority', 'americans', '.', '|', 'state_info', ':', 'texas', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'david-dewhurst', '|', 'subject', ':', 'gays-and-lesbians', '|', 'context', ':', 'press', 'release', '|', 'speaker_job_title', ':', 'lieutenant', 'governor', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['rick', 'perry', 'advocated', 'abandoning', 'social', 'security', ',', 'scuttling', 'medicaid', 'ending', 'federal', 'income', 'tax', '.', '|', 'state_info', ':', 'district', 'columbia', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'margaret-carlson', '|', 'subject', ':', 'medicaid', ',', 'social-security', ',', 'taxes', '|', 'context', ':', 'politics', 'column', '.', '|', 'speaker_job_title', ':', 'columnist', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['two', 'thirds', 'three', 'quarters', 'people', 'without', '[', 'health', ']', 'insurance', 'rhode', 'island', 'work', '.', '|', 'state_info', ':', 'rhode', 'island', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'elizabeth-roberts', '|', 'subject', ':', 'health-care', ',', 'poverty', ',', 'public-health', ',', 'welfare', '|', 'context', ':', 'panel', 'discussion', '``', 'a', 'lively', 'experiment', \"''\", '|', 'speaker_job_title']\n",
            "  ['congress', 'spent', '66', 'first', '100', 'days', 'term', 'recess', '.', '|', 'state_info', ':', 'georgia', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'john-barrow', '|', 'subject', ':', 'congress', '|', 'context', ':', 'letter', '|', 'speaker_job_title', ':', 'congressman', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['mark', 'sharpe', 'lowered', 'property', 'taxes', '17', 'percent', '.', '|', 'state_info', ':', 'florida', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'mark-sharpe', '|', 'subject', ':', 'candidates-biography', ',', 'taxes', '|', 'context', ':', 'campaign', 'mailer', '|', 'speaker_job_title', ':', 'hillsborough', 'county', 'commissioner', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['says', 'iowa', 'gov', '.', 'terry', 'branstad', 'chartered', 'plane', 'remove', '124', 'young', 'illegal', 'immigrants', 'state', 'take', 'back', 'honduras', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'chain-email', '|', 'subject', ':', 'immigration', '|', 'context', ':', 'chain', 'email', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "\n",
            "10000 unique tokens\n",
            "Unique tokens peek:\n",
            "  <PAD>\n",
            "  |\n",
            "  :\n",
            "  ,\n",
            "  .\n",
            "  speaker\n",
            "  state_info\n",
            "  party_affiliation\n",
            "  subject\n",
            "  context\n",
            "  speaker_job_title\n",
            "  republican\n",
            "  nan\n",
            "  democrat\n",
            "  says\n",
            "  u.s.\n",
            "  none\n",
            "  interview\n",
            "  new\n",
            "  state\n",
            "\n",
            "Final Index Sets(Set_Size = 49, 1284 index sets) peek:\n",
            "  [233, 152, 406, 0, 5, 2, 7, 3, 542, 2, 8, 3, 12, 2, 6, 3, 7845, 2, 9, 3, 25, 4, 29, 2, 10, 3, 18, 0, 40, 2, 11, 3, 16, 62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [47, 4897, 164, 4, 367, 0, 2946, 4, 1497, 0, 37, 5601, 0, 2946, 4, 986, 3042, 38, 5, 2, 7, 3, 13, 2, 8, 3, 17, 2, 6, 3, 267, 2, 9, 3, 1208, 4, 263, 2, 10, 3, 13, 2, 11, 3, 13, 1, 1, 1, 1]\n",
            "  [15, 2200, 0, 143, 417, 2200, 1784, 201, 2652, 0, 382, 6648, 3469, 59, 431, 91, 4005, 5, 2, 7, 3, 104, 2, 8, 3, 14, 2, 6, 3, 4008, 2, 9, 3, 197, 4, 81, 4, 23, 2, 10, 3, 16, 2904, 1000, 360, 2, 11, 3, 16]\n",
            "  [15, 208, 272, 1734, 113, 1149, 5, 2, 7, 3, 104, 2, 8, 3, 17, 2, 6, 3, 7618, 2, 9, 3, 159, 2, 10, 3, 446, 249, 2, 11, 3, 186, 20, 274, 337, 39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [1042, 262, 1272, 701, 365, 131, 128, 0, 4, 24, 2500, 1409, 6121, 712, 4, 1823, 233, 165, 30, 1782, 1897, 5, 27, 2, 7, 3, 61, 2, 8, 3, 14, 2, 6, 3, 73, 2, 9, 3, 25, 4, 131, 2, 10, 3, 18, 653, 40, 2, 11]\n",
            "  [15, 3343, 8780, 583, 1190, 1317, 85, 4, 181, 1929, 60, 1117, 956, 4391, 4, 181, 723, 60, 1117, 5, 2, 7, 3, 19, 216, 2, 8, 3, 12, 2, 6, 3, 8012, 2, 9, 3, 85, 2, 10, 3, 18, 286, 6258, 6434, 4, 474, 2, 11, 3]\n",
            "  [15, 412, 3615, 383, 214, 0, 137, 561, 3447, 1121, 1121, 5, 2, 7, 3, 412, 2, 8, 3, 14, 2, 6, 3, 0, 2, 9, 3, 39, 4, 52, 2, 10, 3, 297, 20, 66, 39, 221, 2932, 0, 0, 5, 2, 11, 3, 620, 20, 32, 1]\n",
            "  [57, 68, 329, 128, 65, 1226, 2697, 1696, 4097, 302, 3782, 4, 60, 636, 1117, 1943, 65, 230, 26, 4190, 5, 2, 7, 3, 13, 2, 8, 3, 17, 2, 6, 3, 1682, 2, 9, 3, 31, 2, 10, 3, 78, 42, 2, 11, 3, 13, 1, 1, 1]\n",
            "  [15, 259, 225, 783, 1298, 382, 3164, 3318, 656, 296, 4433, 2436, 65, 2397, 4408, 77, 0, 2098, 5, 2, 7, 3, 19, 45, 2, 8, 3, 14, 2, 6, 3, 153, 2, 9, 3, 54, 4, 420, 4, 348, 2, 10, 3, 129, 70, 46, 2, 11, 3]\n",
            "  [80, 260, 1080, 63, 904, 1470, 156, 0, 82, 362, 5, 2, 7, 3, 21, 2, 8, 3, 12, 2, 6, 3, 2796, 2, 9, 3, 82, 2, 10, 3, 281, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [238, 5764, 833, 365, 1498, 0, 970, 1252, 1329, 3110, 65, 987, 163, 807, 2907, 71, 29, 5, 2, 7, 3, 69, 2, 8, 3, 14, 2, 6, 3, 765, 2, 9, 3, 25, 2, 10, 3, 33, 117, 102, 218, 847, 2, 11, 3, 16, 32, 1, 1]\n",
            "  [15, 0, 34, 665, 340, 29, 354, 4, 3610, 44, 5, 2, 7, 3, 13, 2, 8, 3, 14, 2, 6, 3, 5288, 2, 9, 3, 124, 4, 29, 4, 44, 2, 10, 3, 276, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [20, 610, 4525, 2023, 954, 533, 533, 5, 2, 7, 3, 58, 2, 8, 3, 14, 2, 6, 3, 0, 2, 9, 3, 52, 2, 10, 3, 50, 53, 2, 11, 3, 20, 32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [1735, 103, 538, 607, 411, 388, 26, 6210, 1467, 1155, 5, 2, 7, 3, 496, 2, 8, 3, 14, 2, 6, 3, 563, 2, 9, 3, 103, 4, 558, 2, 10, 3, 2858, 19, 8844, 8712, 20, 306, 2, 11, 3, 16, 32, 1, 1, 1, 1, 1, 1]\n",
            "  [89, 2193, 0, 1235, 33, 4, 77, 235, 367, 110, 624, 2150, 0, 4557, 0, 0, 2268, 292, 152, 5, 2, 7, 3, 21, 2, 8, 3, 12, 2, 6, 3, 1062, 2, 9, 3, 339, 2, 10, 3, 50, 53, 2, 11, 3, 461, 35, 1, 1, 1]\n",
            "  [251, 541, 2342, 0, 143, 182, 4, 0, 223, 2222, 96, 103, 51, 5, 2, 7, 3, 127, 1406, 2, 8, 3, 17, 2, 6, 3, 0, 2, 9, 3, 223, 4, 312, 4, 23, 2, 10, 3, 1271, 224, 5, 2, 11, 3, 448, 1, 1, 1, 1]\n",
            "  [209, 5565, 207, 6449, 60, 317, 253, 57, 254, 177, 72, 74, 316, 5, 2, 7, 3, 72, 74, 2, 8, 3, 14, 2, 6, 3, 5065, 2, 9, 3, 31, 4, 159, 4, 169, 4, 417, 2, 10, 3, 824, 559, 24, 603, 8771, 5951, 27, 2, 11]\n",
            "  [81, 335, 4273, 129, 393, 524, 813, 0, 5, 2, 7, 3, 58, 2, 8, 3, 14, 2, 6, 3, 0, 2, 9, 3, 81, 2, 10, 3, 297, 2, 11, 3, 188, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [954, 0, 5036, 476, 23, 958, 30, 5, 2, 7, 3, 22, 2, 8, 3, 12, 2, 6, 3, 0, 2, 9, 3, 54, 4, 23, 2, 10, 3, 36, 356, 2, 11, 3, 2686, 87, 481, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [15, 307, 191, 5, 2806, 0, 0, 2575, 1744, 0, 655, 219, 353, 20, 344, 382, 4784, 5, 2, 7, 3, 13, 2, 8, 3, 17, 2, 6, 3, 267, 2, 9, 3, 56, 2, 10, 3, 414, 184, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1]\n",
            "VALID SPLIT: 1284 overall samples: torch.Size([1284, 49])\n",
            "\n",
            "{'Baseline': {'Accuracy': 0.6728971962616822,\n",
            "              'Macro F1': 0.4022346368715084,\n",
            "              'Macro Precision': 0.3364485981308411,\n",
            "              'Macro Recall': 0.5,\n",
            "              'Micro F1': 0.6728971962616822,\n",
            "              'Micro Precision': 0.6728971962616822,\n",
            "              'Micro Recall': 0.6728971962616822,\n",
            "              'Per-Class F1': {'false': 0.8044692737430168, 'true': 0.0},\n",
            "              'Per-Class Precision': {'false': 0.6728971962616822, 'true': 0.0},\n",
            "              'Per-Class Recall': {'false': 1.0, 'true': 0.0}},\n",
            " 'Model': {'Accuracy': 0.6487538940809969,\n",
            "           'Macro F1': 0.5838738954316844,\n",
            "           'Macro Precision': 0.5896721148006128,\n",
            "           'Macro Recall': 0.5817791005291005,\n",
            "           'Micro F1': 0.6487538940809969,\n",
            "           'Micro Precision': 0.6487538940809969,\n",
            "           'Micro Recall': 0.6487538940809969,\n",
            "           'Per-Class F1': {'false': 0.7481853713009492,\n",
            "                            'true': 0.4195624195624196},\n",
            "           'Per-Class Precision': {'false': 0.7227615965480043,\n",
            "                                   'true': 0.4565826330532213},\n",
            "           'Per-Class Recall': {'false': 0.7754629629629629,\n",
            "                                'true': 0.3880952380952381}},\n",
            " 'Random': {'Accuracy': 0.4984423676012461,\n",
            "            'Macro F1': 0.48090598633989556,\n",
            "            'Macro Precision': 0.4946694888923412,\n",
            "            'Macro Recall': 0.4939484126984127,\n",
            "            'Micro F1': 0.4984423676012461,\n",
            "            'Micro Precision': 0.4984423676012461,\n",
            "            'Micro Recall': 0.4984423676012461,\n",
            "            'Per-Class F1': {'false': 0.5763157894736842,\n",
            "                             'true': 0.38549618320610685},\n",
            "            'Per-Class Precision': {'false': 0.6676829268292683,\n",
            "                                    'true': 0.321656050955414},\n",
            "            'Per-Class Recall': {'false': 0.5069444444444444,\n",
            "                                 'true': 0.48095238095238096}}}\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1267 entries, 0 to 1266\n",
            "Data columns (total 14 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   id                    1267 non-null   object\n",
            " 1   label                 1267 non-null   object\n",
            " 2   claim                 1267 non-null   object\n",
            " 3   subject               1267 non-null   object\n",
            " 4   speaker               1267 non-null   object\n",
            " 5   speaker_job_title     942 non-null    object\n",
            " 6   state_info            1005 non-null   object\n",
            " 7   party_affiliation     1267 non-null   object\n",
            " 8   barely_true_counts    1267 non-null   int64 \n",
            " 9   false_counts          1267 non-null   int64 \n",
            " 10  half_true_counts      1267 non-null   int64 \n",
            " 11  mostly_true_counts    1267 non-null   int64 \n",
            " 12  pants_on_fire_counts  1267 non-null   int64 \n",
            " 13  context               1250 non-null   object\n",
            "dtypes: int64(5), object(9)\n",
            "memory usage: 138.7+ KB\n",
            "\n",
            "Data peek:\n",
            "            id        label  \\\n",
            "0   11972.json         true   \n",
            "1   11685.json        false   \n",
            "2   11096.json        false   \n",
            "3    5209.json    half-true   \n",
            "4    9524.json   pants-fire   \n",
            "5    5962.json         true   \n",
            "6    7070.json         true   \n",
            "7    1046.json  barely-true   \n",
            "8   12849.json         true   \n",
            "9   13270.json  barely-true   \n",
            "10   6649.json  barely-true   \n",
            "11   2508.json  barely-true   \n",
            "12  11269.json   pants-fire   \n",
            "13  11200.json        false   \n",
            "14   8047.json    half-true   \n",
            "15   4888.json         true   \n",
            "16   3331.json   pants-fire   \n",
            "17   9198.json    half-true   \n",
            "18     73.json         true   \n",
            "19   1328.json        false   \n",
            "\n",
            "                                                claim  \\\n",
            "0   Building a wall on the U.S.-Mexico border will...   \n",
            "1   Wisconsin is on pace to double the number of l...   \n",
            "2   Says John McCain has done nothing to help the ...   \n",
            "3   Suzanne Bonamici supports a plan that will cut...   \n",
            "4   When asked by a reporter whether hes at the ce...   \n",
            "5   Over the past five years the federal governmen...   \n",
            "6   Says that Tennessee law requires that schools ...   \n",
            "7   Says Vice President Joe Biden \"admits that the...   \n",
            "8   Donald Trump is against marriage equality. He ...   \n",
            "9   We know that more than half of Hillary Clinton...   \n",
            "10  We know there are more Democrats in Georgia th...   \n",
            "11  PolitiFact Texas says Congressman Edwards atta...   \n",
            "12         Denali is the Kenyan word for black power.   \n",
            "13  Says 57 percent of federal spending goes to th...   \n",
            "14       On residency requirements for public workers   \n",
            "15  Says the unemployment rate for college graduat...   \n",
            "16  Unfortunately we have documented instances whe...   \n",
            "17  A recent Gallup poll found that 72 percent of ...   \n",
            "18  Each year, 18,000 people die in America becaus...   \n",
            "19  Ronald Reagan faced an even worse recession th...   \n",
            "\n",
            "                                              subject  \\\n",
            "0                                         immigration   \n",
            "1                                                jobs   \n",
            "2                     military,veterans,voting-record   \n",
            "3   medicare,message-machine-2012,campaign-adverti...   \n",
            "4   campaign-finance,legal-issues,campaign-adverti...   \n",
            "5                  federal-budget,pensions,retirement   \n",
            "6     county-budget,county-government,education,taxes   \n",
            "7                                    economy,stimulus   \n",
            "8                          gays-and-lesbians,marriage   \n",
            "9                                      foreign-policy   \n",
            "10                                          elections   \n",
            "11                             ethics,message-machine   \n",
            "12                                        environment   \n",
            "13                    federal-budget,military,poverty   \n",
            "14           city-government,county-government,unions   \n",
            "15                                     education,jobs   \n",
            "16                                 labor,state-budget   \n",
            "17  government-efficiency,government-regulation,polls   \n",
            "18                                        health-care   \n",
            "19                                    economy,history   \n",
            "\n",
            "                             speaker  \\\n",
            "0                         rick-perry   \n",
            "1                  katrina-shankland   \n",
            "2                       donald-trump   \n",
            "3                      rob-cornilles   \n",
            "4   state-democratic-party-wisconsin   \n",
            "5                    brendan-doherty   \n",
            "6           stand-children-tennessee   \n",
            "7                       john-boehner   \n",
            "8               sean-patrick-maloney   \n",
            "9                         mike-pence   \n",
            "10                       mike-berlon   \n",
            "11                       bill-flores   \n",
            "12                       viral-image   \n",
            "13                    facebook-posts   \n",
            "14                       chris-abele   \n",
            "15                     rick-santorum   \n",
            "16                       tom-niehaus   \n",
            "17                  marsha-blackburn   \n",
            "18                   hillary-clinton   \n",
            "19                       sarah-palin   \n",
            "\n",
            "                             speaker_job_title    state_info  \\\n",
            "0                                     Governor         Texas   \n",
            "1                         State representative     Wisconsin   \n",
            "2                              President-Elect      New York   \n",
            "3                                   consultant        Oregon   \n",
            "4                                          NaN     Wisconsin   \n",
            "5                                          NaN  Rhode Island   \n",
            "6   Child and education advocacy organization.     Tennessee   \n",
            "7      Speaker of the House of Representatives          Ohio   \n",
            "8                        Congressman for NY-18      New York   \n",
            "9                                     Governor       Indiana   \n",
            "10                                         NaN       Georgia   \n",
            "11                                 Businessman         Texas   \n",
            "12                                         NaN           NaN   \n",
            "13                        Social media posting           NaN   \n",
            "14                              Philanthropist     Wisconsin   \n",
            "15                                         NaN  Pennsylvania   \n",
            "16                President of the Ohio Senate          Ohio   \n",
            "17                         U.S. Representative     Tennessee   \n",
            "18                      Presidential candidate      New York   \n",
            "19                                         NaN        Alaska   \n",
            "\n",
            "   party_affiliation  barely_true_counts  false_counts  half_true_counts  \\\n",
            "0         republican                  30            30                42   \n",
            "1           democrat                   2             1                 0   \n",
            "2         republican                  63           114                51   \n",
            "3         republican                   1             1                 3   \n",
            "4           democrat                   5             7                 2   \n",
            "5         republican                   1             2                 1   \n",
            "6               none                   0             0                 0   \n",
            "7         republican                  13            22                11   \n",
            "8           democrat                   0             0                 0   \n",
            "9         republican                   8            10                12   \n",
            "10          democrat                   1             0                 0   \n",
            "11        republican                   2             0                 0   \n",
            "12              none                   5             5                 0   \n",
            "13              none                  14            18                15   \n",
            "14              none                   3             5                 4   \n",
            "15        republican                  12            16                13   \n",
            "16        republican                   0             0                 0   \n",
            "17        republican                   2             2                 1   \n",
            "18          democrat                  40            29                69   \n",
            "19        republican                   9            19                 9   \n",
            "\n",
            "    mostly_true_counts  pants_on_fire_counts  \\\n",
            "0                   23                    18   \n",
            "1                    0                     0   \n",
            "2                   37                    61   \n",
            "3                    1                     1   \n",
            "4                    2                     7   \n",
            "5                    1                     0   \n",
            "6                    0                     0   \n",
            "7                    4                     2   \n",
            "8                    0                     0   \n",
            "9                    5                     0   \n",
            "10                   0                     0   \n",
            "11                   0                     0   \n",
            "12                   3                    15   \n",
            "13                  11                    36   \n",
            "14                   4                     2   \n",
            "15                   7                     5   \n",
            "16                   0                     1   \n",
            "17                   0                     0   \n",
            "18                  76                     7   \n",
            "19                   6                     6   \n",
            "\n",
            "                                            context  \n",
            "0                                   Radio interview  \n",
            "1                                 a news conference  \n",
            "2                      comments on ABC's This Week.  \n",
            "3                                      a radio show  \n",
            "4                                       a web video  \n",
            "5                                a campaign website  \n",
            "6                            in a post on Facebook.  \n",
            "7                                  a press release.  \n",
            "8    a speech at the Democratic National Convention  \n",
            "9                      comments on \"Meet the Press\"  \n",
            "10                                       an article  \n",
            "11                                         a TV ad.  \n",
            "12                      an image shared on Facebook  \n",
            "13                           a meme on social media  \n",
            "14                                         a letter  \n",
            "15                                         a speech  \n",
            "16                        interviews with reporters  \n",
            "17  a speech to the Freedom Summit in New Hampshire  \n",
            "18                    a speech in Des Moines, Iowa.  \n",
            "19                            her book, Going Rogue  \n",
            "\n",
            "Tokenized sentences(1267 sentences, 55177 total tokens) peek:\n",
            "  ['building', 'wall', 'u.s.-mexico', 'border', 'take', 'literally', 'years', '.', '|', 'state_info', ':', 'texas', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'rick-perry', '|', 'subject', ':', 'immigration', '|', 'context', ':', 'radio', 'interview', '|', 'speaker_job_title', ':', 'governor', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['wisconsin', 'pace', 'double', 'number', 'layoffs', 'year', '.', '|', 'state_info', ':', 'wisconsin', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'katrina-shankland', '|', 'subject', ':', 'jobs', '|', 'context', ':', 'news', 'conference', '|', 'speaker_job_title', ':', 'state', 'representative', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['says', 'john', 'mccain', 'done', 'nothing', 'help', 'vets', '.', '|', 'state_info', ':', 'new', 'york', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'donald-trump', '|', 'subject', ':', 'military', ',', 'veterans', ',', 'voting-record', '|', 'context', ':', 'comments', 'abc', \"'s\", 'week', '.', '|', 'speaker_job_title', ':', 'president-elect', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['suzanne', 'bonamici', 'supports', 'plan', 'cut', 'choice', 'medicare', 'advantage', 'seniors', '.', '|', 'state_info', ':', 'oregon', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'rob-cornilles', '|', 'subject', ':', 'medicare', ',', 'message-machine-2012', ',', 'campaign-advertising', '|', 'context', ':', 'radio', 'show', '|', 'speaker_job_title', ':', 'consultant', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['asked', 'reporter', 'whether', 'hes', 'center', 'criminal', 'scheme', 'violate', 'campaign', 'laws', ',', 'gov', '.', 'scott', 'walker', 'nodded', 'yes', '.', '|', 'state_info', ':', 'wisconsin', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'state-democratic-party-wisconsin', '|', 'subject', ':', 'campaign-finance', ',', 'legal-issues', ',', 'campaign-advertising', '|', 'context', ':', 'web', 'video', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>']\n",
            "  ['past', 'five', 'years', 'federal', 'government', 'paid', '$', '601', 'million', 'retirement', 'disability', 'benefits', 'deceased', 'former', 'federal', 'employees', '.', '|', 'state_info', ':', 'rhode', 'island', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'brendan-doherty', '|', 'subject', ':', 'federal-budget', ',', 'pensions', ',', 'retirement', '|', 'context', ':', 'campaign', 'website', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>']\n",
            "  ['says', 'tennessee', 'law', 'requires', 'schools', 'receive', 'half', 'proceeds', '--', '$', '31', 'million', 'per', 'year', '--', 'half-cent', 'increase', 'shelby', 'county', 'sales', 'tax', '.', '|', 'state_info', ':', 'tennessee', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'stand-children-tennessee', '|', 'subject', ':', 'county-budget', ',', 'county-government', ',', 'education', ',', 'taxes', '|', 'context', ':', 'post', 'facebook']\n",
            "  ['says', 'vice', 'president', 'joe', 'biden', '``', 'admits', 'american', 'people', 'scammed', \"''\", 'economic', 'stimulus', 'package', '.', '|', 'state_info', ':', 'ohio', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'john-boehner', '|', 'subject', ':', 'economy', ',', 'stimulus', '|', 'context', ':', 'press', 'release', '.', '|', 'speaker_job_title', ':', 'speaker', 'house', 'representatives', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['donald', 'trump', 'marriage', 'equality', '.', 'wants', 'go', 'back', '.', '|', 'state_info', ':', 'new', 'york', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'sean-patrick-maloney', '|', 'subject', ':', 'gays-and-lesbians', ',', 'marriage', '|', 'context', ':', 'speech', 'democratic', 'national', 'convention', '|', 'speaker_job_title', ':', 'congressman', 'ny-18', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['know', 'half', 'hillary', 'clintons', 'meetings', 'secretary', 'state', 'given', 'major', 'contributors', 'clinton', 'foundation', '.', '|', 'state_info', ':', 'indiana', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'mike-pence', '|', 'subject', ':', 'foreign-policy', '|', 'context', ':', 'comments', '``', 'meet', 'press', \"''\", '|', 'speaker_job_title', ':', 'governor', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['know', 'democrats', 'georgia', 'republicans', '.', 'know', 'fact', '.', '|', 'state_info', ':', 'georgia', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'mike-berlon', '|', 'subject', ':', 'elections', '|', 'context', ':', 'article', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['politifact', 'texas', 'says', 'congressman', 'edwards', 'attacks', 'bill', 'flores', 'false', '.', '|', 'state_info', ':', 'texas', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'bill-flores', '|', 'subject', ':', 'ethics', ',', 'message-machine', '|', 'context', ':', 'tv', 'ad', '.', '|', 'speaker_job_title', ':', 'businessman', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['denali', 'kenyan', 'word', 'black', 'power', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'viral-image', '|', 'subject', ':', 'environment', '|', 'context', ':', 'image', 'shared', 'facebook', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['says', '57', 'percent', 'federal', 'spending', 'goes', 'military', '1', 'percent', 'goes', 'food', 'agriculture', ',', 'including', 'food', 'stamps', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'facebook-posts', '|', 'subject', ':', 'federal-budget', ',', 'military', ',', 'poverty', '|', 'context', ':', 'meme', 'social', 'media', '|', 'speaker_job_title', ':', 'social', 'media', 'posting']\n",
            "  ['residency', 'requirements', 'public', 'workers', '|', 'state_info', ':', 'wisconsin', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'chris-abele', '|', 'subject', ':', 'city-government', ',', 'county-government', ',', 'unions', '|', 'context', ':', 'letter', '|', 'speaker_job_title', ':', 'philanthropist', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['says', 'unemployment', 'rate', 'college', 'graduates', '4.4', 'percent', '10', 'percent', 'noncollege-educated', '.', '|', 'state_info', ':', 'pennsylvania', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'rick-santorum', '|', 'subject', ':', 'education', ',', 'jobs', '|', 'context', ':', 'speech', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['unfortunately', 'documented', 'instances', 'people', 'defecated', '(', 'statehouse', ')', 'building', '.', '|', 'state_info', ':', 'ohio', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'tom-niehaus', '|', 'subject', ':', 'labor', ',', 'state-budget', '|', 'context', ':', 'interviews', 'reporters', '|', 'speaker_job_title', ':', 'president', 'ohio', 'senate', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['recent', 'gallup', 'poll', 'found', '72', 'percent', 'americans', '56', 'percent', 'democrats', 'say', 'biggest', 'threat', 'nations', 'security', 'big', 'government', '.', '|', 'state_info', ':', 'tennessee', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'marsha-blackburn', '|', 'subject', ':', 'government-efficiency', ',', 'government-regulation', ',', 'polls', '|', 'context', ':', 'speech', 'freedom', 'summit', 'new', 'hampshire', '|', 'speaker_job_title', ':']\n",
            "  ['year', ',', '18,000', 'people', 'die', 'america', 'health', 'care', '.', '|', 'state_info', ':', 'new', 'york', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'hillary-clinton', '|', 'subject', ':', 'health-care', '|', 'context', ':', 'speech', 'des', 'moines', ',', 'iowa', '.', '|', 'speaker_job_title', ':', 'presidential', 'candidate', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['ronald', 'reagan', 'faced', 'even', 'worse', 'recession', 'current', 'one', '.', '|', 'state_info', ':', 'alaska', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'sarah-palin', '|', 'subject', ':', 'economy', ',', 'history', '|', 'context', ':', 'book', ',', 'going', 'rogue', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "\n",
            "10000 unique tokens\n",
            "Unique tokens peek:\n",
            "  <PAD>\n",
            "  |\n",
            "  :\n",
            "  ,\n",
            "  .\n",
            "  speaker\n",
            "  state_info\n",
            "  party_affiliation\n",
            "  subject\n",
            "  context\n",
            "  speaker_job_title\n",
            "  republican\n",
            "  nan\n",
            "  democrat\n",
            "  says\n",
            "  u.s.\n",
            "  none\n",
            "  interview\n",
            "  new\n",
            "  state\n",
            "\n",
            "Final Index Sets(Set_Size = 49, 1267 index sets) peek:\n",
            "  [906, 494, 2122, 409, 344, 2143, 59, 5, 2, 7, 3, 21, 2, 8, 3, 12, 2, 6, 3, 268, 2, 9, 3, 56, 2, 10, 3, 92, 18, 2, 11, 3, 35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [34, 2818, 1070, 303, 3051, 64, 5, 2, 7, 3, 34, 2, 8, 3, 14, 2, 6, 3, 0, 2, 9, 3, 29, 2, 10, 3, 40, 125, 2, 11, 3, 20, 62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [15, 238, 314, 645, 599, 544, 8812, 5, 2, 7, 3, 19, 45, 2, 8, 3, 12, 2, 6, 3, 132, 2, 9, 3, 82, 4, 273, 4, 185, 2, 10, 3, 118, 220, 41, 162, 5, 2, 11, 3, 155, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [7588, 7589, 516, 128, 145, 1546, 86, 1994, 699, 5, 2, 7, 3, 104, 2, 8, 3, 12, 2, 6, 3, 3126, 2, 9, 3, 86, 4, 142, 4, 550, 2, 10, 3, 92, 135, 2, 11, 3, 764, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [842, 1947, 568, 729, 924, 895, 2110, 6882, 36, 554, 4, 191, 5, 178, 358, 0, 2672, 5, 2, 7, 3, 34, 2, 8, 3, 14, 2, 6, 3, 1484, 2, 9, 3, 197, 4, 105, 4, 550, 2, 10, 3, 199, 187, 2, 11, 3, 13, 1, 1]\n",
            "  [387, 278, 59, 96, 110, 327, 26, 0, 71, 380, 1055, 520, 0, 111, 96, 397, 5, 2, 7, 3, 72, 74, 2, 8, 3, 12, 2, 6, 3, 3660, 2, 9, 3, 48, 4, 577, 4, 380, 2, 10, 3, 36, 150, 2, 11, 3, 13, 1, 1]\n",
            "  [15, 412, 109, 1630, 279, 858, 272, 0, 157, 26, 3401, 71, 241, 64, 157, 0, 243, 3893, 87, 623, 51, 5, 2, 7, 3, 412, 2, 8, 3, 17, 2, 6, 3, 0, 2, 9, 3, 649, 4, 672, 4, 39, 4, 23, 2, 10, 3, 106, 236]\n",
            "  [15, 725, 28, 466, 1647, 24, 2688, 161, 60, 0, 27, 365, 131, 1897, 5, 2, 7, 3, 43, 2, 8, 3, 12, 2, 6, 3, 675, 2, 9, 3, 25, 4, 131, 2, 10, 3, 50, 53, 5, 2, 11, 3, 6, 49, 190, 1, 1, 1, 1]\n",
            "  [259, 225, 370, 3357, 5, 321, 284, 382, 5, 2, 7, 3, 19, 45, 2, 8, 3, 14, 2, 6, 3, 0, 2, 9, 3, 339, 4, 370, 2, 10, 3, 33, 117, 102, 218, 2, 11, 3, 188, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [390, 272, 170, 992, 1953, 305, 20, 718, 564, 6953, 130, 828, 5, 2, 7, 3, 637, 2, 8, 3, 12, 2, 6, 3, 1133, 2, 9, 3, 76, 2, 10, 3, 118, 24, 248, 50, 27, 2, 11, 3, 35, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [390, 239, 58, 262, 5, 390, 635, 5, 2, 7, 3, 58, 2, 8, 3, 14, 2, 6, 3, 0, 2, 9, 3, 55, 2, 10, 3, 249, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [1875, 21, 15, 188, 6973, 1042, 80, 6813, 2632, 5, 2, 7, 3, 21, 2, 8, 3, 12, 2, 6, 3, 8924, 2, 9, 3, 200, 4, 193, 2, 10, 3, 78, 42, 5, 2, 11, 3, 758, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [0, 0, 1622, 662, 627, 5, 2, 7, 3, 13, 2, 8, 3, 17, 2, 6, 3, 1541, 2, 9, 3, 101, 2, 10, 3, 3769, 2611, 236, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [15, 2566, 30, 96, 166, 959, 82, 165, 30, 959, 539, 377, 4, 510, 539, 1282, 5, 2, 7, 3, 13, 2, 8, 3, 17, 2, 6, 3, 471, 2, 9, 3, 48, 4, 82, 4, 159, 2, 10, 3, 859, 143, 244, 2, 11, 3, 143, 244, 394]\n",
            "  [3988, 3125, 126, 88, 2, 7, 3, 34, 2, 8, 3, 17, 2, 6, 3, 1832, 2, 9, 3, 271, 4, 672, 4, 347, 2, 10, 3, 297, 2, 11, 3, 1753, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [15, 210, 141, 257, 2030, 0, 30, 151, 30, 0, 5, 2, 7, 3, 350, 2, 8, 3, 12, 2, 6, 3, 740, 2, 9, 3, 39, 4, 29, 2, 10, 3, 33, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [0, 4277, 4564, 60, 0, 37, 4819, 38, 906, 5, 2, 7, 3, 43, 2, 8, 3, 12, 2, 6, 3, 9108, 2, 9, 3, 147, 4, 52, 2, 10, 3, 1599, 449, 2, 11, 3, 28, 43, 66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [572, 6641, 872, 695, 3009, 30, 152, 2561, 30, 239, 398, 832, 1660, 506, 182, 556, 110, 5, 2, 7, 3, 412, 2, 8, 3, 12, 2, 6, 3, 4655, 2, 9, 3, 250, 4, 211, 4, 245, 2, 10, 3, 33, 1235, 1172, 19, 216, 2, 11, 3]\n",
            "  [64, 4, 3610, 60, 1117, 163, 57, 68, 5, 2, 7, 3, 19, 45, 2, 8, 3, 14, 2, 6, 3, 153, 2, 9, 3, 31, 2, 10, 3, 33, 1446, 1504, 4, 307, 5, 2, 11, 3, 70, 75, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [774, 585, 2537, 156, 1591, 1340, 677, 77, 5, 2, 7, 3, 416, 2, 8, 3, 12, 2, 6, 3, 660, 2, 9, 3, 25, 4, 63, 2, 10, 3, 724, 4, 228, 8110, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "TEST SPLIT: 1267 overall samples: torch.Size([1267, 49])\n",
            "\n",
            "{'Baseline': {'Accuracy': 0.6456195737963694,\n",
            "              'Macro F1': 0.39232613908872904,\n",
            "              'Macro Precision': 0.3228097868981847,\n",
            "              'Macro Recall': 0.5,\n",
            "              'Micro F1': 0.6456195737963694,\n",
            "              'Micro Precision': 0.6456195737963694,\n",
            "              'Micro Recall': 0.6456195737963694,\n",
            "              'Per-Class F1': {'false': 0.7846522781774581, 'true': 0.0},\n",
            "              'Per-Class Precision': {'false': 0.6456195737963694, 'true': 0.0},\n",
            "              'Per-Class Recall': {'false': 1.0, 'true': 0.0}},\n",
            " 'Model': {'Accuracy': 0.6124704025256511,\n",
            "           'Macro F1': 0.5456137749590423,\n",
            "           'Macro Precision': 0.5558066490561175,\n",
            "           'Macro Recall': 0.5471667547007476,\n",
            "           'Micro F1': 0.6124704025256511,\n",
            "           'Micro Precision': 0.6124704025256511,\n",
            "           'Micro Recall': 0.6124704025256511,\n",
            "           'Per-Class F1': {'false': 0.7199087278950371,\n",
            "                            'true': 0.3713188220230474},\n",
            "           'Per-Class Precision': {'false': 0.6748663101604279,\n",
            "                                   'true': 0.4367469879518072},\n",
            "           'Per-Class Recall': {'false': 0.7713936430317848,\n",
            "                                'true': 0.32293986636971045}},\n",
            " 'Random': {'Accuracy': 0.5011838989739542,\n",
            "            'Macro F1': 0.4919291798219344,\n",
            "            'Macro Precision': 0.504289026275116,\n",
            "            'Macro Recall': 0.5046844114331768,\n",
            "            'Micro F1': 0.5011838989739542,\n",
            "            'Micro Precision': 0.5011838989739542,\n",
            "            'Micro Recall': 0.5011838989739542,\n",
            "            'Per-Class F1': {'false': 0.5605006954102921,\n",
            "                             'true': 0.4233576642335766},\n",
            "            'Per-Class Precision': {'false': 0.65, 'true': 0.35857805255023184},\n",
            "            'Per-Class Recall': {'false': 0.49266503667481665,\n",
            "                                 'true': 0.5167037861915368}}}\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import nltk\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.optim as optim\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import pprint\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Hyperopt imports\n",
        "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
        "from hyperopt.pyll import scope\n",
        "\n",
        "random.seed(184)\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "peek = 20\n",
        "\n",
        "def present_list_like(name, list_like, peek=peek):\n",
        "    print(f\"{name} peek:\")\n",
        "    print('  ' + '\\n  '.join(str(v) for v in list_like[:peek]))\n",
        "\n",
        "columns = [\n",
        "    'id', 'label', 'claim', 'subject', 'speaker', 'speaker_job_title', 'state_info',\n",
        "    'party_affiliation', 'barely_true_counts', 'false_counts',\n",
        "    'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context'\n",
        "]\n",
        "present_list_like(f\"Dataset columns({len(columns)} in total)\", columns, len(columns))\n",
        "\n",
        "def load_data(split):\n",
        "    df = pd.read_csv(f\"./data/{split}.tsv\", sep='\\t', names=columns)\n",
        "    df = df.drop(index=[\n",
        "        idx for idx in df.index if type(df[\"claim\"][idx]) == type(None) or not len(df[\"claim\"][idx])\n",
        "    ])\n",
        "    print(\"The training dataset:\")\n",
        "    df.info()\n",
        "    print(\"\\nData peek:\")\n",
        "    print(df.head(peek))\n",
        "    print()\n",
        "    return df\n",
        "\n",
        "pad_tkn = \"<PAD>\"\n",
        "\n",
        "def tokenize_text(input_text, known_vector_size=None, token_to_idx={}):\n",
        "    def preprocess_text(text) -> str:\n",
        "        # Letter-level cleaning\n",
        "        text = text.lower()\n",
        "        valid_asciis = {9, *range(32, 127)}\n",
        "        text = ''.join(filter(lambda x: ord(x) in valid_asciis, text))\n",
        "\n",
        "        # Word/sequence-level cleaning\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = re.sub(r'http\\S+', '', text)\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        text = ' '.join(word for word in text.split() if word not in stop_words)\n",
        "        return text\n",
        "\n",
        "    # Preprocess the text\n",
        "    for i in range(len(input_text)):\n",
        "        input_text[i] = preprocess_text(input_text[i])\n",
        "\n",
        "    # Tokenize\n",
        "    final_tokens = input_tokens = [nltk.word_tokenize(text) for text in input_text]\n",
        "    total_tokens = sum(len(tkns) for tkns in final_tokens)\n",
        "\n",
        "    # Make all token sets the same length\n",
        "    forced_tkn_set_size = (\n",
        "        known_vector_size if known_vector_size\n",
        "        else int(np.percentile([len(tkns) for tkns in final_tokens], 80))\n",
        "    )\n",
        "    final_tokens = [\n",
        "        tkns[:forced_tkn_set_size] + [pad_tkn] * (forced_tkn_set_size - len(tkns))\n",
        "        for tkns in final_tokens\n",
        "    ]\n",
        "\n",
        "    # Present results\n",
        "    present_list_like(\n",
        "        f\"Tokenized sentences({len(final_tokens)} sentences, {total_tokens} total tokens)\",\n",
        "        final_tokens\n",
        "    )\n",
        "\n",
        "    # Index the tokens\n",
        "    # Map each token to its frequency in the dataset\n",
        "    if not len(token_to_idx):\n",
        "        flat_tokens = [word for token_set in final_tokens for word in token_set]\n",
        "        frequencies = Counter(flat_tokens)\n",
        "        token_to_idx = {}\n",
        "        for idx, (word, _) in enumerate(frequencies.most_common()):\n",
        "            if idx >= 10000:\n",
        "                break\n",
        "            token_to_idx[word] = idx + 1\n",
        "        if pad_tkn not in token_to_idx:\n",
        "            token_to_idx[pad_tkn] = len(token_to_idx) + 1\n",
        "    vocab_size = len(token_to_idx)\n",
        "    print()\n",
        "    print(vocab_size, \"unique tokens\")\n",
        "    present_list_like(\"Unique tokens\", list(token_to_idx.keys()))\n",
        "\n",
        "    # Index the tokens\n",
        "    freq_indexed = [\n",
        "        [(token_to_idx[token] if token in token_to_idx else 0) for token in token_set]\n",
        "        for token_set in final_tokens\n",
        "    ]\n",
        "\n",
        "    # Present results\n",
        "    present_list_like(\n",
        "        f\"\\nFinal Index Sets(Set_Size = {forced_tkn_set_size}, {len(freq_indexed)} index sets)\",\n",
        "        freq_indexed\n",
        "    )\n",
        "\n",
        "    return freq_indexed, token_to_idx\n",
        "\n",
        "def get_freq_indexed_and_labels(split, known_vector_size=None, token_to_idx={}):\n",
        "    df = load_data(split)\n",
        "    input_text = df[\"claim\"].to_numpy()\n",
        "    # Augment input text with the other columns\n",
        "    other_cols = {\n",
        "        \"context\",\n",
        "        \"subject\",\n",
        "        \"speaker\",\n",
        "        \"speaker_job_title\",\n",
        "        \"state_info\",\n",
        "        \"party_affiliation\",\n",
        "    }\n",
        "    for i in range(len(input_text)):\n",
        "        extra_data = [f\"{col}: {df[col].values[i]}\" for col in other_cols if df[col].values[i]]\n",
        "        input_text[i] += \" | \\n\" * (len(extra_data) > 0) + \" | \\n\".join(extra_data)\n",
        "    input_labels = df[\"label\"].to_numpy()\n",
        "    # Fuse some labels\n",
        "    input_labels = np.array([\n",
        "        \"false\" if x in (\"false\", \"half-true\", \"barely-true\", \"pants-fire\")\n",
        "        else \"true\" if x in (\"true\", \"mostly-true\")\n",
        "        else x\n",
        "        for x in input_labels\n",
        "    ])\n",
        "    freq_indexed, token_to_idx = tokenize_text(input_text, known_vector_size, token_to_idx)\n",
        "\n",
        "    return freq_indexed, token_to_idx, input_labels\n",
        "\n",
        "def as_tensors(split, label_encoder=None, known_vector_size=None, token_to_idx={}):\n",
        "    freq_indexed, token_to_idx, input_labels = get_freq_indexed_and_labels(split, known_vector_size, token_to_idx)\n",
        "    X = torch.tensor(freq_indexed, dtype=torch.long)\n",
        "    label_encoder_existed = (type(label_encoder) != type(None))\n",
        "    label_encoder = (LabelEncoder() if not label_encoder_existed else label_encoder)\n",
        "    y = (\n",
        "        label_encoder.fit_transform(input_labels) if not label_encoder_existed\n",
        "        else label_encoder.transform(input_labels)\n",
        "    )\n",
        "    y = torch.tensor(y, dtype=torch.long)\n",
        "    print(f\"{split.upper()} SPLIT:\", X.size(0), \"overall samples:\", X.shape)\n",
        "\n",
        "    return X, token_to_idx, label_encoder, input_labels, y\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "X_train, token_to_idx, label_encoder, train_input_labels, y_train = as_tensors(\"train\")\n",
        "X_val, _, _, _, y_val = as_tensors(\"valid\", label_encoder=label_encoder, known_vector_size=X_train.shape[1], token_to_idx=token_to_idx)\n",
        "\n",
        "label_to_idx = {l: i for i, l in enumerate(label_encoder.classes_)}\n",
        "train_vocab_size = len(token_to_idx)\n",
        "input_vector_size = X_train.shape[1]\n",
        "\n",
        "# Use validation set for evaluation during hyperparameter tuning\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "val_dataset = TensorDataset(X_val, y_val)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "train_label_counts = pd.DataFrame({\"label\": train_input_labels})[\"label\"].value_counts(normalize=True)\n",
        "print(train_label_counts.shape[0], \"labels\\n\")\n",
        "print(train_label_counts)\n",
        "\n",
        "# Balance if necessary\n",
        "print(f\"TRAIN SPLIT(pre-balancing):\", X_train.size(0), \"overall samples:\", X_train.shape)\n",
        "X_train, y_train = SMOTE(random_state=42).fit_resample(X_train, y_train)\n",
        "X_train = torch.tensor(X_train, dtype=torch.long)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "print()\n",
        "print(f\"TRAIN SPLIT(post-balancing):\", X_train.size(0), \"overall samples:\", X_train.shape)\n",
        "print(pd.DataFrame({\"label\": [label_encoder.classes_[y] for y in y_train]})[\"label\"].value_counts())\n",
        "\n",
        "def train_model(model, dataloader, optimizer, criterion, device, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        epoch_tps = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(inputs)\n",
        "            loss = criterion(predictions, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()  # Track total loss\n",
        "            # Track total accuracy\n",
        "            _, predicted_classes = torch.max(predictions, 1)\n",
        "            epoch_tps += (predicted_classes == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}/{epochs} | Loss: {epoch_loss/len(dataloader):.4f} | Accuracy: {epoch_tps/total_samples:.4f}\"\n",
        "        )\n",
        "\n",
        "# Define the model\n",
        "class BiLSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        super(BiLSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=token_to_idx[pad_tkn])\n",
        "        self.lstm = nn.LSTM(\n",
        "            embedding_dim, hidden_dim, num_layers=n_layers, batch_first=True, dropout=dropout, bidirectional=True\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # Multiply by 2 for bidirectional\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, (hidden, cell) = self.lstm(embedded)\n",
        "        # Concatenate the final forward and backward hidden states\n",
        "        hidden = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
        "        return self.fc(hidden)\n",
        "\n",
        "# Evaluation functions (modified to return Macro F1 for optimization)\n",
        "def per_class_metrics(labels, predictions, num_classes, label_ordering):\n",
        "    labels = labels.cpu().numpy()\n",
        "    predictions = predictions.cpu().numpy()\n",
        "\n",
        "    precision_per_class = precision_score(\n",
        "        labels, predictions, average=None, labels=np.arange(num_classes), zero_division=0\n",
        "    )\n",
        "    recall_per_class = recall_score(\n",
        "        labels, predictions, average=None, labels=np.arange(num_classes), zero_division=0\n",
        "    )\n",
        "    f1_per_class = f1_score(labels, predictions, average=None, labels=np.arange(num_classes), zero_division=0)\n",
        "\n",
        "    results = []\n",
        "    for metrics in [precision_per_class, recall_per_class, f1_per_class]:\n",
        "        results.append({label_ordering[i]: metrics[i] for i in range(len(metrics))})\n",
        "    return tuple(results)\n",
        "\n",
        "def macro_metrics(labels, predictions):\n",
        "    labels = labels.cpu().numpy()\n",
        "    predictions = predictions.cpu().numpy()\n",
        "\n",
        "    precision_macro = precision_score(labels, predictions, average='macro', zero_division=0)\n",
        "    recall_macro = recall_score(labels, predictions, average='macro', zero_division=0)\n",
        "    f1_macro = f1_score(labels, predictions, average='macro', zero_division=0)\n",
        "\n",
        "    return precision_macro, recall_macro, f1_macro\n",
        "\n",
        "def micro_metrics(labels, predictions):\n",
        "    labels = labels.cpu().numpy()\n",
        "    predictions = predictions.cpu().numpy()\n",
        "\n",
        "    precision_micro = precision_score(labels, predictions, average='micro', zero_division=0)\n",
        "    recall_micro = recall_score(labels, predictions, average='micro', zero_division=0)\n",
        "    f1_micro = f1_score(labels, predictions, average='micro', zero_division=0)\n",
        "\n",
        "    return precision_micro, recall_micro, f1_micro\n",
        "\n",
        "def evaluate(labels, num_classes, model_pred, baseline_pred, random_pred, label_ordering):\n",
        "    results = {}\n",
        "\n",
        "    for pred_type, predictions in [('Model', model_pred), ('Baseline', baseline_pred), ('Random', random_pred)]:\n",
        "        curr_results = results[pred_type] = {}\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = (predictions == labels).sum().item() / labels.size(0)\n",
        "        precision_per_class, recall_per_class, f1_per_class = per_class_metrics(\n",
        "            labels, predictions, num_classes, label_ordering\n",
        "        )\n",
        "        precision_macro, recall_macro, f1_macro = macro_metrics(labels, predictions)\n",
        "        precision_micro, recall_micro, f1_micro = micro_metrics(labels, predictions)\n",
        "\n",
        "        # Save all metrics\n",
        "        curr_results[\"Accuracy\"] = accuracy\n",
        "        curr_results[\"Per-Class Precision\"] = precision_per_class\n",
        "        curr_results[\"Per-Class Recall\"] = recall_per_class\n",
        "        curr_results[\"Per-Class F1\"] = f1_per_class\n",
        "        curr_results[\"Macro Precision\"] = precision_macro\n",
        "        curr_results[\"Macro Recall\"] = recall_macro\n",
        "        curr_results[\"Macro F1\"] = f1_macro\n",
        "        curr_results[\"Micro Precision\"] = precision_micro\n",
        "        curr_results[\"Micro Recall\"] = recall_micro\n",
        "        curr_results[\"Micro F1\"] = f1_micro\n",
        "\n",
        "    return results, f1_macro\n",
        "\n",
        "# Get predictions\n",
        "import typing as tp\n",
        "\n",
        "def get_predictions(\n",
        "    test_loader, model, num_samples,\n",
        "    pred_type: tp.Literal['model', 'baseline', 'random'] = 'model',\n",
        "    device=None,\n",
        "    label_ordering=None, orig_label_counts=None,\n",
        "    num_classes=None\n",
        "):\n",
        "    predictions = []\n",
        "    y_eval = []\n",
        "\n",
        "    if pred_type == 'model':\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in test_loader:\n",
        "                y_eval.extend(batch_y)\n",
        "\n",
        "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "                batch_size = batch_X.size(0)\n",
        "\n",
        "                outputs = model(batch_X)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                predictions.extend(predicted.cpu())\n",
        "        y_eval = torch.tensor(y_eval, dtype=torch.long)\n",
        "    elif pred_type == 'baseline':\n",
        "        orig_label_counts = orig_label_counts.sort_index(key=lambda idx: orig_label_counts[idx], inplace=False, ascending=False)\n",
        "        majority_class = list(label_ordering).index(orig_label_counts.index[0])\n",
        "        predictions += [majority_class for _ in range(num_samples)]\n",
        "    else:\n",
        "        predictions += [random.randint(0, num_classes - 1) for _ in range(num_samples)]\n",
        "\n",
        "    predictions = torch.tensor(predictions, dtype=torch.long)\n",
        "    if pred_type == 'model':\n",
        "        return predictions, y_eval\n",
        "    return predictions\n",
        "\n",
        "# Hyperparameter space\n",
        "space = {\n",
        "    'embedding_dim': scope.int(hp.quniform('embedding_dim', 50, 500, 50)),\n",
        "    'hidden_dim': scope.int(hp.quniform('hidden_dim', 32, 256, 32)),\n",
        "    'n_layers': scope.int(hp.quniform('n_layers', 1, 3, 1)),\n",
        "    'dropout': hp.uniform('dropout', 0.1, 0.7),\n",
        "    'learning_rate': hp.loguniform('learning_rate', -6, -2),  # 0.002 - 0.01\n",
        "}\n",
        "\n",
        "# Objective function for Hyperopt\n",
        "def objective(params):\n",
        "    print(\"Training with params:\")\n",
        "    print(params)\n",
        "\n",
        "    # Create model\n",
        "    model = BiLSTMModel(\n",
        "        input_dim=train_vocab_size + 1,\n",
        "        embedding_dim=params['embedding_dim'],\n",
        "        hidden_dim=params['hidden_dim'],\n",
        "        output_dim=train_label_counts.shape[0],\n",
        "        n_layers=params['n_layers'],\n",
        "        dropout=params['dropout']\n",
        "    )\n",
        "    model.to(device)\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=params['learning_rate'])\n",
        "\n",
        "    # Loss function (consider class weights if imbalanced)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    criterion.to(device)\n",
        "\n",
        "    # Train\n",
        "    train_model(model, train_loader, optimizer, criterion, device, epochs=10)\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    model_pred, labels = get_predictions(val_loader, model, y_val.size(0), pred_type='model', device=device)\n",
        "    baseline_pred = get_predictions(\n",
        "        val_loader, model, y_val.size(0), pred_type='baseline',\n",
        "        label_ordering=label_encoder.classes_, orig_label_counts=train_label_counts\n",
        "    )\n",
        "    random_pred = get_predictions(val_loader, model, y_val.size(0), pred_type='random', num_classes=train_label_counts.shape[0])\n",
        "\n",
        "    _, f1_macro = evaluate(labels, train_label_counts.shape[0], model_pred, baseline_pred, random_pred, label_encoder.classes_)\n",
        "\n",
        "    # Hyperopt minimizes the objective, so return negative F1 Macro\n",
        "    return {'loss': -f1_macro, 'status': STATUS_OK}\n",
        "\n",
        "# Move model to GPU if possible\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if torch.cuda.is_available():\n",
        "    num_gpus = torch.cuda.device_count()\n",
        "    print(f\"Number of available GPUs: {num_gpus}\")\n",
        "    for i in range(num_gpus):\n",
        "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "    t4_available = any(\"t4\" in torch.cuda.get_device_name(i).lower() for i in range(num_gpus))\n",
        "    print(f\"Is a T4 GPU available? {t4_available}\")\n",
        "    device = torch.device('cuda:0')\n",
        "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"No GPU available, using CPU.\")\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "# Run hyperparameter optimization\n",
        "trials = Trials()\n",
        "best = fmin(fn=objective,\n",
        "            space=space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=50,\n",
        "            trials=trials)\n",
        "\n",
        "print(\"Best hyperparameters found:\")\n",
        "print(best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuhOBWlmuqty",
        "outputId": "cdee2941-1584-4366-9073-7e8eed4eaca7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset columns(14 in total) peek:\n",
            "  id\n",
            "  label\n",
            "  claim\n",
            "  subject\n",
            "  speaker\n",
            "  speaker_job_title\n",
            "  state_info\n",
            "  party_affiliation\n",
            "  barely_true_counts\n",
            "  false_counts\n",
            "  half_true_counts\n",
            "  mostly_true_counts\n",
            "  pants_on_fire_counts\n",
            "  context\n",
            "The training dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10240 entries, 0 to 10239\n",
            "Data columns (total 14 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   id                    10240 non-null  object \n",
            " 1   label                 10240 non-null  object \n",
            " 2   claim                 10240 non-null  object \n",
            " 3   subject               10238 non-null  object \n",
            " 4   speaker               10238 non-null  object \n",
            " 5   speaker_job_title     7342 non-null   object \n",
            " 6   state_info            8030 non-null   object \n",
            " 7   party_affiliation     10238 non-null  object \n",
            " 8   barely_true_counts    10238 non-null  float64\n",
            " 9   false_counts          10238 non-null  float64\n",
            " 10  half_true_counts      10238 non-null  float64\n",
            " 11  mostly_true_counts    10238 non-null  float64\n",
            " 12  pants_on_fire_counts  10238 non-null  float64\n",
            " 13  context               10138 non-null  object \n",
            "dtypes: float64(5), object(9)\n",
            "memory usage: 1.1+ MB\n",
            "\n",
            "Data peek:\n",
            "            id        label  \\\n",
            "0    2635.json        false   \n",
            "1   10540.json    half-true   \n",
            "2     324.json  mostly-true   \n",
            "3    1123.json        false   \n",
            "4    9028.json    half-true   \n",
            "5   12465.json         true   \n",
            "6    2342.json  barely-true   \n",
            "7     153.json    half-true   \n",
            "8    5602.json    half-true   \n",
            "9    9741.json  mostly-true   \n",
            "10   7115.json  mostly-true   \n",
            "11   4148.json    half-true   \n",
            "12   5947.json        false   \n",
            "13   8616.json  mostly-true   \n",
            "14   8705.json  barely-true   \n",
            "15  10683.json    half-true   \n",
            "16    620.json         true   \n",
            "17   3863.json  barely-true   \n",
            "18  12372.json    half-true   \n",
            "19  12385.json  mostly-true   \n",
            "\n",
            "                                                claim  \\\n",
            "0   Says the Annies List political group supports ...   \n",
            "1   When did the decline of coal start? It started...   \n",
            "2   Hillary Clinton agrees with John McCain \"by vo...   \n",
            "3   Health care reform legislation is likely to ma...   \n",
            "4   The economic turnaround started at the end of ...   \n",
            "5   The Chicago Bears have had more starting quart...   \n",
            "6   Jim Dunnam has not lived in the district he re...   \n",
            "7   I'm the only person on this stage who has work...   \n",
            "8   However, it took $19.5 million in Oregon Lotte...   \n",
            "9   Says GOP primary opponents Glenn Grothman and ...   \n",
            "10  For the first time in history, the share of th...   \n",
            "11  Since 2000, nearly 12 million Americans have s...   \n",
            "12  When Mitt Romney was governor of Massachusetts...   \n",
            "13  The economy bled $24 billion due to the govern...   \n",
            "14  Most of the (Affordable Care Act) has already ...   \n",
            "15  In this last election in November, ... 63 perc...   \n",
            "16  McCain opposed a requirement that the governme...   \n",
            "17  U.S. Rep. Ron Kind, D-Wis., and his fellow Dem...   \n",
            "18  Water rates in Manila, Philippines, were raise...   \n",
            "19  Almost 100,000 people left Puerto Rico last year.   \n",
            "\n",
            "                                      subject  \\\n",
            "0                                    abortion   \n",
            "1          energy,history,job-accomplishments   \n",
            "2                              foreign-policy   \n",
            "3                                 health-care   \n",
            "4                                economy,jobs   \n",
            "5                                   education   \n",
            "6                        candidates-biography   \n",
            "7                                      ethics   \n",
            "8                                        jobs   \n",
            "9   energy,message-machine-2014,voting-record   \n",
            "10                                  elections   \n",
            "11    economy,jobs,new-hampshire-2012,poverty   \n",
            "12                       history,state-budget   \n",
            "13         economy,federal-budget,health-care   \n",
            "14                                health-care   \n",
            "15                                  elections   \n",
            "16                             federal-budget   \n",
            "17                             federal-budget   \n",
            "18  financial-regulation,foreign-policy,water   \n",
            "19              bankruptcy,economy,population   \n",
            "\n",
            "                                        speaker  \\\n",
            "0                                  dwayne-bohac   \n",
            "1                                scott-surovell   \n",
            "2                                  barack-obama   \n",
            "3                                  blog-posting   \n",
            "4                                 charlie-crist   \n",
            "5                                     robin-vos   \n",
            "6                        republican-party-texas   \n",
            "7                                  barack-obama   \n",
            "8                                oregon-lottery   \n",
            "9                                 duey-stroebel   \n",
            "10                              robert-menendez   \n",
            "11                                     bernie-s   \n",
            "12                                  mitt-romney   \n",
            "13                                   doonesbury   \n",
            "14                                  george-will   \n",
            "15                                     bernie-s   \n",
            "16                                 barack-obama   \n",
            "17  national-republican-congressional-committee   \n",
            "18                                   gwen-moore   \n",
            "19                                     jack-lew   \n",
            "\n",
            "                    speaker_job_title         state_info party_affiliation  \\\n",
            "0                State representative              Texas        republican   \n",
            "1                      State delegate           Virginia          democrat   \n",
            "2                           President           Illinois          democrat   \n",
            "3                                 NaN                NaN              none   \n",
            "4                                 NaN            Florida          democrat   \n",
            "5          Wisconsin Assembly speaker          Wisconsin        republican   \n",
            "6                                 NaN              Texas        republican   \n",
            "7                           President           Illinois          democrat   \n",
            "8                                 NaN                NaN      organization   \n",
            "9                State representative          Wisconsin        republican   \n",
            "10                       U.S. Senator         New Jersey          democrat   \n",
            "11                       U.S. Senator            Vermont       independent   \n",
            "12                    Former governor      Massachusetts        republican   \n",
            "13                                NaN                NaN              none   \n",
            "14                          Columnist           Maryland         columnist   \n",
            "15                       U.S. Senator            Vermont       independent   \n",
            "16                          President           Illinois          democrat   \n",
            "17                                NaN                NaN        republican   \n",
            "18  U.S. House member -- 4th District          Wisconsin          democrat   \n",
            "19                Treasury secretary   Washington, D.C.           democrat   \n",
            "\n",
            "    barely_true_counts  false_counts  half_true_counts  mostly_true_counts  \\\n",
            "0                  0.0           1.0               0.0                 0.0   \n",
            "1                  0.0           0.0               1.0                 1.0   \n",
            "2                 70.0          71.0             160.0               163.0   \n",
            "3                  7.0          19.0               3.0                 5.0   \n",
            "4                 15.0           9.0              20.0                19.0   \n",
            "5                  0.0           3.0               2.0                 5.0   \n",
            "6                  3.0           1.0               1.0                 3.0   \n",
            "7                 70.0          71.0             160.0               163.0   \n",
            "8                  0.0           0.0               1.0                 0.0   \n",
            "9                  0.0           0.0               0.0                 1.0   \n",
            "10                 1.0           3.0               1.0                 3.0   \n",
            "11                18.0          12.0              22.0                41.0   \n",
            "12                34.0          32.0              58.0                33.0   \n",
            "13                 0.0           0.0               2.0                 4.0   \n",
            "14                 7.0           6.0               3.0                 5.0   \n",
            "15                18.0          12.0              22.0                41.0   \n",
            "16                70.0          71.0             160.0               163.0   \n",
            "17                18.0           9.0               8.0                 5.0   \n",
            "18                 3.0           4.0               4.0                 3.0   \n",
            "19                 0.0           1.0               0.0                 1.0   \n",
            "\n",
            "    pants_on_fire_counts                                   context  \n",
            "0                    0.0                                  a mailer  \n",
            "1                    0.0                           a floor speech.  \n",
            "2                    9.0                                    Denver  \n",
            "3                   44.0                            a news release  \n",
            "4                    2.0                       an interview on CNN  \n",
            "5                    1.0                 a an online opinion-piece  \n",
            "6                    1.0                          a press release.  \n",
            "7                    9.0  a Democratic debate in Philadelphia, Pa.  \n",
            "8                    1.0                                a website   \n",
            "9                    0.0                           an online video  \n",
            "10                   0.0                                  a speech  \n",
            "11                   0.0                                   a tweet  \n",
            "12                  19.0                an interview with CBN News  \n",
            "13                   0.0   a Doonesbury strip in the Sunday comics  \n",
            "14                   1.0             comments on \"Fox News Sunday\"  \n",
            "15                   0.0              a town hall in Austin, Texas  \n",
            "16                   9.0                                a radio ad  \n",
            "17                   8.0                            a news release  \n",
            "18                   1.0                   a congressional hearing  \n",
            "19                   0.0          an interview with Bloomberg News  \n",
            "\n",
            "Tokenized sentences(10240 sentences, 442958 total tokens) peek:\n",
            "  ['says', 'annies', 'list', 'political', 'group', 'supports', 'third-trimester', 'abortions', 'demand', '.', '|', 'state_info', ':', 'texas', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'dwayne-bohac', '|', 'subject', ':', 'abortion', '|', 'context', ':', 'mailer', '|', 'speaker_job_title', ':', 'state', 'representative', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['decline', 'coal', 'start', '?', 'started', 'natural', 'gas', 'took', 'started', 'begin', '(', 'president', 'george', 'w.', ')', 'bushs', 'administration', '.', '|', 'state_info', ':', 'virginia', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'scott-surovell', '|', 'subject', ':', 'energy', ',', 'history', ',', 'job-accomplishments', '|', 'context', ':', 'floor', 'speech', '.', '|', 'speaker_job_title', ':', 'state', 'delegate']\n",
            "  ['hillary', 'clinton', 'agrees', 'john', 'mccain', '``', 'by', 'voting', 'give', 'george', 'bush', 'benefit', 'doubt', 'iran', '.', \"''\", '|', 'state_info', ':', 'illinois', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'barack-obama', '|', 'subject', ':', 'foreign-policy', '|', 'context', ':', 'denver', '|', 'speaker_job_title', ':', 'president', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['health', 'care', 'reform', 'legislation', 'likely', 'mandate', 'free', 'sex', 'change', 'surgeries', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'blog-posting', '|', 'subject', ':', 'health-care', '|', 'context', ':', 'news', 'release', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['economic', 'turnaround', 'started', 'end', 'term', '.', '|', 'state_info', ':', 'florida', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'charlie-crist', '|', 'subject', ':', 'economy', ',', 'jobs', '|', 'context', ':', 'interview', 'cnn', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['chicago', 'bears', 'starting', 'quarterbacks', 'last', '10', 'years', 'total', 'number', 'tenured', '(', 'uw', ')', 'faculty', 'fired', 'last', 'two', 'decades', '.', '|', 'state_info', ':', 'wisconsin', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'robin-vos', '|', 'subject', ':', 'education', '|', 'context', ':', 'online', 'opinion-piece', '|', 'speaker_job_title', ':', 'wisconsin', 'assembly', 'speaker', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['jim', 'dunnam', 'lived', 'district', 'represents', 'years', 'now', '.', '|', 'state_info', ':', 'texas', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'republican-party-texas', '|', 'subject', ':', 'candidates-biography', '|', 'context', ':', 'press', 'release', '.', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['i', \"'m\", 'person', 'stage', 'worked', 'actively', 'last', 'year', 'passing', ',', 'along', 'russ', 'feingold', ',', 'toughest', 'ethics', 'reform', 'since', 'watergate', '.', '|', 'state_info', ':', 'illinois', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'barack-obama', '|', 'subject', ':', 'ethics', '|', 'context', ':', 'democratic', 'debate', 'philadelphia', ',', 'pa.', '|', 'speaker_job_title', ':', 'president', '<PAD>']\n",
            "  ['however', ',', 'took', '$', '19.5', 'million', 'oregon', 'lottery', 'funds', 'port', 'newport', 'eventually', 'land', 'new', 'noaa', 'marine', 'operations', 'center-pacific', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'organization', '|', 'speaker', ':', 'oregon-lottery', '|', 'subject', ':', 'jobs', '|', 'context', ':', 'website', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['says', 'gop', 'primary', 'opponents', 'glenn', 'grothman', 'joe', 'leibham', 'cast', 'compromise', 'vote', 'cost', '$', '788', 'million', 'higher', 'electricity', 'costs', '.', '|', 'state_info', ':', 'wisconsin', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'duey-stroebel', '|', 'subject', ':', 'energy', ',', 'message-machine-2014', ',', 'voting-record', '|', 'context', ':', 'online', 'video', '|', 'speaker_job_title', ':', 'state', 'representative']\n",
            "  ['first', 'time', 'history', ',', 'share', 'national', 'popular', 'vote', 'margin', 'smaller', 'latino', 'vote', 'margin', '.', '|', 'state_info', ':', 'new', 'jersey', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'robert-menendez', '|', 'subject', ':', 'elections', '|', 'context', ':', 'speech', '|', 'speaker_job_title', ':', 'u.s.', 'senator', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['since', '2000', ',', 'nearly', '12', 'million', 'americans', 'slipped', 'middle', 'class', 'poverty', '.', '|', 'state_info', ':', 'vermont', '|', 'party_affiliation', ':', 'independent', '|', 'speaker', ':', 'bernie-s', '|', 'subject', ':', 'economy', ',', 'jobs', ',', 'new-hampshire-2012', ',', 'poverty', '|', 'context', ':', 'tweet', '|', 'speaker_job_title', ':', 'u.s.', 'senator', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['mitt', 'romney', 'governor', 'massachusetts', ',', 'didnt', 'slow', 'rate', 'growth', 'government', ',', 'actually', 'cut', 'it', '.', '|', 'state_info', ':', 'massachusetts', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'mitt-romney', '|', 'subject', ':', 'history', ',', 'state-budget', '|', 'context', ':', 'interview', 'cbn', 'news', '|', 'speaker_job_title', ':', 'former', 'governor', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['economy', 'bled', '$', '24', 'billion', 'due', 'government', 'shutdown', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'doonesbury', '|', 'subject', ':', 'economy', ',', 'federal-budget', ',', 'health-care', '|', 'context', ':', 'doonesbury', 'strip', 'sunday', 'comics', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['(', 'affordable', 'care', 'act', ')', 'already', 'sense', 'waived', 'otherwise', 'suspended', '.', '|', 'state_info', ':', 'maryland', '|', 'party_affiliation', ':', 'columnist', '|', 'speaker', ':', 'george-will', '|', 'subject', ':', 'health-care', '|', 'context', ':', 'comments', '``', 'fox', 'news', 'sunday', \"''\", '|', 'speaker_job_title', ':', 'columnist', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['last', 'election', 'november', ',', '...', '63', 'percent', 'american', 'people', 'chose', 'vote', ',', '...', '80', 'percent', 'young', 'people', ',', '(', 'and', ')', '75', 'percent', 'low-income', 'workers', 'chose', 'vote', '.', '|', 'state_info', ':', 'vermont', '|', 'party_affiliation', ':', 'independent', '|', 'speaker', ':', 'bernie-s', '|', 'subject', ':', 'elections', '|', 'context', ':', 'town', 'hall']\n",
            "  ['mccain', 'opposed', 'requirement', 'government', 'buy', 'american-made', 'motorcycles', '.', 'said', 'buy-american', 'provisions', 'quote', \"'disgraceful\", '.', \"'\", '|', 'state_info', ':', 'illinois', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'barack-obama', '|', 'subject', ':', 'federal-budget', '|', 'context', ':', 'radio', 'ad', '|', 'speaker_job_title', ':', 'president', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['u.s.', 'rep.', 'ron', 'kind', ',', 'd-wis.', ',', 'fellow', 'democrats', 'went', 'spending', 'spree', 'credit', 'card', 'maxed', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'national-republican-congressional-committee', '|', 'subject', ':', 'federal-budget', '|', 'context', ':', 'news', 'release', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['water', 'rates', 'manila', ',', 'philippines', ',', 'raised', '845', 'percent', 'subsidiary', 'world', 'bank', 'became', 'partial', 'owner', '.', '|', 'state_info', ':', 'wisconsin', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'gwen-moore', '|', 'subject', ':', 'financial-regulation', ',', 'foreign-policy', ',', 'water', '|', 'context', ':', 'congressional', 'hearing', '|', 'speaker_job_title', ':', 'u.s.', 'house', 'member', '--', '4th']\n",
            "  ['almost', '100,000', 'people', 'left', 'puerto', 'rico', 'last', 'year', '.', '|', 'state_info', ':', 'washington', ',', 'd.c.', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'jack-lew', '|', 'subject', ':', 'bankruptcy', ',', 'economy', ',', 'population', '|', 'context', ':', 'interview', 'bloomberg', 'news', '|', 'speaker_job_title', ':', 'treasury', 'secretary', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "\n",
            "10000 unique tokens\n",
            "Unique tokens peek:\n",
            "  <PAD>\n",
            "  |\n",
            "  :\n",
            "  ,\n",
            "  .\n",
            "  speaker\n",
            "  state_info\n",
            "  party_affiliation\n",
            "  subject\n",
            "  context\n",
            "  speaker_job_title\n",
            "  republican\n",
            "  nan\n",
            "  democrat\n",
            "  says\n",
            "  u.s.\n",
            "  none\n",
            "  interview\n",
            "  new\n",
            "  state\n",
            "\n",
            "Final Index Sets(Set_Size = 49, 10240 index sets) peek:\n",
            "  [15, 8935, 1182, 201, 326, 516, 6415, 766, 1978, 5, 2, 7, 3, 21, 2, 8, 3, 12, 2, 6, 3, 8936, 2, 9, 3, 100, 2, 10, 3, 356, 2, 11, 3, 20, 62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [2580, 1333, 1183, 479, 783, 1431, 407, 247, 783, 2393, 37, 28, 333, 784, 38, 1704, 232, 5, 2, 7, 3, 69, 2, 8, 3, 14, 2, 6, 3, 8937, 2, 9, 3, 79, 4, 63, 4, 124, 2, 10, 3, 192, 33, 5, 2, 11, 3, 20, 1492]\n",
            "  [170, 130, 4384, 238, 314, 24, 4385, 438, 456, 333, 227, 1381, 4386, 547, 5, 27, 2, 7, 3, 61, 2, 8, 3, 14, 2, 6, 3, 73, 2, 9, 3, 76, 2, 10, 3, 1046, 2, 11, 3, 28, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [57, 68, 329, 385, 866, 867, 580, 868, 540, 5156, 5, 2, 7, 3, 13, 2, 8, 3, 17, 2, 6, 3, 581, 2, 9, 3, 31, 2, 10, 3, 40, 53, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [365, 5157, 783, 557, 813, 5, 2, 7, 3, 22, 2, 8, 3, 14, 2, 6, 3, 522, 2, 9, 3, 25, 4, 29, 2, 10, 3, 18, 121, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [1334, 4387, 1979, 6416, 108, 151, 59, 705, 303, 6417, 37, 5158, 38, 2581, 1705, 108, 209, 1231, 5, 2, 7, 3, 34, 2, 8, 3, 12, 2, 6, 3, 2230, 2, 9, 3, 39, 2, 10, 3, 410, 8938, 2, 11, 3, 34, 501, 6, 1, 1, 1]\n",
            "  [889, 8939, 2795, 127, 1882, 59, 517, 5, 2, 7, 3, 21, 2, 8, 3, 12, 2, 6, 3, 2796, 2, 9, 3, 54, 2, 10, 3, 50, 53, 5, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [606, 1626, 654, 2103, 890, 3811, 108, 64, 2231, 4, 1627, 1287, 1288, 4, 3812, 200, 329, 99, 8940, 5, 2, 7, 3, 61, 2, 8, 3, 14, 2, 6, 3, 73, 2, 9, 3, 200, 2, 10, 3, 117, 46, 847, 4, 1493, 2, 11, 3, 28, 1]\n",
            "  [6418, 4, 247, 26, 8941, 71, 104, 1794, 624, 3061, 4388, 4389, 848, 19, 6419, 3813, 1795, 8942, 5, 2, 7, 3, 13, 2, 8, 3, 149, 2, 6, 3, 6420, 2, 9, 3, 29, 2, 10, 3, 150, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1]\n",
            "  [15, 442, 493, 3364, 1706, 6421, 466, 8943, 1707, 3365, 229, 230, 26, 8944, 71, 337, 2394, 357, 5, 2, 7, 3, 34, 2, 8, 3, 12, 2, 6, 3, 8945, 2, 9, 3, 79, 4, 814, 4, 185, 2, 10, 3, 410, 187, 2, 11, 3, 20, 62]\n",
            "  [129, 138, 63, 4, 1382, 102, 1140, 229, 2232, 1708, 2582, 229, 2232, 5, 2, 7, 3, 19, 84, 2, 8, 3, 14, 2, 6, 3, 2233, 2, 9, 3, 55, 2, 10, 3, 33, 2, 11, 3, 16, 32, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [99, 977, 4, 208, 548, 71, 152, 8946, 538, 607, 159, 5, 2, 7, 3, 371, 2, 8, 3, 202, 2, 6, 3, 418, 2, 9, 3, 25, 4, 29, 4, 558, 4, 159, 2, 10, 3, 173, 2, 11, 3, 16, 32, 1, 1, 1, 1, 1, 1]\n",
            "  [293, 246, 35, 134, 4, 457, 5159, 141, 451, 110, 4, 298, 145, 290, 5, 2, 7, 3, 134, 2, 8, 3, 12, 2, 6, 3, 204, 2, 9, 3, 63, 4, 52, 2, 10, 3, 18, 8947, 40, 2, 11, 3, 111, 35, 1, 1, 1, 1, 1]\n",
            "  [25, 8948, 26, 1141, 93, 767, 110, 1980, 5, 2, 7, 3, 13, 2, 8, 3, 17, 2, 6, 3, 3062, 2, 9, 3, 25, 4, 48, 4, 31, 2, 10, 3, 3062, 1981, 372, 5160, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [37, 639, 68, 300, 38, 467, 3063, 4390, 4391, 4392, 5, 2, 7, 3, 447, 2, 8, 3, 448, 2, 6, 3, 1232, 2, 9, 3, 31, 2, 10, 3, 118, 24, 90, 40, 372, 27, 2, 11, 3, 448, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [108, 373, 1563, 4, 97, 3366, 30, 161, 60, 2583, 229, 4, 97, 640, 30, 655, 60, 4, 37, 753, 38, 1289, 30, 2104, 88, 2583, 229, 5, 2, 7, 3, 371, 2, 8, 3, 202, 2, 6, 3, 418, 2, 9, 3, 55, 2, 10, 3, 366, 419]\n",
            "  [314, 683, 2395, 110, 549, 8949, 6422, 5, 91, 8950, 2234, 2584, 8951, 5, 139, 2, 7, 3, 61, 2, 8, 3, 14, 2, 6, 3, 73, 2, 9, 3, 48, 2, 10, 3, 92, 42, 2, 11, 3, 28, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [16, 345, 1184, 1233, 4, 8952, 4, 1982, 239, 388, 166, 4393, 754, 1709, 3367, 2, 7, 3, 13, 2, 8, 3, 12, 2, 6, 3, 721, 2, 9, 3, 48, 2, 10, 3, 40, 53, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [330, 389, 8953, 4, 6423, 4, 439, 6424, 30, 8954, 205, 1001, 755, 5161, 869, 5, 2, 7, 3, 34, 2, 8, 3, 14, 2, 6, 3, 1628, 2, 9, 3, 395, 4, 76, 4, 330, 2, 10, 3, 310, 360, 2, 11, 3, 16, 49, 186, 157, 1494]\n",
            "  [304, 706, 60, 582, 3368, 4394, 108, 64, 5, 2, 7, 3, 120, 4, 198, 2, 8, 3, 14, 2, 6, 3, 6425, 2, 9, 3, 800, 4, 25, 4, 285, 2, 10, 3, 18, 3064, 40, 2, 11, 3, 2105, 305, 1, 1, 1, 1, 1, 1, 1]\n",
            "TRAIN SPLIT: 10240 overall samples: torch.Size([10240, 49])\n",
            "The training dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1284 entries, 0 to 1283\n",
            "Data columns (total 14 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   id                    1284 non-null   object\n",
            " 1   label                 1284 non-null   object\n",
            " 2   claim                 1284 non-null   object\n",
            " 3   subject               1284 non-null   object\n",
            " 4   speaker               1284 non-null   object\n",
            " 5   speaker_job_title     939 non-null    object\n",
            " 6   state_info            1005 non-null   object\n",
            " 7   party_affiliation     1284 non-null   object\n",
            " 8   barely_true_counts    1284 non-null   int64 \n",
            " 9   false_counts          1284 non-null   int64 \n",
            " 10  half_true_counts      1284 non-null   int64 \n",
            " 11  mostly_true_counts    1284 non-null   int64 \n",
            " 12  pants_on_fire_counts  1284 non-null   int64 \n",
            " 13  context               1272 non-null   object\n",
            "dtypes: int64(5), object(9)\n",
            "memory usage: 140.6+ KB\n",
            "\n",
            "Data peek:\n",
            "            id        label  \\\n",
            "0   12134.json  barely-true   \n",
            "1     238.json   pants-fire   \n",
            "2    7891.json        false   \n",
            "3    8169.json    half-true   \n",
            "4     929.json    half-true   \n",
            "5    9416.json        false   \n",
            "6    6861.json         true   \n",
            "7    1122.json        false   \n",
            "8   13138.json         true   \n",
            "9    1880.json    half-true   \n",
            "10  12803.json    half-true   \n",
            "11   5409.json        false   \n",
            "12   7313.json    half-true   \n",
            "13   4809.json         true   \n",
            "14   1671.json  barely-true   \n",
            "15   4348.json    half-true   \n",
            "16   6225.json    half-true   \n",
            "17   7675.json  mostly-true   \n",
            "18   2255.json  barely-true   \n",
            "19   9827.json   pants-fire   \n",
            "\n",
            "                                                claim  \\\n",
            "0   We have less Americans working now than in the...   \n",
            "1   When Obama was sworn into office, he DID NOT u...   \n",
            "2   Says Having organizations parading as being so...   \n",
            "3      Says nearly half of Oregons children are poor.   \n",
            "4   On attacks by Republicans that various program...   \n",
            "5   Says when armed civilians stop mass shootings ...   \n",
            "6   Says Tennessee is providing millions of dollar...   \n",
            "7   The health care reform plan would set limits s...   \n",
            "8   Says Donald Trump started his career back in 1...   \n",
            "9   Bill White has a long history of trying to lim...   \n",
            "10  John McCains chief economic adviser during the...   \n",
            "11  Says 21,000 Wisconsin residents got jobs in 20...   \n",
            "12  State revenue projections have missed the mark...   \n",
            "13  The median income of a middle class family wen...   \n",
            "14  Every citizen is entitled to the freedom of sp...   \n",
            "15  Rick Perry has advocated abandoning Social Sec...   \n",
            "16  Two thirds to three quarters of people without...   \n",
            "17  Congress has spent 66 of the first 100 days of...   \n",
            "18  Mark Sharpe has lowered property taxes by 17 p...   \n",
            "19  Says Iowa Gov. Terry Branstad chartered a plan...   \n",
            "\n",
            "                                      subject                 speaker  \\\n",
            "0                                economy,jobs          vicky-hartzler   \n",
            "1            obama-birth-certificate,religion             chain-email   \n",
            "2             campaign-finance,congress,taxes         earl-blumenauer   \n",
            "3                                     poverty         jim-francesconi   \n",
            "4                            economy,stimulus            barack-obama   \n",
            "5                                        guns              jim-rubens   \n",
            "6                      education,state-budget              andy-berke   \n",
            "7                                 health-care             club-growth   \n",
            "8      candidates-biography,diversity,housing         hillary-clinton   \n",
            "9                                    military  republican-party-texas   \n",
            "10                                    economy               tim-kaine   \n",
            "11            job-accomplishments,jobs,states       kathleen-vinehout   \n",
            "12                               state-budget            steve-henson   \n",
            "13                  income,new-hampshire-2012               joe-biden   \n",
            "14                          gays-and-lesbians          david-dewhurst   \n",
            "15             medicaid,social-security,taxes        margaret-carlson   \n",
            "16  health-care,poverty,public-health,welfare       elizabeth-roberts   \n",
            "17                                   congress             john-barrow   \n",
            "18                 candidates-biography,taxes             mark-sharpe   \n",
            "19                                immigration             chain-email   \n",
            "\n",
            "                                speaker_job_title            state_info  \\\n",
            "0                             U.S. Representative              Missouri   \n",
            "1                                             NaN                   NaN   \n",
            "2                             U.S. representative                Oregon   \n",
            "3   Member of the State Board of Higher Education                Oregon   \n",
            "4                                       President              Illinois   \n",
            "5                            Small business owner         New Hampshire   \n",
            "6                        Lawyer and state senator             Tennessee   \n",
            "7                                             NaN                   NaN   \n",
            "8                          Presidential candidate              New York   \n",
            "9                                             NaN                 Texas   \n",
            "10                                   U.S. Senator              Virginia   \n",
            "11                                            NaN                   NaN   \n",
            "12                                  State Senator               Georgia   \n",
            "13                                   U.S. senator              Delaware   \n",
            "14                            Lieutenant governor                 Texas   \n",
            "15                                      Columnist  District of Columbia   \n",
            "16                            Lieutenant Governor          Rhode Island   \n",
            "17                                    Congressman               Georgia   \n",
            "18               Hillsborough County commissioner               Florida   \n",
            "19                                            NaN                   NaN   \n",
            "\n",
            "   party_affiliation  barely_true_counts  false_counts  half_true_counts  \\\n",
            "0         republican                   1             0                 1   \n",
            "1               none                  11            43                 8   \n",
            "2           democrat                   0             1                 1   \n",
            "3               none                   0             1                 1   \n",
            "4           democrat                  70            71               160   \n",
            "5         republican                   1             1                 0   \n",
            "6           democrat                   0             0                 0   \n",
            "7               none                   4             5                 4   \n",
            "8           democrat                  40            29                69   \n",
            "9         republican                   3             1                 1   \n",
            "10          democrat                   8             3                15   \n",
            "11          democrat                   1             1                 1   \n",
            "12          democrat                   0             0                 1   \n",
            "13          democrat                  11            10                21   \n",
            "14        republican                   8             8                10   \n",
            "15              none                   0             0                 1   \n",
            "16          democrat                   1             0                 2   \n",
            "17          democrat                   0             0                 1   \n",
            "18        republican                   1             0                 0   \n",
            "19              none                  11            43                 8   \n",
            "\n",
            "    mostly_true_counts  pants_on_fire_counts  \\\n",
            "0                    0                     0   \n",
            "1                    5                   105   \n",
            "2                    1                     0   \n",
            "3                    1                     0   \n",
            "4                  163                     9   \n",
            "5                    1                     0   \n",
            "6                    0                     0   \n",
            "7                    2                     0   \n",
            "8                   76                     7   \n",
            "9                    3                     1   \n",
            "10                  15                     0   \n",
            "11                   1                     0   \n",
            "12                   0                     0   \n",
            "13                  16                     4   \n",
            "14                   5                     5   \n",
            "15                   0                     0   \n",
            "16                   0                     0   \n",
            "17                   1                     0   \n",
            "18                   0                     0   \n",
            "19                   5                   105   \n",
            "\n",
            "                                              context  \n",
            "0                        an interview with ABC17 News  \n",
            "1                                                 NaN  \n",
            "2                       a U.S. Ways and Means hearing  \n",
            "3                                  an opinion article  \n",
            "4                             interview with CBS News  \n",
            "5         in an interview at gun shop in Hudson, N.H.  \n",
            "6   a letter to state Senate education committee c...  \n",
            "7                                             a TV ad  \n",
            "8                       the first presidential debate  \n",
            "9                                           an e-mail  \n",
            "10  a speech at the Democratic National Convention...  \n",
            "11                                            remarks  \n",
            "12                                    a press release  \n",
            "13  speaking at New Hampshires Plymouth State Uni...  \n",
            "14                                    a press release  \n",
            "15                                 a politics column.  \n",
            "16        a panel discussion on \"A Lively Experiment\"  \n",
            "17                                           a letter  \n",
            "18                                  a campaign mailer  \n",
            "19                                      a chain email  \n",
            "\n",
            "Tokenized sentences(1284 sentences, 55513 total tokens) peek:\n",
            "  ['less', 'americans', 'working', '70s', '.', '|', 'state_info', ':', 'missouri', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'vicky-hartzler', '|', 'subject', ':', 'economy', ',', 'jobs', '|', 'context', ':', 'interview', 'abc17', 'news', '|', 'speaker_job_title', ':', 'u.s.', 'representative', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['obama', 'sworn', 'office', ',', 'use', 'holy', 'bible', ',', 'instead', 'kuran', '(', 'their', 'equivalency', 'bible', ',', 'different', 'beliefs', ')', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'chain-email', '|', 'subject', ':', 'obama-birth-certificate', ',', 'religion', '|', 'context', ':', 'nan', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['says', 'organizations', 'parading', 'social', 'welfare', 'organizations', 'involved', 'political', 'combat', 'harkens', 'back', 'statute', 'hundred', 'years', 'ago', 'said', 'prohibited', '.', '|', 'state_info', ':', 'oregon', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'earl-blumenauer', '|', 'subject', ':', 'campaign-finance', ',', 'congress', ',', 'taxes', '|', 'context', ':', 'u.s.', 'ways', 'means', 'hearing', '|', 'speaker_job_title', ':', 'u.s.']\n",
            "  ['says', 'nearly', 'half', 'oregons', 'children', 'poor', '.', '|', 'state_info', ':', 'oregon', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'jim-francesconi', '|', 'subject', ':', 'poverty', '|', 'context', ':', 'opinion', 'article', '|', 'speaker_job_title', ':', 'member', 'state', 'board', 'higher', 'education', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['attacks', 'republicans', 'various', 'programs', 'economic', 'stimulus', 'plan', 'stimulative', ',', '``', 'if', 'add', 'stuff', 'up', ',', 'accounts', 'less', '1', 'percent', 'overall', 'package', '.', \"''\", '|', 'state_info', ':', 'illinois', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'barack-obama', '|', 'subject', ':', 'economy', ',', 'stimulus', '|', 'context', ':', 'interview', 'cbs', 'news', '|', 'speaker_job_title']\n",
            "  ['says', 'armed', 'civilians', 'stop', 'mass', 'shootings', 'guns', ',', 'average', '2.5', 'people', 'die', ';', 'otherwise', ',', 'average', '18', 'people', 'die', '.', '|', 'state_info', ':', 'new', 'hampshire', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'jim-rubens', '|', 'subject', ':', 'guns', '|', 'context', ':', 'interview', 'gun', 'shop', 'hudson', ',', 'n.h.', '|', 'speaker_job_title', ':']\n",
            "  ['says', 'tennessee', 'providing', 'millions', 'dollars', 'virtual', 'school', 'company', 'results', 'bottom', 'bottom', '.', '|', 'state_info', ':', 'tennessee', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'andy-berke', '|', 'subject', ':', 'education', ',', 'state-budget', '|', 'context', ':', 'letter', 'state', 'senate', 'education', 'committee', 'chairwoman', 'dolores', 'gresham', '.', '|', 'speaker_job_title', ':', 'lawyer', 'state', 'senator', '<PAD>']\n",
            "  ['health', 'care', 'reform', 'plan', 'would', 'set', 'limits', 'similar', 'socialized', 'system', 'britain', ',', 'people', 'allowed', 'die', 'treatment', 'would', 'cost', '$', '22,000', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'club-growth', '|', 'subject', ':', 'health-care', '|', 'context', ':', 'tv', 'ad', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['says', 'donald', 'trump', 'started', 'career', 'back', '1973', 'sued', 'justice', 'department', 'racial', 'discrimination', 'would', 'rent', 'apartments', 'one', 'developments', 'african-americans', '.', '|', 'state_info', ':', 'new', 'york', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'hillary-clinton', '|', 'subject', ':', 'candidates-biography', ',', 'diversity', ',', 'housing', '|', 'context', ':', 'first', 'presidential', 'debate', '|', 'speaker_job_title', ':']\n",
            "  ['bill', 'white', 'long', 'history', 'trying', 'limit', 'even', 'disenfranchise', 'military', 'voters', '.', '|', 'state_info', ':', 'texas', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'republican-party-texas', '|', 'subject', ':', 'military', '|', 'context', ':', 'e-mail', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['john', 'mccains', 'chief', 'economic', 'adviser', '08', 'race', 'estimated', 'trumps', 'promises', 'would', 'cause', 'america', 'lose', '3.5', 'million', 'jobs', '.', '|', 'state_info', ':', 'virginia', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'tim-kaine', '|', 'subject', ':', 'economy', '|', 'context', ':', 'speech', 'democratic', 'national', 'convention', 'philadelphia', '|', 'speaker_job_title', ':', 'u.s.', 'senator', '<PAD>', '<PAD>']\n",
            "  ['says', '21,000', 'wisconsin', 'residents', 'got', 'jobs', '2011', ',', '18,000', 'states', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'kathleen-vinehout', '|', 'subject', ':', 'job-accomplishments', ',', 'jobs', ',', 'states', '|', 'context', ':', 'remarks', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['state', 'revenue', 'projections', 'missed', 'mark', 'month', 'month', '.', '|', 'state_info', ':', 'georgia', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'steve-henson', '|', 'subject', ':', 'state-budget', '|', 'context', ':', 'press', 'release', '|', 'speaker_job_title', ':', 'state', 'senator', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['median', 'income', 'middle', 'class', 'family', 'went', '$', '2,100', '2001', '2007', '.', '|', 'state_info', ':', 'delaware', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'joe-biden', '|', 'subject', ':', 'income', ',', 'new-hampshire-2012', '|', 'context', ':', 'speaking', 'new', 'hampshires', 'plymouth', 'state', 'university', '|', 'speaker_job_title', ':', 'u.s.', 'senator', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['every', 'citizen', 'entitled', 'freedom', 'speech', ',', 'one', 'right', 'use', 'government', 'funds', 'institutions', 'portray', 'acts', 'morally', 'reprehensible', 'vast', 'majority', 'americans', '.', '|', 'state_info', ':', 'texas', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'david-dewhurst', '|', 'subject', ':', 'gays-and-lesbians', '|', 'context', ':', 'press', 'release', '|', 'speaker_job_title', ':', 'lieutenant', 'governor', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['rick', 'perry', 'advocated', 'abandoning', 'social', 'security', ',', 'scuttling', 'medicaid', 'ending', 'federal', 'income', 'tax', '.', '|', 'state_info', ':', 'district', 'columbia', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'margaret-carlson', '|', 'subject', ':', 'medicaid', ',', 'social-security', ',', 'taxes', '|', 'context', ':', 'politics', 'column', '.', '|', 'speaker_job_title', ':', 'columnist', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['two', 'thirds', 'three', 'quarters', 'people', 'without', '[', 'health', ']', 'insurance', 'rhode', 'island', 'work', '.', '|', 'state_info', ':', 'rhode', 'island', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'elizabeth-roberts', '|', 'subject', ':', 'health-care', ',', 'poverty', ',', 'public-health', ',', 'welfare', '|', 'context', ':', 'panel', 'discussion', '``', 'a', 'lively', 'experiment', \"''\", '|', 'speaker_job_title']\n",
            "  ['congress', 'spent', '66', 'first', '100', 'days', 'term', 'recess', '.', '|', 'state_info', ':', 'georgia', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'john-barrow', '|', 'subject', ':', 'congress', '|', 'context', ':', 'letter', '|', 'speaker_job_title', ':', 'congressman', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['mark', 'sharpe', 'lowered', 'property', 'taxes', '17', 'percent', '.', '|', 'state_info', ':', 'florida', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'mark-sharpe', '|', 'subject', ':', 'candidates-biography', ',', 'taxes', '|', 'context', ':', 'campaign', 'mailer', '|', 'speaker_job_title', ':', 'hillsborough', 'county', 'commissioner', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['says', 'iowa', 'gov', '.', 'terry', 'branstad', 'chartered', 'plane', 'remove', '124', 'young', 'illegal', 'immigrants', 'state', 'take', 'back', 'honduras', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'chain-email', '|', 'subject', ':', 'immigration', '|', 'context', ':', 'chain', 'email', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "\n",
            "10000 unique tokens\n",
            "Unique tokens peek:\n",
            "  <PAD>\n",
            "  |\n",
            "  :\n",
            "  ,\n",
            "  .\n",
            "  speaker\n",
            "  state_info\n",
            "  party_affiliation\n",
            "  subject\n",
            "  context\n",
            "  speaker_job_title\n",
            "  republican\n",
            "  nan\n",
            "  democrat\n",
            "  says\n",
            "  u.s.\n",
            "  none\n",
            "  interview\n",
            "  new\n",
            "  state\n",
            "\n",
            "Final Index Sets(Set_Size = 49, 1284 index sets) peek:\n",
            "  [233, 152, 406, 0, 5, 2, 7, 3, 542, 2, 8, 3, 12, 2, 6, 3, 7845, 2, 9, 3, 25, 4, 29, 2, 10, 3, 18, 0, 40, 2, 11, 3, 16, 62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [47, 4897, 164, 4, 367, 0, 2946, 4, 1497, 0, 37, 5601, 0, 2946, 4, 986, 3042, 38, 5, 2, 7, 3, 13, 2, 8, 3, 17, 2, 6, 3, 267, 2, 9, 3, 1208, 4, 263, 2, 10, 3, 13, 2, 11, 3, 13, 1, 1, 1, 1]\n",
            "  [15, 2200, 0, 143, 417, 2200, 1784, 201, 2652, 0, 382, 6648, 3469, 59, 431, 91, 4005, 5, 2, 7, 3, 104, 2, 8, 3, 14, 2, 6, 3, 4008, 2, 9, 3, 197, 4, 81, 4, 23, 2, 10, 3, 16, 2904, 1000, 360, 2, 11, 3, 16]\n",
            "  [15, 208, 272, 1734, 113, 1149, 5, 2, 7, 3, 104, 2, 8, 3, 17, 2, 6, 3, 7618, 2, 9, 3, 159, 2, 10, 3, 446, 249, 2, 11, 3, 186, 20, 274, 337, 39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [1042, 262, 1272, 701, 365, 131, 128, 0, 4, 24, 2500, 1409, 6121, 712, 4, 1823, 233, 165, 30, 1782, 1897, 5, 27, 2, 7, 3, 61, 2, 8, 3, 14, 2, 6, 3, 73, 2, 9, 3, 25, 4, 131, 2, 10, 3, 18, 653, 40, 2, 11]\n",
            "  [15, 3343, 8780, 583, 1190, 1317, 85, 4, 181, 1929, 60, 1117, 956, 4391, 4, 181, 723, 60, 1117, 5, 2, 7, 3, 19, 216, 2, 8, 3, 12, 2, 6, 3, 8012, 2, 9, 3, 85, 2, 10, 3, 18, 286, 6258, 6434, 4, 474, 2, 11, 3]\n",
            "  [15, 412, 3615, 383, 214, 0, 137, 561, 3447, 1121, 1121, 5, 2, 7, 3, 412, 2, 8, 3, 14, 2, 6, 3, 0, 2, 9, 3, 39, 4, 52, 2, 10, 3, 297, 20, 66, 39, 221, 2932, 0, 0, 5, 2, 11, 3, 620, 20, 32, 1]\n",
            "  [57, 68, 329, 128, 65, 1226, 2697, 1696, 4097, 302, 3782, 4, 60, 636, 1117, 1943, 65, 230, 26, 4190, 5, 2, 7, 3, 13, 2, 8, 3, 17, 2, 6, 3, 1682, 2, 9, 3, 31, 2, 10, 3, 78, 42, 2, 11, 3, 13, 1, 1, 1]\n",
            "  [15, 259, 225, 783, 1298, 382, 3164, 3318, 656, 296, 4433, 2436, 65, 2397, 4408, 77, 0, 2098, 5, 2, 7, 3, 19, 45, 2, 8, 3, 14, 2, 6, 3, 153, 2, 9, 3, 54, 4, 420, 4, 348, 2, 10, 3, 129, 70, 46, 2, 11, 3]\n",
            "  [80, 260, 1080, 63, 904, 1470, 156, 0, 82, 362, 5, 2, 7, 3, 21, 2, 8, 3, 12, 2, 6, 3, 2796, 2, 9, 3, 82, 2, 10, 3, 281, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [238, 5764, 833, 365, 1498, 0, 970, 1252, 1329, 3110, 65, 987, 163, 807, 2907, 71, 29, 5, 2, 7, 3, 69, 2, 8, 3, 14, 2, 6, 3, 765, 2, 9, 3, 25, 2, 10, 3, 33, 117, 102, 218, 847, 2, 11, 3, 16, 32, 1, 1]\n",
            "  [15, 0, 34, 665, 340, 29, 354, 4, 3610, 44, 5, 2, 7, 3, 13, 2, 8, 3, 14, 2, 6, 3, 5288, 2, 9, 3, 124, 4, 29, 4, 44, 2, 10, 3, 276, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [20, 610, 4525, 2023, 954, 533, 533, 5, 2, 7, 3, 58, 2, 8, 3, 14, 2, 6, 3, 0, 2, 9, 3, 52, 2, 10, 3, 50, 53, 2, 11, 3, 20, 32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [1735, 103, 538, 607, 411, 388, 26, 6210, 1467, 1155, 5, 2, 7, 3, 496, 2, 8, 3, 14, 2, 6, 3, 563, 2, 9, 3, 103, 4, 558, 2, 10, 3, 2858, 19, 8844, 8712, 20, 306, 2, 11, 3, 16, 32, 1, 1, 1, 1, 1, 1]\n",
            "  [89, 2193, 0, 1235, 33, 4, 77, 235, 367, 110, 624, 2150, 0, 4557, 0, 0, 2268, 292, 152, 5, 2, 7, 3, 21, 2, 8, 3, 12, 2, 6, 3, 1062, 2, 9, 3, 339, 2, 10, 3, 50, 53, 2, 11, 3, 461, 35, 1, 1, 1]\n",
            "  [251, 541, 2342, 0, 143, 182, 4, 0, 223, 2222, 96, 103, 51, 5, 2, 7, 3, 127, 1406, 2, 8, 3, 17, 2, 6, 3, 0, 2, 9, 3, 223, 4, 312, 4, 23, 2, 10, 3, 1271, 224, 5, 2, 11, 3, 448, 1, 1, 1, 1]\n",
            "  [209, 5565, 207, 6449, 60, 317, 253, 57, 254, 177, 72, 74, 316, 5, 2, 7, 3, 72, 74, 2, 8, 3, 14, 2, 6, 3, 5065, 2, 9, 3, 31, 4, 159, 4, 169, 4, 417, 2, 10, 3, 824, 559, 24, 603, 8771, 5951, 27, 2, 11]\n",
            "  [81, 335, 4273, 129, 393, 524, 813, 0, 5, 2, 7, 3, 58, 2, 8, 3, 14, 2, 6, 3, 0, 2, 9, 3, 81, 2, 10, 3, 297, 2, 11, 3, 188, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [954, 0, 5036, 476, 23, 958, 30, 5, 2, 7, 3, 22, 2, 8, 3, 12, 2, 6, 3, 0, 2, 9, 3, 54, 4, 23, 2, 10, 3, 36, 356, 2, 11, 3, 2686, 87, 481, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [15, 307, 191, 5, 2806, 0, 0, 2575, 1744, 0, 655, 219, 353, 20, 344, 382, 4784, 5, 2, 7, 3, 13, 2, 8, 3, 17, 2, 6, 3, 267, 2, 9, 3, 56, 2, 10, 3, 414, 184, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1]\n",
            "VALID SPLIT: 1284 overall samples: torch.Size([1284, 49])\n",
            "2 labels\n",
            "\n",
            "label\n",
            "false    0.644727\n",
            "true     0.355273\n",
            "Name: proportion, dtype: float64\n",
            "TRAIN SPLIT(pre-balancing): 10240 overall samples: torch.Size([10240, 49])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRAIN SPLIT(post-balancing): 13204 overall samples: torch.Size([13204, 49])\n",
            "label\n",
            "false    6602\n",
            "true     6602\n",
            "Name: count, dtype: int64\n",
            "Number of available GPUs: 1\n",
            "GPU 0: Tesla T4\n",
            "Is a T4 GPU available? True\n",
            "Using GPU: Tesla T4\n",
            "Training with params:\n",
            "{'dropout': 0.5053885100582086, 'embedding_dim': 300, 'hidden_dim': 128, 'learning_rate': 0.0042859896809875325, 'n_layers': 1}\n",
            "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5053885100582086 and num_layers=1\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.6474 | Accuracy: 0.6344\n",
            "Epoch 2/10 | Loss: 0.5526 | Accuracy: 0.7198\n",
            "Epoch 3/10 | Loss: 0.3491 | Accuracy: 0.8461\n",
            "Epoch 4/10 | Loss: 0.1739 | Accuracy: 0.9345\n",
            "Epoch 5/10 | Loss: 0.0778 | Accuracy: 0.9746\n",
            "Epoch 6/10 | Loss: 0.0339 | Accuracy: 0.9911\n",
            "Epoch 7/10 | Loss: 0.0127 | Accuracy: 0.9974\n",
            "Epoch 8/10 | Loss: 0.0053 | Accuracy: 0.9985\n",
            "Epoch 9/10 | Loss: 0.0029 | Accuracy: 0.9992\n",
            "Epoch 10/10 | Loss: 0.0013 | Accuracy: 0.9996\n",
            "Training with params:\n",
            "{'dropout': 0.5814945611550191, 'embedding_dim': 150, 'hidden_dim': 224, 'learning_rate': 0.010749310069838244, 'n_layers': 2}\n",
            "Epoch 1/10 | Loss: 0.6686 | Accuracy: 0.6307\n",
            "Epoch 2/10 | Loss: 0.6497 | Accuracy: 0.6356\n",
            "Epoch 3/10 | Loss: 0.6217 | Accuracy: 0.6694\n",
            "Epoch 4/10 | Loss: 0.5975 | Accuracy: 0.6875\n",
            "Epoch 5/10 | Loss: 0.5641 | Accuracy: 0.7161\n",
            "Epoch 6/10 | Loss: 0.5416 | Accuracy: 0.7342\n",
            "Epoch 7/10 | Loss: 0.5142 | Accuracy: 0.7512\n",
            "Epoch 8/10 | Loss: 0.5000 | Accuracy: 0.7593\n",
            "Epoch 9/10 | Loss: 0.4895 | Accuracy: 0.7732\n",
            "Epoch 10/10 | Loss: 0.4754 | Accuracy: 0.7834\n",
            "Training with params:\n",
            "{'dropout': 0.3381948263498564, 'embedding_dim': 200, 'hidden_dim': 64, 'learning_rate': 0.06844476496798725, 'n_layers': 2}\n",
            "Epoch 1/10 | Loss: 0.7026 | Accuracy: 0.6036\n",
            "Epoch 2/10 | Loss: 0.8565 | Accuracy: 0.5773\n",
            "Epoch 3/10 | Loss: 0.8815 | Accuracy: 0.5620\n",
            "Epoch 4/10 | Loss: 0.8419 | Accuracy: 0.5671\n",
            "Epoch 5/10 | Loss: 0.8396 | Accuracy: 0.5632\n",
            "Epoch 6/10 | Loss: 0.7965 | Accuracy: 0.5752\n",
            "Epoch 7/10 | Loss: 0.8033 | Accuracy: 0.5720\n",
            "Epoch 8/10 | Loss: 0.7828 | Accuracy: 0.5739\n",
            "Epoch 9/10 | Loss: 0.7957 | Accuracy: 0.5696\n",
            "Epoch 10/10 | Loss: 0.7822 | Accuracy: 0.5701\n",
            "Training with params:\n",
            "{'dropout': 0.5319254662928736, 'embedding_dim': 200, 'hidden_dim': 224, 'learning_rate': 0.06862988890547264, 'n_layers': 3}\n",
            "Epoch 1/10 | Loss: 0.8989 | Accuracy: 0.5563\n",
            "Epoch 2/10 | Loss: 0.9762 | Accuracy: 0.5564\n",
            "Epoch 3/10 | Loss: 0.8731 | Accuracy: 0.5535\n",
            "Epoch 4/10 | Loss: 0.8346 | Accuracy: 0.5684\n",
            "Epoch 5/10 | Loss: 0.8640 | Accuracy: 0.5630\n",
            "Epoch 6/10 | Loss: 0.8049 | Accuracy: 0.5588\n",
            "Epoch 7/10 | Loss: 0.7693 | Accuracy: 0.5753\n",
            "Epoch 8/10 | Loss: 0.8725 | Accuracy: 0.5639\n",
            "Epoch 9/10 | Loss: 1.2422 | Accuracy: 0.5516\n",
            "Epoch 10/10 | Loss: 1.0828 | Accuracy: 0.5524\n",
            "Training with params:\n",
            "{'dropout': 0.5387193320691896, 'embedding_dim': 500, 'hidden_dim': 64, 'learning_rate': 0.0498559388919886, 'n_layers': 1}\n",
            "  8%|         | 4/50 [02:04<27:14, 35.54s/trial, best loss: -0.49904337452450087]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5387193320691896 and num_layers=1\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.7387 | Accuracy: 0.5924\n",
            "Epoch 2/10 | Loss: 0.7248 | Accuracy: 0.5996\n",
            "Epoch 3/10 | Loss: 0.7227 | Accuracy: 0.6030\n",
            "Epoch 4/10 | Loss: 0.7204 | Accuracy: 0.6050\n",
            "Epoch 5/10 | Loss: 0.7403 | Accuracy: 0.6041\n",
            "Epoch 6/10 | Loss: 0.7341 | Accuracy: 0.5972\n",
            "Epoch 7/10 | Loss: 0.7250 | Accuracy: 0.6061\n",
            "Epoch 8/10 | Loss: 0.7199 | Accuracy: 0.6053\n",
            "Epoch 9/10 | Loss: 0.7141 | Accuracy: 0.6092\n",
            "Epoch 10/10 | Loss: 0.7144 | Accuracy: 0.6091\n",
            "Training with params:\n",
            "{'dropout': 0.5758549920116105, 'embedding_dim': 200, 'hidden_dim': 96, 'learning_rate': 0.018964507930669044, 'n_layers': 1}\n",
            " 10%|         | 5/50 [02:21<21:43, 28.97s/trial, best loss: -0.49904337452450087]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5758549920116105 and num_layers=1\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.6824 | Accuracy: 0.6114\n",
            "Epoch 2/10 | Loss: 0.6314 | Accuracy: 0.6595\n",
            "Epoch 3/10 | Loss: 0.5743 | Accuracy: 0.7097\n",
            "Epoch 4/10 | Loss: 0.5238 | Accuracy: 0.7405\n",
            "Epoch 5/10 | Loss: 0.4903 | Accuracy: 0.7667\n",
            "Epoch 6/10 | Loss: 0.4555 | Accuracy: 0.7846\n",
            "Epoch 7/10 | Loss: 0.4338 | Accuracy: 0.7992\n",
            "Epoch 8/10 | Loss: 0.4138 | Accuracy: 0.8122\n",
            "Epoch 9/10 | Loss: 0.4121 | Accuracy: 0.8101\n",
            "Epoch 10/10 | Loss: 0.4215 | Accuracy: 0.8031\n",
            "Training with params:\n",
            "{'dropout': 0.6765022316378859, 'embedding_dim': 400, 'hidden_dim': 96, 'learning_rate': 0.008701691118170058, 'n_layers': 1}\n",
            " 12%|        | 6/50 [02:34<17:12, 23.46s/trial, best loss: -0.49904337452450087]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6765022316378859 and num_layers=1\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.6599 | Accuracy: 0.6293\n",
            "Epoch 2/10 | Loss: 0.5782 | Accuracy: 0.7024\n",
            "Epoch 3/10 | Loss: 0.4331 | Accuracy: 0.7938\n",
            "Epoch 4/10 | Loss: 0.3294 | Accuracy: 0.8528\n",
            "Epoch 5/10 | Loss: 0.2387 | Accuracy: 0.8998\n",
            "Epoch 6/10 | Loss: 0.1767 | Accuracy: 0.9289\n",
            "Epoch 7/10 | Loss: 0.1403 | Accuracy: 0.9433\n",
            "Epoch 8/10 | Loss: 0.1298 | Accuracy: 0.9483\n",
            "Epoch 9/10 | Loss: 0.1331 | Accuracy: 0.9474\n",
            "Epoch 10/10 | Loss: 0.1247 | Accuracy: 0.9504\n",
            "Training with params:\n",
            "{'dropout': 0.37551396035644513, 'embedding_dim': 200, 'hidden_dim': 64, 'learning_rate': 0.11613973348347902, 'n_layers': 2}\n",
            "Epoch 1/10 | Loss: 0.9068 | Accuracy: 0.5605\n",
            "Epoch 2/10 | Loss: 0.9575 | Accuracy: 0.5554\n",
            "Epoch 3/10 | Loss: 0.9423 | Accuracy: 0.5579\n",
            "Epoch 4/10 | Loss: 0.9519 | Accuracy: 0.5530\n",
            "Epoch 5/10 | Loss: 0.9146 | Accuracy: 0.5659\n",
            "Epoch 6/10 | Loss: 0.9065 | Accuracy: 0.5589\n",
            "Epoch 7/10 | Loss: 0.9034 | Accuracy: 0.5655\n",
            "Epoch 8/10 | Loss: 0.8888 | Accuracy: 0.5659\n",
            "Epoch 9/10 | Loss: 0.7967 | Accuracy: 0.5791\n",
            "Epoch 10/10 | Loss: 0.7959 | Accuracy: 0.5687\n",
            "Training with params:\n",
            "{'dropout': 0.41815611177168577, 'embedding_dim': 300, 'hidden_dim': 32, 'learning_rate': 0.009628118862343223, 'n_layers': 1}\n",
            " 16%|        | 8/50 [03:04<13:16, 18.97s/trial, best loss: -0.49904337452450087]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.41815611177168577 and num_layers=1\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.6476 | Accuracy: 0.6386\n",
            "Epoch 2/10 | Loss: 0.5641 | Accuracy: 0.7117\n",
            "Epoch 3/10 | Loss: 0.4330 | Accuracy: 0.8024\n",
            "Epoch 4/10 | Loss: 0.3431 | Accuracy: 0.8491\n",
            "Epoch 5/10 | Loss: 0.2726 | Accuracy: 0.8824\n",
            "Epoch 6/10 | Loss: 0.2308 | Accuracy: 0.9032\n",
            "Epoch 7/10 | Loss: 0.1946 | Accuracy: 0.9198\n",
            "Epoch 8/10 | Loss: 0.1597 | Accuracy: 0.9334\n",
            "Epoch 9/10 | Loss: 0.1415 | Accuracy: 0.9450\n",
            "Epoch 10/10 | Loss: 0.1518 | Accuracy: 0.9388\n",
            "Training with params:\n",
            "{'dropout': 0.6704986957645299, 'embedding_dim': 250, 'hidden_dim': 224, 'learning_rate': 0.004590342902957793, 'n_layers': 2}\n",
            "Epoch 1/10 | Loss: 0.6548 | Accuracy: 0.6390\n",
            "Epoch 2/10 | Loss: 0.6065 | Accuracy: 0.6706\n",
            "Epoch 3/10 | Loss: 0.5230 | Accuracy: 0.7419\n",
            "Epoch 4/10 | Loss: 0.4080 | Accuracy: 0.8216\n",
            "Epoch 5/10 | Loss: 0.3249 | Accuracy: 0.8638\n",
            "Epoch 6/10 | Loss: 0.2489 | Accuracy: 0.9062\n",
            "Epoch 7/10 | Loss: 0.1959 | Accuracy: 0.9287\n",
            "Epoch 8/10 | Loss: 0.1544 | Accuracy: 0.9480\n",
            "Epoch 9/10 | Loss: 0.1267 | Accuracy: 0.9567\n",
            "Epoch 10/10 | Loss: 0.1256 | Accuracy: 0.9561\n",
            "Training with params:\n",
            "{'dropout': 0.626013310613408, 'embedding_dim': 300, 'hidden_dim': 64, 'learning_rate': 0.024580066992116064, 'n_layers': 2}\n",
            "Epoch 1/10 | Loss: 0.6702 | Accuracy: 0.6221\n",
            "Epoch 2/10 | Loss: 0.6727 | Accuracy: 0.6245\n",
            "Epoch 3/10 | Loss: 0.6734 | Accuracy: 0.6208\n",
            "Epoch 4/10 | Loss: 0.6698 | Accuracy: 0.6251\n",
            "Epoch 5/10 | Loss: 0.6722 | Accuracy: 0.6253\n",
            "Epoch 6/10 | Loss: 0.6621 | Accuracy: 0.6316\n",
            "Epoch 7/10 | Loss: 0.6642 | Accuracy: 0.6293\n",
            "Epoch 8/10 | Loss: 0.6612 | Accuracy: 0.6316\n",
            "Epoch 9/10 | Loss: 0.6662 | Accuracy: 0.6305\n",
            "Epoch 10/10 | Loss: 0.6652 | Accuracy: 0.6331\n",
            "Training with params:\n",
            "{'dropout': 0.5826610766764859, 'embedding_dim': 200, 'hidden_dim': 192, 'learning_rate': 0.0028255773450163997, 'n_layers': 3}\n",
            "Epoch 1/10 | Loss: 0.6468 | Accuracy: 0.6428\n",
            "Epoch 2/10 | Loss: 0.6000 | Accuracy: 0.6800\n",
            "Epoch 3/10 | Loss: 0.5167 | Accuracy: 0.7531\n",
            "Epoch 4/10 | Loss: 0.3929 | Accuracy: 0.8327\n",
            "Epoch 5/10 | Loss: 0.2750 | Accuracy: 0.8915\n",
            "Epoch 6/10 | Loss: 0.1973 | Accuracy: 0.9271\n",
            "Epoch 7/10 | Loss: 0.1316 | Accuracy: 0.9576\n",
            "Epoch 8/10 | Loss: 0.0997 | Accuracy: 0.9691\n",
            "Epoch 9/10 | Loss: 0.0775 | Accuracy: 0.9752\n",
            "Epoch 10/10 | Loss: 0.0685 | Accuracy: 0.9790\n",
            "Training with params:\n",
            "{'dropout': 0.11726683591084522, 'embedding_dim': 100, 'hidden_dim': 96, 'learning_rate': 0.008513288300335398, 'n_layers': 2}\n",
            "Epoch 1/10 | Loss: 0.6509 | Accuracy: 0.6394\n",
            "Epoch 2/10 | Loss: 0.5977 | Accuracy: 0.6771\n",
            "Epoch 3/10 | Loss: 0.4944 | Accuracy: 0.7581\n",
            "Epoch 4/10 | Loss: 0.3838 | Accuracy: 0.8341\n",
            "Epoch 5/10 | Loss: 0.2727 | Accuracy: 0.8869\n",
            "Epoch 6/10 | Loss: 0.2305 | Accuracy: 0.9070\n",
            "Epoch 7/10 | Loss: 0.1910 | Accuracy: 0.9247\n",
            "Epoch 8/10 | Loss: 0.1473 | Accuracy: 0.9443\n",
            "Epoch 9/10 | Loss: 0.1111 | Accuracy: 0.9589\n",
            "Epoch 10/10 | Loss: 0.1018 | Accuracy: 0.9619\n",
            "Training with params:\n",
            "{'dropout': 0.17061458990769068, 'embedding_dim': 50, 'hidden_dim': 160, 'learning_rate': 0.0039287801444876334, 'n_layers': 3}\n",
            "Epoch 1/10 | Loss: 0.6561 | Accuracy: 0.6413\n",
            "Epoch 2/10 | Loss: 0.6481 | Accuracy: 0.6447\n",
            "Epoch 3/10 | Loss: 0.6355 | Accuracy: 0.6461\n",
            "Epoch 4/10 | Loss: 0.6168 | Accuracy: 0.6572\n",
            "Epoch 5/10 | Loss: 0.5860 | Accuracy: 0.7011\n",
            "Epoch 6/10 | Loss: 0.5475 | Accuracy: 0.7328\n",
            "Epoch 7/10 | Loss: 0.4949 | Accuracy: 0.7741\n",
            "Epoch 8/10 | Loss: 0.4325 | Accuracy: 0.8161\n",
            "Epoch 9/10 | Loss: 0.3537 | Accuracy: 0.8587\n",
            "Epoch 10/10 | Loss: 0.2881 | Accuracy: 0.8900\n",
            "Training with params:\n",
            "{'dropout': 0.40805544196811316, 'embedding_dim': 300, 'hidden_dim': 64, 'learning_rate': 0.011704070892225839, 'n_layers': 3}\n",
            "Epoch 1/10 | Loss: 0.6485 | Accuracy: 0.6411\n",
            "Epoch 2/10 | Loss: 0.5924 | Accuracy: 0.6812\n",
            "Epoch 3/10 | Loss: 0.5388 | Accuracy: 0.7345\n",
            "Epoch 4/10 | Loss: 0.4942 | Accuracy: 0.7723\n",
            "Epoch 5/10 | Loss: 0.4697 | Accuracy: 0.7835\n",
            "Epoch 6/10 | Loss: 0.4340 | Accuracy: 0.8059\n",
            "Epoch 7/10 | Loss: 0.4120 | Accuracy: 0.8251\n",
            "Epoch 8/10 | Loss: 0.3935 | Accuracy: 0.8311\n",
            "Epoch 9/10 | Loss: 0.3903 | Accuracy: 0.8281\n",
            "Epoch 10/10 | Loss: 0.3764 | Accuracy: 0.8354\n",
            "Training with params:\n",
            "{'dropout': 0.394052508363656, 'embedding_dim': 200, 'hidden_dim': 32, 'learning_rate': 0.027104104728307873, 'n_layers': 2}\n",
            "Epoch 1/10 | Loss: 0.6553 | Accuracy: 0.6380\n",
            "Epoch 2/10 | Loss: 0.6394 | Accuracy: 0.6406\n",
            "Epoch 3/10 | Loss: 0.6271 | Accuracy: 0.6495\n",
            "Epoch 4/10 | Loss: 0.6085 | Accuracy: 0.6637\n",
            "Epoch 5/10 | Loss: 0.5942 | Accuracy: 0.6787\n",
            "Epoch 6/10 | Loss: 0.5876 | Accuracy: 0.6882\n",
            "Epoch 7/10 | Loss: 0.5759 | Accuracy: 0.6919\n",
            "Epoch 8/10 | Loss: 0.5726 | Accuracy: 0.6985\n",
            "Epoch 9/10 | Loss: 0.5581 | Accuracy: 0.7098\n",
            "Epoch 10/10 | Loss: 0.5484 | Accuracy: 0.7150\n",
            "Training with params:\n",
            "{'dropout': 0.20062215527912203, 'embedding_dim': 150, 'hidden_dim': 192, 'learning_rate': 0.005466244764314541, 'n_layers': 2}\n",
            "Epoch 1/10 | Loss: 0.6529 | Accuracy: 0.6376\n",
            "Epoch 2/10 | Loss: 0.6097 | Accuracy: 0.6642\n",
            "Epoch 3/10 | Loss: 0.5012 | Accuracy: 0.7563\n",
            "Epoch 4/10 | Loss: 0.3665 | Accuracy: 0.8387\n",
            "Epoch 5/10 | Loss: 0.2401 | Accuracy: 0.9015\n",
            "Epoch 6/10 | Loss: 0.1727 | Accuracy: 0.9317\n",
            "Epoch 7/10 | Loss: 0.1436 | Accuracy: 0.9450\n",
            "Epoch 8/10 | Loss: 0.1131 | Accuracy: 0.9562\n",
            "Epoch 9/10 | Loss: 0.0962 | Accuracy: 0.9621\n",
            "Epoch 10/10 | Loss: 0.0753 | Accuracy: 0.9704\n",
            "Training with params:\n",
            "{'dropout': 0.6858180916393298, 'embedding_dim': 100, 'hidden_dim': 64, 'learning_rate': 0.0639219065755827, 'n_layers': 2}\n",
            "Epoch 1/10 | Loss: 0.7270 | Accuracy: 0.5917\n",
            "Epoch 2/10 | Loss: 0.7735 | Accuracy: 0.5730\n",
            "Epoch 3/10 | Loss: 0.7981 | Accuracy: 0.5764\n",
            "Epoch 4/10 | Loss: 0.8670 | Accuracy: 0.5580\n",
            "Epoch 5/10 | Loss: 0.8545 | Accuracy: 0.5587\n",
            "Epoch 6/10 | Loss: 0.8351 | Accuracy: 0.5635\n",
            "Epoch 7/10 | Loss: 0.8149 | Accuracy: 0.5632\n",
            "Epoch 8/10 | Loss: 0.8302 | Accuracy: 0.5669\n",
            "Epoch 9/10 | Loss: 0.8113 | Accuracy: 0.5632\n",
            "Epoch 10/10 | Loss: 0.7910 | Accuracy: 0.5786\n",
            "Training with params:\n",
            "{'dropout': 0.5297993746065305, 'embedding_dim': 400, 'hidden_dim': 32, 'learning_rate': 0.04840176483465656, 'n_layers': 2}\n",
            "Epoch 1/10 | Loss: 0.6679 | Accuracy: 0.6261\n",
            "Epoch 2/10 | Loss: 0.6629 | Accuracy: 0.6313\n",
            "Epoch 3/10 | Loss: 0.6620 | Accuracy: 0.6363\n",
            "Epoch 4/10 | Loss: 0.6597 | Accuracy: 0.6382\n",
            "Epoch 5/10 | Loss: 0.6577 | Accuracy: 0.6391\n",
            "Epoch 6/10 | Loss: 0.6618 | Accuracy: 0.6321\n",
            "Epoch 7/10 | Loss: 0.6587 | Accuracy: 0.6416\n",
            "Epoch 8/10 | Loss: 0.6636 | Accuracy: 0.6370\n",
            "Epoch 9/10 | Loss: 0.6568 | Accuracy: 0.6405\n",
            "Epoch 10/10 | Loss: 0.6588 | Accuracy: 0.6385\n",
            "Training with params:\n",
            "{'dropout': 0.14583289165392038, 'embedding_dim': 350, 'hidden_dim': 192, 'learning_rate': 0.010332061356401539, 'n_layers': 2}\n",
            "Epoch 1/10 | Loss: 0.6604 | Accuracy: 0.6351\n",
            "Epoch 2/10 | Loss: 0.6267 | Accuracy: 0.6472\n",
            "Epoch 3/10 | Loss: 0.5654 | Accuracy: 0.7061\n",
            "Epoch 4/10 | Loss: 0.4917 | Accuracy: 0.7606\n",
            "Epoch 5/10 | Loss: 0.4416 | Accuracy: 0.7942\n",
            "Epoch 6/10 | Loss: 0.3830 | Accuracy: 0.8267\n",
            "Epoch 7/10 | Loss: 0.3400 | Accuracy: 0.8515\n",
            "Epoch 8/10 | Loss: 0.3037 | Accuracy: 0.8708\n",
            "Epoch 9/10 | Loss: 0.2993 | Accuracy: 0.8752\n",
            "Epoch 10/10 | Loss: 0.2723 | Accuracy: 0.8873\n",
            "Training with params:\n",
            "{'dropout': 0.48503155286217425, 'embedding_dim': 250, 'hidden_dim': 256, 'learning_rate': 0.11825883483391457, 'n_layers': 3}\n",
            "Epoch 1/10 | Loss: 1.2988 | Accuracy: 0.5506\n",
            "Epoch 2/10 | Loss: 1.7821 | Accuracy: 0.5394\n",
            "Epoch 3/10 | Loss: 2.1133 | Accuracy: 0.5441\n",
            "Epoch 4/10 | Loss: 1.7846 | Accuracy: 0.5481\n",
            "Epoch 5/10 | Loss: 1.7912 | Accuracy: 0.5489\n",
            "Epoch 6/10 | Loss: 1.8469 | Accuracy: 0.5377\n",
            "Epoch 7/10 | Loss: 1.6610 | Accuracy: 0.5444\n",
            "Epoch 8/10 | Loss: 1.3331 | Accuracy: 0.5554\n",
            "Epoch 9/10 | Loss: 1.4307 | Accuracy: 0.5478\n",
            "Epoch 10/10 | Loss: 1.4136 | Accuracy: 0.5500\n",
            "Training with params:\n",
            "{'dropout': 0.6504486664956798, 'embedding_dim': 250, 'hidden_dim': 224, 'learning_rate': 0.0027892382348197495, 'n_layers': 3}\n",
            "Epoch 1/10 | Loss: 0.6504 | Accuracy: 0.6412\n",
            "Epoch 2/10 | Loss: 0.6108 | Accuracy: 0.6712\n",
            "Epoch 3/10 | Loss: 0.5240 | Accuracy: 0.7476\n",
            "Epoch 4/10 | Loss: 0.4029 | Accuracy: 0.8266\n",
            "Epoch 5/10 | Loss: 0.2909 | Accuracy: 0.8927\n",
            "Epoch 6/10 | Loss: 0.2109 | Accuracy: 0.9295\n",
            "Epoch 7/10 | Loss: 0.1590 | Accuracy: 0.9493\n",
            "Epoch 8/10 | Loss: 0.1260 | Accuracy: 0.9620\n",
            "Epoch 9/10 | Loss: 0.0997 | Accuracy: 0.9703\n",
            "Epoch 10/10 | Loss: 0.0811 | Accuracy: 0.9765\n",
            "Training with params:\n",
            "{'dropout': 0.46992088418420636, 'embedding_dim': 350, 'hidden_dim': 256, 'learning_rate': 0.03686311341463216, 'n_layers': 3}\n",
            "Epoch 1/10 | Loss: 0.8089 | Accuracy: 0.5716\n",
            "Epoch 2/10 | Loss: 0.7975 | Accuracy: 0.5742\n",
            "Epoch 3/10 | Loss: 0.7710 | Accuracy: 0.5787\n",
            "Epoch 4/10 | Loss: 0.7615 | Accuracy: 0.5799\n",
            "Epoch 5/10 | Loss: 0.7718 | Accuracy: 0.5682\n",
            "Epoch 6/10 | Loss: 0.7415 | Accuracy: 0.5811\n",
            "Epoch 7/10 | Loss: 0.7604 | Accuracy: 0.5814\n",
            "Epoch 8/10 | Loss: 0.7647 | Accuracy: 0.5676\n",
            "Epoch 9/10 | Loss: 0.7524 | Accuracy: 0.5736\n",
            "Epoch 10/10 | Loss: 0.7722 | Accuracy: 0.5646\n",
            "Training with params:\n",
            "{'dropout': 0.6225631899105762, 'embedding_dim': 150, 'hidden_dim': 224, 'learning_rate': 0.09124469673111672, 'n_layers': 3}\n",
            "Epoch 1/10 | Loss: 1.0473 | Accuracy: 0.5538\n",
            "Epoch 2/10 | Loss: 1.1154 | Accuracy: 0.5488\n",
            "Epoch 3/10 | Loss: 1.0201 | Accuracy: 0.5551\n",
            "Epoch 4/10 | Loss: 1.3050 | Accuracy: 0.5449\n",
            "Epoch 5/10 | Loss: 1.9973 | Accuracy: 0.5539\n",
            "Epoch 6/10 | Loss: 2.1300 | Accuracy: 0.5453\n",
            "Epoch 7/10 | Loss: 1.6966 | Accuracy: 0.5370\n",
            "Epoch 8/10 | Loss: 1.5520 | Accuracy: 0.5419\n",
            "Epoch 9/10 | Loss: 1.4606 | Accuracy: 0.5522\n",
            "Epoch 10/10 | Loss: 1.4764 | Accuracy: 0.5437\n",
            "Training with params:\n",
            "{'dropout': 0.2840818927250103, 'embedding_dim': 250, 'hidden_dim': 160, 'learning_rate': 0.014499305909854987, 'n_layers': 3}\n",
            "Epoch 1/10 | Loss: 0.6623 | Accuracy: 0.6370\n",
            "Epoch 2/10 | Loss: 0.6463 | Accuracy: 0.6439\n",
            "Epoch 3/10 | Loss: 0.6256 | Accuracy: 0.6604\n",
            "Epoch 4/10 | Loss: 0.6074 | Accuracy: 0.6822\n",
            "Epoch 5/10 | Loss: 0.5944 | Accuracy: 0.6877\n",
            "Epoch 6/10 | Loss: 0.6064 | Accuracy: 0.6790\n",
            "Epoch 7/10 | Loss: 0.6514 | Accuracy: 0.6319\n",
            "Epoch 8/10 | Loss: 0.6512 | Accuracy: 0.6351\n",
            "Epoch 9/10 | Loss: 0.6430 | Accuracy: 0.6418\n",
            "Epoch 10/10 | Loss: 0.6364 | Accuracy: 0.6457\n",
            "Training with params:\n",
            "{'dropout': 0.6965716948355345, 'embedding_dim': 500, 'hidden_dim': 256, 'learning_rate': 0.03129649974579133, 'n_layers': 1}\n",
            " 50%|     | 25/50 [15:48<24:35, 59.03s/trial, best loss: -0.49904337452450087]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6965716948355345 and num_layers=1\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.8671 | Accuracy: 0.5773\n",
            "Epoch 2/10 | Loss: 0.8750 | Accuracy: 0.5942\n",
            "Epoch 3/10 | Loss: 0.9847 | Accuracy: 0.5939\n",
            "Epoch 4/10 | Loss: 1.0667 | Accuracy: 0.5775\n",
            "Epoch 5/10 | Loss: 0.9946 | Accuracy: 0.5973\n",
            "Epoch 6/10 | Loss: 1.0220 | Accuracy: 0.5984\n",
            "Epoch 7/10 | Loss: 0.9103 | Accuracy: 0.6067\n",
            "Epoch 8/10 | Loss: 0.9014 | Accuracy: 0.6259\n",
            "Epoch 9/10 | Loss: 0.9031 | Accuracy: 0.6239\n",
            "Epoch 10/10 | Loss: 0.8977 | Accuracy: 0.6188\n",
            "Training with params:\n",
            "{'dropout': 0.460425970811283, 'embedding_dim': 100, 'hidden_dim': 224, 'learning_rate': 0.006726312796465516, 'n_layers': 3}\n",
            "Epoch 1/10 | Loss: 0.6591 | Accuracy: 0.6404\n",
            "Epoch 2/10 | Loss: 0.6434 | Accuracy: 0.6400\n",
            "Epoch 3/10 | Loss: 0.6264 | Accuracy: 0.6568\n",
            "Epoch 4/10 | Loss: 0.6081 | Accuracy: 0.6892\n",
            "Epoch 5/10 | Loss: 0.5926 | Accuracy: 0.7128\n",
            "Epoch 6/10 | Loss: 0.5672 | Accuracy: 0.7267\n",
            "Epoch 7/10 | Loss: 0.5361 | Accuracy: 0.7471\n",
            "Epoch 8/10 | Loss: 0.5198 | Accuracy: 0.7652\n",
            "Epoch 9/10 | Loss: 0.4866 | Accuracy: 0.7847\n",
            "Epoch 10/10 | Loss: 0.4662 | Accuracy: 0.7916\n",
            "Training with params:\n",
            "{'dropout': 0.5570753746946494, 'embedding_dim': 350, 'hidden_dim': 192, 'learning_rate': 0.019832699123685297, 'n_layers': 3}\n",
            "Epoch 1/10 | Loss: 0.6817 | Accuracy: 0.6303\n",
            "Epoch 2/10 | Loss: 0.6649 | Accuracy: 0.6310\n",
            "Epoch 3/10 | Loss: 0.6690 | Accuracy: 0.6299\n",
            "Epoch 4/10 | Loss: 0.6761 | Accuracy: 0.6135\n",
            "Epoch 5/10 | Loss: 0.6814 | Accuracy: 0.6120\n",
            "Epoch 6/10 | Loss: 0.7181 | Accuracy: 0.5923\n",
            "Epoch 7/10 | Loss: 0.6936 | Accuracy: 0.6021\n",
            "Epoch 8/10 | Loss: 0.6860 | Accuracy: 0.6004\n",
            "Epoch 9/10 | Loss: 0.6742 | Accuracy: 0.6187\n",
            "Epoch 10/10 | Loss: 0.6747 | Accuracy: 0.6189\n",
            "Training with params:\n",
            "{'dropout': 0.5056829673011182, 'embedding_dim': 50, 'hidden_dim': 128, 'learning_rate': 0.0036631876594125073, 'n_layers': 1}\n",
            " 56%|    | 28/50 [18:55<24:38, 67.19s/trial, best loss: -0.49904337452450087]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5056829673011182 and num_layers=1\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.6486 | Accuracy: 0.6389\n",
            "Epoch 2/10 | Loss: 0.6033 | Accuracy: 0.6792\n",
            "Epoch 3/10 | Loss: 0.5043 | Accuracy: 0.7560\n",
            "Epoch 4/10 | Loss: 0.3685 | Accuracy: 0.8377\n",
            "Epoch 5/10 | Loss: 0.2001 | Accuracy: 0.9225\n",
            "Epoch 6/10 | Loss: 0.0889 | Accuracy: 0.9703\n",
            "Epoch 7/10 | Loss: 0.0313 | Accuracy: 0.9913\n",
            "Epoch 8/10 | Loss: 0.0193 | Accuracy: 0.9954\n",
            "Epoch 9/10 | Loss: 0.0243 | Accuracy: 0.9927\n",
            "Epoch 10/10 | Loss: 0.0214 | Accuracy: 0.9940\n",
            "Training with params:\n",
            "{'dropout': 0.6174601723474022, 'embedding_dim': 400, 'hidden_dim': 160, 'learning_rate': 0.005008775194977379, 'n_layers': 1}\n",
            " 58%|    | 29/50 [19:07<17:38, 50.40s/trial, best loss: -0.49904337452450087]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6174601723474022 and num_layers=1\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.6538 | Accuracy: 0.6326\n",
            "Epoch 2/10 | Loss: 0.5616 | Accuracy: 0.7068\n",
            "Epoch 3/10 | Loss: 0.3538 | Accuracy: 0.8384\n",
            "Epoch 4/10 | Loss: 0.1920 | Accuracy: 0.9233\n",
            "Epoch 5/10 | Loss: 0.0929 | Accuracy: 0.9667\n",
            "Epoch 6/10 | Loss: 0.0411 | Accuracy: 0.9880\n",
            "Epoch 7/10 | Loss: 0.0198 | Accuracy: 0.9946\n",
            "Epoch 8/10 | Loss: 0.0100 | Accuracy: 0.9975\n",
            "Epoch 9/10 | Loss: 0.0046 | Accuracy: 0.9993\n",
            "Epoch 10/10 | Loss: 0.0025 | Accuracy: 0.9993\n",
            "Training with params:\n",
            "{'dropout': 0.6076200741708722, 'embedding_dim': 450, 'hidden_dim': 160, 'learning_rate': 0.01578554000949572, 'n_layers': 1}\n",
            " 60%|    | 30/50 [19:37<14:50, 44.51s/trial, best loss: -0.503956273519438]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6076200741708722 and num_layers=1\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.7002 | Accuracy: 0.6058\n",
            "Epoch 2/10 | Loss: 0.6429 | Accuracy: 0.6664\n",
            "Epoch 3/10 | Loss: 0.5570 | Accuracy: 0.7251\n",
            "Epoch 4/10 | Loss: 0.5101 | Accuracy: 0.7550\n",
            "Epoch 5/10 | Loss: 0.4523 | Accuracy: 0.7896\n",
            "Epoch 6/10 | Loss: 0.4287 | Accuracy: 0.7999\n",
            "Epoch 7/10 | Loss: 0.4211 | Accuracy: 0.8115\n",
            "Epoch 8/10 | Loss: 0.4165 | Accuracy: 0.8098\n",
            "Epoch 9/10 | Loss: 0.3956 | Accuracy: 0.8229\n",
            "Epoch 10/10 | Loss: 0.3886 | Accuracy: 0.8250\n",
            "Training with params:\n",
            "{'dropout': 0.3166181330432435, 'embedding_dim': 450, 'hidden_dim': 128, 'learning_rate': 0.006649937708367666, 'n_layers': 1}\n",
            " 62%|   | 31/50 [20:09<12:55, 40.81s/trial, best loss: -0.503956273519438]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3166181330432435 and num_layers=1\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.6572 | Accuracy: 0.6278\n",
            "Epoch 2/10 | Loss: 0.5543 | Accuracy: 0.7172\n",
            "Epoch 3/10 | Loss: 0.3734 | Accuracy: 0.8287\n",
            "Epoch 4/10 | Loss: 0.2372 | Accuracy: 0.9002\n",
            "Epoch 5/10 | Loss: 0.1529 | Accuracy: 0.9415\n",
            "Epoch 6/10 | Loss: 0.1034 | Accuracy: 0.9603\n",
            "Epoch 7/10 | Loss: 0.0724 | Accuracy: 0.9740\n",
            "Epoch 8/10 | Loss: 0.0598 | Accuracy: 0.9806\n",
            "Epoch 9/10 | Loss: 0.0504 | Accuracy: 0.9812\n",
            "Epoch 10/10 | Loss: 0.0826 | Accuracy: 0.9682\n",
            "Training with params:\n",
            "{'dropout': 0.2555903243683639, 'embedding_dim': 400, 'hidden_dim': 128, 'learning_rate': 0.08158387131337683, 'n_layers': 1}\n",
            " 64%|   | 32/50 [20:28<10:12, 34.05s/trial, best loss: -0.503956273519438]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2555903243683639 and num_layers=1\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 1.0174 | Accuracy: 0.5648\n",
            "Epoch 2/10 | Loss: 0.9592 | Accuracy: 0.5698\n",
            "Epoch 3/10 | Loss: 0.9803 | Accuracy: 0.5663\n",
            "Epoch 4/10 | Loss: 0.9706 | Accuracy: 0.5656\n",
            "Epoch 5/10 | Loss: 1.0194 | Accuracy: 0.5610\n",
            "Epoch 6/10 | Loss: 0.9892 | Accuracy: 0.5707\n",
            "Epoch 7/10 | Loss: 1.0214 | Accuracy: 0.5706\n",
            "Epoch 8/10 | Loss: 1.0169 | Accuracy: 0.5685\n",
            "Epoch 9/10 | Loss: 1.0116 | Accuracy: 0.5654\n",
            "Epoch 10/10 | Loss: 1.0344 | Accuracy: 0.5616\n",
            "Training with params:\n",
            "{'dropout': 0.5049111997502143, 'embedding_dim': 450, 'hidden_dim': 160, 'learning_rate': 0.040272123821376356, 'n_layers': 1}\n",
            " 66%|   | 33/50 [20:45<08:11, 28.89s/trial, best loss: -0.503956273519438]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5049111997502143 and num_layers=1\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.8540 | Accuracy: 0.5845\n",
            "Epoch 2/10 | Loss: 0.8131 | Accuracy: 0.5935\n",
            "Epoch 3/10 | Loss: 0.8293 | Accuracy: 0.5924\n",
            "Epoch 4/10 | Loss: 0.8233 | Accuracy: 0.6021\n",
            "Epoch 5/10 | Loss: 0.8125 | Accuracy: 0.6063\n",
            "Epoch 6/10 | Loss: 0.7922 | Accuracy: 0.6169\n",
            "Epoch 7/10 | Loss: 0.8112 | Accuracy: 0.6035\n",
            "Epoch 8/10 | Loss: 0.8511 | Accuracy: 0.6025\n",
            "Epoch 9/10 | Loss: 1.0206 | Accuracy: 0.5780\n",
            "Epoch 10/10 | Loss: 0.9044 | Accuracy: 0.5914\n",
            "Training with params:\n",
            "{'dropout': 0.5808113317973147, 'embedding_dim': 500, 'hidden_dim': 192, 'learning_rate': 0.0601198726296624, 'n_layers': 1}\n",
            " 68%|   | 34/50 [21:17<07:57, 29.85s/trial, best loss: -0.503956273519438]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5808113317973147 and num_layers=1\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 1.0935 | Accuracy: 0.5583\n",
            "Epoch 2/10 | Loss: 1.1533 | Accuracy: 0.5613\n",
            "Epoch 3/10 | Loss: 1.2869 | Accuracy: 0.5632\n",
            "Epoch 4/10 | Loss: 1.3365 | Accuracy: 0.5590\n",
            "Epoch 5/10 | Loss: 1.2787 | Accuracy: 0.5659\n",
            "Epoch 6/10 | Loss: 1.1857 | Accuracy: 0.5668\n",
            "Epoch 7/10 | Loss: 1.1571 | Accuracy: 0.5743\n",
            "Epoch 8/10 | Loss: 1.1788 | Accuracy: 0.5645\n",
            "Epoch 9/10 | Loss: 1.2311 | Accuracy: 0.5717\n",
            "Epoch 10/10 | Loss: 1.2033 | Accuracy: 0.5706\n",
            "Training with params:\n",
            "{'dropout': 0.4427331623474678, 'embedding_dim': 350, 'hidden_dim': 224, 'learning_rate': 0.1345034704265014, 'n_layers': 2}\n",
            "Epoch 1/10 | Loss: 2.5800 | Accuracy: 0.5449\n",
            "Epoch 2/10 | Loss: 2.5480 | Accuracy: 0.5475\n",
            "Epoch 3/10 | Loss: 2.3543 | Accuracy: 0.5498\n",
            "Epoch 4/10 | Loss: 2.4174 | Accuracy: 0.5392\n",
            "Epoch 5/10 | Loss: 2.3507 | Accuracy: 0.5473\n",
            "Epoch 6/10 | Loss: 2.2630 | Accuracy: 0.5523\n",
            "Epoch 7/10 | Loss: 2.2899 | Accuracy: 0.5597\n",
            "Epoch 8/10 | Loss: 1.9574 | Accuracy: 0.5466\n",
            "Epoch 9/10 | Loss: 1.7255 | Accuracy: 0.5533\n",
            "Epoch 10/10 | Loss: 1.4116 | Accuracy: 0.5460\n",
            "Training with params:\n",
            "{'dropout': 0.3637721950380055, 'embedding_dim': 150, 'hidden_dim': 256, 'learning_rate': 0.013031848705016969, 'n_layers': 1}\n",
            " 72%|  | 36/50 [22:41<08:26, 36.19s/trial, best loss: -0.503956273519438]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3637721950380055 and num_layers=1\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.6769 | Accuracy: 0.6166\n",
            "Epoch 2/10 | Loss: 0.6361 | Accuracy: 0.6608\n",
            "Epoch 3/10 | Loss: 0.5672 | Accuracy: 0.7168\n",
            "Epoch 4/10 | Loss: 0.5059 | Accuracy: 0.7585\n",
            "Epoch 5/10 | Loss: 0.4794 | Accuracy: 0.7824\n",
            "Epoch 6/10 | Loss: 0.4507 | Accuracy: 0.7948\n",
            "Epoch 7/10 | Loss: 0.4334 | Accuracy: 0.8046\n",
            "Epoch 8/10 | Loss: 0.4098 | Accuracy: 0.8149\n",
            "Epoch 9/10 | Loss: 0.4122 | Accuracy: 0.8138\n",
            "Epoch 10/10 | Loss: 0.4590 | Accuracy: 0.7968\n",
            "Training with params:\n",
            "{'dropout': 0.3447049458449401, 'embedding_dim': 150, 'hidden_dim': 256, 'learning_rate': 0.006853978714582779, 'n_layers': 1}\n",
            " 74%|  | 37/50 [23:02<06:48, 31.41s/trial, best loss: -0.5055484651672859]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3447049458449401 and num_layers=1\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.6715 | Accuracy: 0.6257\n",
            "Epoch 2/10 | Loss: 0.5971 | Accuracy: 0.6841\n",
            "Epoch 3/10 | Loss: 0.4425 | Accuracy: 0.7967\n",
            "Epoch 4/10 | Loss: 0.2859 | Accuracy: 0.8838\n",
            "Epoch 5/10 | Loss: 0.1911 | Accuracy: 0.9258\n",
            "Epoch 6/10 | Loss: 0.1347 | Accuracy: 0.9479\n",
            "Epoch 7/10 | Loss: 0.0971 | Accuracy: 0.9645\n",
            "Epoch 8/10 | Loss: 0.0763 | Accuracy: 0.9721\n",
            "Epoch 9/10 | Loss: 0.0775 | Accuracy: 0.9709\n",
            "Epoch 10/10 | Loss: 0.1110 | Accuracy: 0.9574\n",
            "Training with params:\n",
            "{'dropout': 0.23011944923259475, 'embedding_dim': 400, 'hidden_dim': 96, 'learning_rate': 0.012700646327688513, 'n_layers': 1}\n",
            " 76%|  | 38/50 [23:21<05:34, 27.89s/trial, best loss: -0.5055484651672859]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.23011944923259475 and num_layers=1\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.6672 | Accuracy: 0.6253\n",
            "Epoch 2/10 | Loss: 0.5949 | Accuracy: 0.6882\n",
            "Epoch 3/10 | Loss: 0.4975 | Accuracy: 0.7562\n",
            "Epoch 4/10 | Loss: 0.4172 | Accuracy: 0.8034\n",
            "Epoch 5/10 | Loss: 0.3663 | Accuracy: 0.8366\n",
            "Epoch 6/10 | Loss: 0.3174 | Accuracy: 0.8570\n",
            "Epoch 7/10 | Loss: 0.2963 | Accuracy: 0.8697\n",
            "Epoch 8/10 | Loss: 0.2698 | Accuracy: 0.8838\n",
            "Epoch 9/10 | Loss: 0.2506 | Accuracy: 0.8956\n",
            "Epoch 10/10 | Loss: 0.2566 | Accuracy: 0.8902\n",
            "Training with params:\n",
            "{'dropout': 0.3462466132571343, 'embedding_dim': 100, 'hidden_dim': 160, 'learning_rate': 0.005387696748496084, 'n_layers': 1}\n",
            " 78%|  | 39/50 [23:37<04:26, 24.26s/trial, best loss: -0.5055484651672859]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3462466132571343 and num_layers=1\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.6526 | Accuracy: 0.6372\n",
            "Epoch 2/10 | Loss: 0.5914 | Accuracy: 0.6867\n",
            "Epoch 3/10 | Loss: 0.4305 | Accuracy: 0.8020\n",
            "Epoch 4/10 | Loss: 0.2359 | Accuracy: 0.9038\n",
            "Epoch 5/10 | Loss: 0.1061 | Accuracy: 0.9626\n",
            "Epoch 6/10 | Loss: 0.0521 | Accuracy: 0.9836\n",
            "Epoch 7/10 | Loss: 0.0265 | Accuracy: 0.9928\n",
            "Epoch 8/10 | Loss: 0.0161 | Accuracy: 0.9956\n",
            "Epoch 9/10 | Loss: 0.0152 | Accuracy: 0.9955\n",
            "Epoch 10/10 | Loss: 0.0691 | Accuracy: 0.9749\n",
            "Training with params:\n",
            "{'dropout': 0.29939797004214264, 'embedding_dim': 450, 'hidden_dim': 96, 'learning_rate': 0.0033041123417282465, 'n_layers': 1}\n",
            " 80%|  | 40/50 [24:01<04:00, 24.05s/trial, best loss: -0.5055484651672859]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.29939797004214264 and num_layers=1\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.6440 | Accuracy: 0.6389\n",
            "Epoch 2/10 | Loss: 0.5395 | Accuracy: 0.7249\n",
            "Epoch 3/10 | Loss: 0.3208 | Accuracy: 0.8609\n",
            "Epoch 4/10 | Loss: 0.1497 | Accuracy: 0.9432\n",
            "Epoch 5/10 | Loss: 0.0612 | Accuracy: 0.9818\n",
            "Epoch 6/10 | Loss: 0.0229 | Accuracy: 0.9949\n",
            "Epoch 7/10 | Loss: 0.0094 | Accuracy: 0.9983\n",
            "Epoch 8/10 | Loss: 0.0037 | Accuracy: 0.9993\n",
            "Epoch 9/10 | Loss: 0.0017 | Accuracy: 0.9997\n",
            "Epoch 10/10 | Loss: 0.0011 | Accuracy: 0.9997\n",
            "Training with params:\n",
            "{'dropout': 0.3726280969461382, 'embedding_dim': 300, 'hidden_dim': 128, 'learning_rate': 0.02364466681746379, 'n_layers': 1}\n",
            " 82%| | 41/50 [24:17<03:15, 21.75s/trial, best loss: -0.5055484651672859]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3726280969461382 and num_layers=1\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.7167 | Accuracy: 0.5954\n",
            "Epoch 2/10 | Loss: 0.6952 | Accuracy: 0.6267\n",
            "Epoch 3/10 | Loss: 0.6480 | Accuracy: 0.6607\n",
            "Epoch 4/10 | Loss: 0.6132 | Accuracy: 0.6896\n",
            "Epoch 5/10 | Loss: 0.5958 | Accuracy: 0.7026\n",
            "Epoch 6/10 | Loss: 0.5802 | Accuracy: 0.7126\n",
            "Epoch 7/10 | Loss: 0.5699 | Accuracy: 0.7247\n",
            "Epoch 8/10 | Loss: 0.5642 | Accuracy: 0.7250\n",
            "Epoch 9/10 | Loss: 0.5516 | Accuracy: 0.7378\n",
            "Epoch 10/10 | Loss: 0.5405 | Accuracy: 0.7400\n",
            "Training with params:\n",
            "{'dropout': 0.43054689494209747, 'embedding_dim': 50, 'hidden_dim': 256, 'learning_rate': 0.007847105520143874, 'n_layers': 1}\n",
            " 84%| | 42/50 [24:32<02:37, 19.65s/trial, best loss: -0.5055484651672859]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.43054689494209747 and num_layers=1\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.6590 | Accuracy: 0.6339\n",
            "Epoch 2/10 | Loss: 0.6190 | Accuracy: 0.6678\n",
            "Epoch 3/10 | Loss: 0.5176 | Accuracy: 0.7465\n",
            "Epoch 4/10 | Loss: 0.3631 | Accuracy: 0.8389\n",
            "Epoch 5/10 | Loss: 0.2407 | Accuracy: 0.9014\n",
            "Epoch 6/10 | Loss: 0.1667 | Accuracy: 0.9346\n",
            "Epoch 7/10 | Loss: 0.1267 | Accuracy: 0.9521\n",
            "Epoch 8/10 | Loss: 0.0972 | Accuracy: 0.9655\n",
            "Epoch 9/10 | Loss: 0.0844 | Accuracy: 0.9683\n",
            "Epoch 10/10 | Loss: 0.0679 | Accuracy: 0.9763\n",
            "Training with params:\n",
            "{'dropout': 0.26557287585889533, 'embedding_dim': 150, 'hidden_dim': 192, 'learning_rate': 0.004915210858550095, 'n_layers': 1}\n",
            " 86%| | 43/50 [24:51<02:16, 19.50s/trial, best loss: -0.5055484651672859]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.26557287585889533 and num_layers=1\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.6513 | Accuracy: 0.6370\n",
            "Epoch 2/10 | Loss: 0.5817 | Accuracy: 0.6926\n",
            "Epoch 3/10 | Loss: 0.4121 | Accuracy: 0.8095\n",
            "Epoch 4/10 | Loss: 0.2057 | Accuracy: 0.9169\n",
            "Epoch 5/10 | Loss: 0.0925 | Accuracy: 0.9688\n",
            "Epoch 6/10 | Loss: 0.0445 | Accuracy: 0.9876\n",
            "Epoch 7/10 | Loss: 0.0285 | Accuracy: 0.9923\n",
            "Epoch 8/10 | Loss: 0.0217 | Accuracy: 0.9937\n",
            "Epoch 9/10 | Loss: 0.0370 | Accuracy: 0.9883\n",
            "Epoch 10/10 | Loss: 0.0764 | Accuracy: 0.9731\n",
            "Training with params:\n",
            "{'dropout': 0.3769046158119786, 'embedding_dim': 200, 'hidden_dim': 224, 'learning_rate': 0.0025466103049593463, 'n_layers': 1}\n",
            " 88%| | 44/50 [25:26<02:24, 24.06s/trial, best loss: -0.5055484651672859]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3769046158119786 and num_layers=1\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.6465 | Accuracy: 0.6401\n",
            "Epoch 2/10 | Loss: 0.5733 | Accuracy: 0.7034\n",
            "Epoch 3/10 | Loss: 0.4039 | Accuracy: 0.8190\n",
            "Epoch 4/10 | Loss: 0.1889 | Accuracy: 0.9279\n",
            "Epoch 5/10 | Loss: 0.0644 | Accuracy: 0.9796\n",
            "Epoch 6/10 | Loss: 0.0209 | Accuracy: 0.9939\n",
            "Epoch 7/10 | Loss: 0.0144 | Accuracy: 0.9960\n",
            "Epoch 8/10 | Loss: 0.0074 | Accuracy: 0.9983\n",
            "Epoch 9/10 | Loss: 0.0050 | Accuracy: 0.9989\n",
            "Epoch 10/10 | Loss: 0.0105 | Accuracy: 0.9966\n",
            "Training with params:\n",
            "{'dropout': 0.21029406628326827, 'embedding_dim': 400, 'hidden_dim': 96, 'learning_rate': 0.018788724645523953, 'n_layers': 1}\n",
            " 90%| | 45/50 [25:46<01:54, 22.80s/trial, best loss: -0.5055484651672859]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.21029406628326827 and num_layers=1\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.6833 | Accuracy: 0.6137\n",
            "Epoch 2/10 | Loss: 0.6349 | Accuracy: 0.6582\n",
            "Epoch 3/10 | Loss: 0.5800 | Accuracy: 0.6997\n",
            "Epoch 4/10 | Loss: 0.5432 | Accuracy: 0.7262\n",
            "Epoch 5/10 | Loss: 0.5045 | Accuracy: 0.7495\n",
            "Epoch 6/10 | Loss: 0.4947 | Accuracy: 0.7607\n",
            "Epoch 7/10 | Loss: 0.4706 | Accuracy: 0.7747\n",
            "Epoch 8/10 | Loss: 0.4553 | Accuracy: 0.7847\n",
            "Epoch 9/10 | Loss: 0.4504 | Accuracy: 0.7905\n",
            "Epoch 10/10 | Loss: 0.4408 | Accuracy: 0.7904\n",
            "Training with params:\n",
            "{'dropout': 0.6564171328443024, 'embedding_dim': 300, 'hidden_dim': 256, 'learning_rate': 0.014403412309376222, 'n_layers': 2}\n",
            "Epoch 1/10 | Loss: 0.6948 | Accuracy: 0.6154\n",
            "Epoch 2/10 | Loss: 0.6499 | Accuracy: 0.6399\n",
            "Epoch 3/10 | Loss: 0.5916 | Accuracy: 0.6923\n",
            "Epoch 4/10 | Loss: 0.5176 | Accuracy: 0.7511\n",
            "Epoch 5/10 | Loss: 0.4543 | Accuracy: 0.7921\n",
            "Epoch 6/10 | Loss: 0.3893 | Accuracy: 0.8339\n",
            "Epoch 7/10 | Loss: 0.3575 | Accuracy: 0.8521\n",
            "Epoch 8/10 | Loss: 0.3536 | Accuracy: 0.8517\n",
            "Epoch 9/10 | Loss: 0.3409 | Accuracy: 0.8544\n",
            "Epoch 10/10 | Loss: 0.4247 | Accuracy: 0.8149\n",
            "Training with params:\n",
            "{'dropout': 0.10069628234376532, 'embedding_dim': 250, 'hidden_dim': 160, 'learning_rate': 0.009356067711302346, 'n_layers': 1}\n",
            " 94%|| 47/50 [26:45<01:22, 27.56s/trial, best loss: -0.5055484651672859]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.10069628234376532 and num_layers=1\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.6654 | Accuracy: 0.6243\n",
            "Epoch 2/10 | Loss: 0.5887 | Accuracy: 0.6910\n",
            "Epoch 3/10 | Loss: 0.4536 | Accuracy: 0.7887\n",
            "Epoch 4/10 | Loss: 0.3362 | Accuracy: 0.8556\n",
            "Epoch 5/10 | Loss: 0.2602 | Accuracy: 0.8899\n",
            "Epoch 6/10 | Loss: 0.1949 | Accuracy: 0.9229\n",
            "Epoch 7/10 | Loss: 0.1784 | Accuracy: 0.9256\n",
            "Epoch 8/10 | Loss: 0.1390 | Accuracy: 0.9446\n",
            "Epoch 9/10 | Loss: 0.1348 | Accuracy: 0.9468\n",
            "Epoch 10/10 | Loss: 0.1407 | Accuracy: 0.9450\n",
            "Training with params:\n",
            "{'dropout': 0.32379699677981744, 'embedding_dim': 500, 'hidden_dim': 192, 'learning_rate': 0.011477440219309605, 'n_layers': 2}\n",
            "Epoch 1/10 | Loss: 0.6601 | Accuracy: 0.6318\n",
            "Epoch 2/10 | Loss: 0.6413 | Accuracy: 0.6370\n",
            "Epoch 3/10 | Loss: 0.6142 | Accuracy: 0.6630\n",
            "Epoch 4/10 | Loss: 0.5708 | Accuracy: 0.7080\n",
            "Epoch 5/10 | Loss: 0.5522 | Accuracy: 0.7131\n",
            "Epoch 6/10 | Loss: 0.5069 | Accuracy: 0.7530\n",
            "Epoch 7/10 | Loss: 0.4919 | Accuracy: 0.7622\n",
            "Epoch 8/10 | Loss: 0.4722 | Accuracy: 0.7732\n",
            "Epoch 9/10 | Loss: 0.4605 | Accuracy: 0.7833\n",
            "Epoch 10/10 | Loss: 0.4715 | Accuracy: 0.7734\n",
            "Training with params:\n",
            "{'dropout': 0.5359382582732288, 'embedding_dim': 200, 'hidden_dim': 128, 'learning_rate': 0.004153629167090387, 'n_layers': 1}\n",
            " 98%|| 49/50 [28:27<00:41, 41.76s/trial, best loss: -0.5055484651672859]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5359382582732288 and num_layers=1\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.6495 | Accuracy: 0.6352\n",
            "Epoch 2/10 | Loss: 0.5693 | Accuracy: 0.7035\n",
            "Epoch 3/10 | Loss: 0.3764 | Accuracy: 0.8315\n",
            "Epoch 4/10 | Loss: 0.1768 | Accuracy: 0.9321\n",
            "Epoch 5/10 | Loss: 0.0787 | Accuracy: 0.9740\n",
            "Epoch 6/10 | Loss: 0.0285 | Accuracy: 0.9918\n",
            "Epoch 7/10 | Loss: 0.0089 | Accuracy: 0.9985\n",
            "Epoch 8/10 | Loss: 0.0159 | Accuracy: 0.9953\n",
            "Epoch 9/10 | Loss: 0.0471 | Accuracy: 0.9840\n",
            "Epoch 10/10 | Loss: 0.0670 | Accuracy: 0.9759\n",
            "100%|| 50/50 [28:40<00:00, 34.41s/trial, best loss: -0.5055484651672859]\n",
            "Best hyperparameters found:\n",
            "{'dropout': 0.3637721950380055, 'embedding_dim': 150.0, 'hidden_dim': 256.0, 'learning_rate': 0.013031848705016969, 'n_layers': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train final model with best hyperparameters\n",
        "print(\"Best Hyperparameters:\", best)\n",
        "best_params = {\n",
        "    'embedding_dim': int(best['embedding_dim']),\n",
        "    'hidden_dim': int(best['hidden_dim']),\n",
        "    'n_layers': int(best['n_layers']),\n",
        "    'dropout': best['dropout'],\n",
        "    'learning_rate': best['learning_rate']\n",
        "}\n",
        "\n",
        "final_model = BiLSTMModel(\n",
        "    input_dim=train_vocab_size + 1,\n",
        "    embedding_dim=best_params['embedding_dim'],\n",
        "    hidden_dim=best_params['hidden_dim'],\n",
        "    output_dim=train_label_counts.shape[0],\n",
        "    n_layers=best_params['n_layers'],\n",
        "    dropout=best_params['dropout']\n",
        ")\n",
        "final_model.to(device)\n",
        "\n",
        "optimizer = optim.AdamW(final_model.parameters(), lr=best_params['learning_rate'])\n",
        "\n",
        "# Example of using class weights:\n",
        "class_weights = torch.tensor([2.0, 1.0], dtype=torch.float).to(device) # You might need to adjust these\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "criterion.to(device)\n",
        "\n",
        "# --- Validation data setup ---\n",
        "X_val, _, _, _, y_val = as_tensors(\"valid\", label_encoder=label_encoder, known_vector_size=X_train.shape[1], token_to_idx=token_to_idx)\n",
        "val_dataset = TensorDataset(X_val, y_val)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Train the final model on the combined training and validation sets\n",
        "combined_X = torch.cat((X_train, X_val), dim=0)\n",
        "combined_y = torch.cat((y_train, y_val), dim=0)\n",
        "combined_dataset = TensorDataset(combined_X, combined_y)\n",
        "combined_loader = DataLoader(combined_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "def train_model(model, dataloader, optimizer, criterion, device, epochs=10):\n",
        "    model.train()\n",
        "    best_val_loss = float('inf')  # Initialize with a very large value\n",
        "    best_model_path = \"best_model.pth\"\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        epoch_tps = 0\n",
        "        total_samples = 0\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(inputs)\n",
        "            loss = criterion(predictions, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()  # Track total loss\n",
        "            # Track total accuracy\n",
        "            _, predicted_classes = torch.max(predictions, 1)\n",
        "            epoch_tps += (predicted_classes == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(predicted_classes.cpu().numpy())\n",
        "\n",
        "        y_true = torch.tensor(y_true, dtype=torch.long)\n",
        "        y_pred = torch.tensor(y_pred, dtype=torch.long)\n",
        "\n",
        "        results, f1_macro = evaluate(y_true, train_label_counts.shape[0], y_pred, y_pred, y_pred, label_encoder.classes_)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {epoch_loss/len(dataloader):.4f} | Accuracy: {epoch_tps/total_samples:.4f}\")\n",
        "        print(f\"  Per-Class Precision: {results['Model']['Per-Class Precision']}\")\n",
        "        print(f\"  Per-Class Recall: {results['Model']['Per-Class Recall']}\")\n",
        "        print(f\"  Per-Class F1: {results['Model']['Per-Class F1']}\")\n",
        "        print(f\"  Macro F1: {results['Model']['Macro F1']}\")\n",
        "\n",
        "        # --- Validation ---\n",
        "        val_loss = 0\n",
        "        model.eval()  # Set the model to evaluation mode\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                predictions = model(inputs)\n",
        "                loss = criterion(predictions, labels)\n",
        "                val_loss += loss.item()\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        print(f\"  Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "        # Save the model if the validation loss is better than the best so far\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "            print(f\"  Best model saved to {best_model_path} (val_loss={best_val_loss:.4f})\")\n",
        "\n",
        "    # Load the best model\n",
        "    print(f\"Loading best model from {best_model_path}\")\n",
        "    model.load_state_dict(torch.load(best_model_path))\n",
        "\n",
        "train_model(final_model, combined_loader, optimizer, criterion, device, epochs=20)\n",
        "\n",
        "\"\"\"## Evaluate Model\"\"\"\n",
        "\n",
        "def evaluate_data(model, loader, num_classes, num_instances, label_ordering, orig_label_counts, device):\n",
        "    model.eval()\n",
        "    model_pred, labels = get_predictions(loader, model, num_instances, pred_type='model', device=device)\n",
        "    baseline_pred = get_predictions(\n",
        "        loader, model, num_instances, pred_type='baseline',\n",
        "        label_ordering=label_ordering, orig_label_counts=orig_label_counts\n",
        "    )\n",
        "    random_pred = get_predictions(loader, model, num_instances, pred_type='random', num_classes=num_classes)\n",
        "\n",
        "    print()\n",
        "\n",
        "    labels = labels.cpu()\n",
        "    model_pred = model_pred.cpu()\n",
        "    baseline_pred = baseline_pred.cpu()\n",
        "    random_pred = random_pred.cpu()\n",
        "\n",
        "    results, _ = evaluate(labels, num_classes, model_pred, baseline_pred, random_pred, label_ordering)\n",
        "    pprint.pprint(results)\n",
        "\n",
        "    conf_matrix = confusion_matrix(labels.cpu(), model_pred.cpu())\n",
        "    class_labels = label_ordering\n",
        "\n",
        "    def plot_confusion_matrix(conf_matrix, class_labels):\n",
        "        sns.heatmap(\n",
        "            conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
        "            xticklabels=class_labels, yticklabels=class_labels\n",
        "        )\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.xlabel('Predicted Labels')\n",
        "        plt.ylabel('True Labels')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    print(\"\\n\")\n",
        "    plot_confusion_matrix(conf_matrix, class_labels)\n",
        "\n",
        "X_test, _, _, _, y_test = as_tensors(\"test\", label_encoder, input_vector_size, token_to_idx)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "evaluate_data(final_model, test_loader, train_label_counts.shape[0], y_test.size(0), label_encoder.classes_, train_label_counts, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wh01tYUJ2k9a",
        "outputId": "8c73d493-8338-451d-a9cb-513b1b231019"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'dropout': 0.3637721950380055, 'embedding_dim': 150.0, 'hidden_dim': 256.0, 'learning_rate': 0.013031848705016969, 'n_layers': 1.0}\n",
            "The training dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1284 entries, 0 to 1283\n",
            "Data columns (total 14 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   id                    1284 non-null   object\n",
            " 1   label                 1284 non-null   object\n",
            " 2   claim                 1284 non-null   object\n",
            " 3   subject               1284 non-null   object\n",
            " 4   speaker               1284 non-null   object\n",
            " 5   speaker_job_title     939 non-null    object\n",
            " 6   state_info            1005 non-null   object\n",
            " 7   party_affiliation     1284 non-null   object\n",
            " 8   barely_true_counts    1284 non-null   int64 \n",
            " 9   false_counts          1284 non-null   int64 \n",
            " 10  half_true_counts      1284 non-null   int64 \n",
            " 11  mostly_true_counts    1284 non-null   int64 \n",
            " 12  pants_on_fire_counts  1284 non-null   int64 \n",
            " 13  context               1272 non-null   object\n",
            "dtypes: int64(5), object(9)\n",
            "memory usage: 140.6+ KB\n",
            "\n",
            "Data peek:\n",
            "            id        label  \\\n",
            "0   12134.json  barely-true   \n",
            "1     238.json   pants-fire   \n",
            "2    7891.json        false   \n",
            "3    8169.json    half-true   \n",
            "4     929.json    half-true   \n",
            "5    9416.json        false   \n",
            "6    6861.json         true   \n",
            "7    1122.json        false   \n",
            "8   13138.json         true   \n",
            "9    1880.json    half-true   \n",
            "10  12803.json    half-true   \n",
            "11   5409.json        false   \n",
            "12   7313.json    half-true   \n",
            "13   4809.json         true   \n",
            "14   1671.json  barely-true   \n",
            "15   4348.json    half-true   \n",
            "16   6225.json    half-true   \n",
            "17   7675.json  mostly-true   \n",
            "18   2255.json  barely-true   \n",
            "19   9827.json   pants-fire   \n",
            "\n",
            "                                                claim  \\\n",
            "0   We have less Americans working now than in the...   \n",
            "1   When Obama was sworn into office, he DID NOT u...   \n",
            "2   Says Having organizations parading as being so...   \n",
            "3      Says nearly half of Oregons children are poor.   \n",
            "4   On attacks by Republicans that various program...   \n",
            "5   Says when armed civilians stop mass shootings ...   \n",
            "6   Says Tennessee is providing millions of dollar...   \n",
            "7   The health care reform plan would set limits s...   \n",
            "8   Says Donald Trump started his career back in 1...   \n",
            "9   Bill White has a long history of trying to lim...   \n",
            "10  John McCains chief economic adviser during the...   \n",
            "11  Says 21,000 Wisconsin residents got jobs in 20...   \n",
            "12  State revenue projections have missed the mark...   \n",
            "13  The median income of a middle class family wen...   \n",
            "14  Every citizen is entitled to the freedom of sp...   \n",
            "15  Rick Perry has advocated abandoning Social Sec...   \n",
            "16  Two thirds to three quarters of people without...   \n",
            "17  Congress has spent 66 of the first 100 days of...   \n",
            "18  Mark Sharpe has lowered property taxes by 17 p...   \n",
            "19  Says Iowa Gov. Terry Branstad chartered a plan...   \n",
            "\n",
            "                                      subject                 speaker  \\\n",
            "0                                economy,jobs          vicky-hartzler   \n",
            "1            obama-birth-certificate,religion             chain-email   \n",
            "2             campaign-finance,congress,taxes         earl-blumenauer   \n",
            "3                                     poverty         jim-francesconi   \n",
            "4                            economy,stimulus            barack-obama   \n",
            "5                                        guns              jim-rubens   \n",
            "6                      education,state-budget              andy-berke   \n",
            "7                                 health-care             club-growth   \n",
            "8      candidates-biography,diversity,housing         hillary-clinton   \n",
            "9                                    military  republican-party-texas   \n",
            "10                                    economy               tim-kaine   \n",
            "11            job-accomplishments,jobs,states       kathleen-vinehout   \n",
            "12                               state-budget            steve-henson   \n",
            "13                  income,new-hampshire-2012               joe-biden   \n",
            "14                          gays-and-lesbians          david-dewhurst   \n",
            "15             medicaid,social-security,taxes        margaret-carlson   \n",
            "16  health-care,poverty,public-health,welfare       elizabeth-roberts   \n",
            "17                                   congress             john-barrow   \n",
            "18                 candidates-biography,taxes             mark-sharpe   \n",
            "19                                immigration             chain-email   \n",
            "\n",
            "                                speaker_job_title            state_info  \\\n",
            "0                             U.S. Representative              Missouri   \n",
            "1                                             NaN                   NaN   \n",
            "2                             U.S. representative                Oregon   \n",
            "3   Member of the State Board of Higher Education                Oregon   \n",
            "4                                       President              Illinois   \n",
            "5                            Small business owner         New Hampshire   \n",
            "6                        Lawyer and state senator             Tennessee   \n",
            "7                                             NaN                   NaN   \n",
            "8                          Presidential candidate              New York   \n",
            "9                                             NaN                 Texas   \n",
            "10                                   U.S. Senator              Virginia   \n",
            "11                                            NaN                   NaN   \n",
            "12                                  State Senator               Georgia   \n",
            "13                                   U.S. senator              Delaware   \n",
            "14                            Lieutenant governor                 Texas   \n",
            "15                                      Columnist  District of Columbia   \n",
            "16                            Lieutenant Governor          Rhode Island   \n",
            "17                                    Congressman               Georgia   \n",
            "18               Hillsborough County commissioner               Florida   \n",
            "19                                            NaN                   NaN   \n",
            "\n",
            "   party_affiliation  barely_true_counts  false_counts  half_true_counts  \\\n",
            "0         republican                   1             0                 1   \n",
            "1               none                  11            43                 8   \n",
            "2           democrat                   0             1                 1   \n",
            "3               none                   0             1                 1   \n",
            "4           democrat                  70            71               160   \n",
            "5         republican                   1             1                 0   \n",
            "6           democrat                   0             0                 0   \n",
            "7               none                   4             5                 4   \n",
            "8           democrat                  40            29                69   \n",
            "9         republican                   3             1                 1   \n",
            "10          democrat                   8             3                15   \n",
            "11          democrat                   1             1                 1   \n",
            "12          democrat                   0             0                 1   \n",
            "13          democrat                  11            10                21   \n",
            "14        republican                   8             8                10   \n",
            "15              none                   0             0                 1   \n",
            "16          democrat                   1             0                 2   \n",
            "17          democrat                   0             0                 1   \n",
            "18        republican                   1             0                 0   \n",
            "19              none                  11            43                 8   \n",
            "\n",
            "    mostly_true_counts  pants_on_fire_counts  \\\n",
            "0                    0                     0   \n",
            "1                    5                   105   \n",
            "2                    1                     0   \n",
            "3                    1                     0   \n",
            "4                  163                     9   \n",
            "5                    1                     0   \n",
            "6                    0                     0   \n",
            "7                    2                     0   \n",
            "8                   76                     7   \n",
            "9                    3                     1   \n",
            "10                  15                     0   \n",
            "11                   1                     0   \n",
            "12                   0                     0   \n",
            "13                  16                     4   \n",
            "14                   5                     5   \n",
            "15                   0                     0   \n",
            "16                   0                     0   \n",
            "17                   1                     0   \n",
            "18                   0                     0   \n",
            "19                   5                   105   \n",
            "\n",
            "                                              context  \n",
            "0                        an interview with ABC17 News  \n",
            "1                                                 NaN  \n",
            "2                       a U.S. Ways and Means hearing  \n",
            "3                                  an opinion article  \n",
            "4                             interview with CBS News  \n",
            "5         in an interview at gun shop in Hudson, N.H.  \n",
            "6   a letter to state Senate education committee c...  \n",
            "7                                             a TV ad  \n",
            "8                       the first presidential debate  \n",
            "9                                           an e-mail  \n",
            "10  a speech at the Democratic National Convention...  \n",
            "11                                            remarks  \n",
            "12                                    a press release  \n",
            "13  speaking at New Hampshires Plymouth State Uni...  \n",
            "14                                    a press release  \n",
            "15                                 a politics column.  \n",
            "16        a panel discussion on \"A Lively Experiment\"  \n",
            "17                                           a letter  \n",
            "18                                  a campaign mailer  \n",
            "19                                      a chain email  \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3637721950380055 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized sentences(1284 sentences, 55513 total tokens) peek:\n",
            "  ['less', 'americans', 'working', '70s', '.', '|', 'state_info', ':', 'missouri', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'vicky-hartzler', '|', 'subject', ':', 'economy', ',', 'jobs', '|', 'context', ':', 'interview', 'abc17', 'news', '|', 'speaker_job_title', ':', 'u.s.', 'representative', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['obama', 'sworn', 'office', ',', 'use', 'holy', 'bible', ',', 'instead', 'kuran', '(', 'their', 'equivalency', 'bible', ',', 'different', 'beliefs', ')', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'chain-email', '|', 'subject', ':', 'obama-birth-certificate', ',', 'religion', '|', 'context', ':', 'nan', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['says', 'organizations', 'parading', 'social', 'welfare', 'organizations', 'involved', 'political', 'combat', 'harkens', 'back', 'statute', 'hundred', 'years', 'ago', 'said', 'prohibited', '.', '|', 'state_info', ':', 'oregon', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'earl-blumenauer', '|', 'subject', ':', 'campaign-finance', ',', 'congress', ',', 'taxes', '|', 'context', ':', 'u.s.', 'ways', 'means', 'hearing', '|', 'speaker_job_title', ':', 'u.s.']\n",
            "  ['says', 'nearly', 'half', 'oregons', 'children', 'poor', '.', '|', 'state_info', ':', 'oregon', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'jim-francesconi', '|', 'subject', ':', 'poverty', '|', 'context', ':', 'opinion', 'article', '|', 'speaker_job_title', ':', 'member', 'state', 'board', 'higher', 'education', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['attacks', 'republicans', 'various', 'programs', 'economic', 'stimulus', 'plan', 'stimulative', ',', '``', 'if', 'add', 'stuff', 'up', ',', 'accounts', 'less', '1', 'percent', 'overall', 'package', '.', \"''\", '|', 'state_info', ':', 'illinois', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'barack-obama', '|', 'subject', ':', 'economy', ',', 'stimulus', '|', 'context', ':', 'interview', 'cbs', 'news', '|', 'speaker_job_title']\n",
            "  ['says', 'armed', 'civilians', 'stop', 'mass', 'shootings', 'guns', ',', 'average', '2.5', 'people', 'die', ';', 'otherwise', ',', 'average', '18', 'people', 'die', '.', '|', 'state_info', ':', 'new', 'hampshire', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'jim-rubens', '|', 'subject', ':', 'guns', '|', 'context', ':', 'interview', 'gun', 'shop', 'hudson', ',', 'n.h.', '|', 'speaker_job_title', ':']\n",
            "  ['says', 'tennessee', 'providing', 'millions', 'dollars', 'virtual', 'school', 'company', 'results', 'bottom', 'bottom', '.', '|', 'state_info', ':', 'tennessee', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'andy-berke', '|', 'subject', ':', 'education', ',', 'state-budget', '|', 'context', ':', 'letter', 'state', 'senate', 'education', 'committee', 'chairwoman', 'dolores', 'gresham', '.', '|', 'speaker_job_title', ':', 'lawyer', 'state', 'senator', '<PAD>']\n",
            "  ['health', 'care', 'reform', 'plan', 'would', 'set', 'limits', 'similar', 'socialized', 'system', 'britain', ',', 'people', 'allowed', 'die', 'treatment', 'would', 'cost', '$', '22,000', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'club-growth', '|', 'subject', ':', 'health-care', '|', 'context', ':', 'tv', 'ad', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['says', 'donald', 'trump', 'started', 'career', 'back', '1973', 'sued', 'justice', 'department', 'racial', 'discrimination', 'would', 'rent', 'apartments', 'one', 'developments', 'african-americans', '.', '|', 'state_info', ':', 'new', 'york', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'hillary-clinton', '|', 'subject', ':', 'candidates-biography', ',', 'diversity', ',', 'housing', '|', 'context', ':', 'first', 'presidential', 'debate', '|', 'speaker_job_title', ':']\n",
            "  ['bill', 'white', 'long', 'history', 'trying', 'limit', 'even', 'disenfranchise', 'military', 'voters', '.', '|', 'state_info', ':', 'texas', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'republican-party-texas', '|', 'subject', ':', 'military', '|', 'context', ':', 'e-mail', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['john', 'mccains', 'chief', 'economic', 'adviser', '08', 'race', 'estimated', 'trumps', 'promises', 'would', 'cause', 'america', 'lose', '3.5', 'million', 'jobs', '.', '|', 'state_info', ':', 'virginia', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'tim-kaine', '|', 'subject', ':', 'economy', '|', 'context', ':', 'speech', 'democratic', 'national', 'convention', 'philadelphia', '|', 'speaker_job_title', ':', 'u.s.', 'senator', '<PAD>', '<PAD>']\n",
            "  ['says', '21,000', 'wisconsin', 'residents', 'got', 'jobs', '2011', ',', '18,000', 'states', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'kathleen-vinehout', '|', 'subject', ':', 'job-accomplishments', ',', 'jobs', ',', 'states', '|', 'context', ':', 'remarks', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['state', 'revenue', 'projections', 'missed', 'mark', 'month', 'month', '.', '|', 'state_info', ':', 'georgia', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'steve-henson', '|', 'subject', ':', 'state-budget', '|', 'context', ':', 'press', 'release', '|', 'speaker_job_title', ':', 'state', 'senator', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['median', 'income', 'middle', 'class', 'family', 'went', '$', '2,100', '2001', '2007', '.', '|', 'state_info', ':', 'delaware', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'joe-biden', '|', 'subject', ':', 'income', ',', 'new-hampshire-2012', '|', 'context', ':', 'speaking', 'new', 'hampshires', 'plymouth', 'state', 'university', '|', 'speaker_job_title', ':', 'u.s.', 'senator', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['every', 'citizen', 'entitled', 'freedom', 'speech', ',', 'one', 'right', 'use', 'government', 'funds', 'institutions', 'portray', 'acts', 'morally', 'reprehensible', 'vast', 'majority', 'americans', '.', '|', 'state_info', ':', 'texas', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'david-dewhurst', '|', 'subject', ':', 'gays-and-lesbians', '|', 'context', ':', 'press', 'release', '|', 'speaker_job_title', ':', 'lieutenant', 'governor', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['rick', 'perry', 'advocated', 'abandoning', 'social', 'security', ',', 'scuttling', 'medicaid', 'ending', 'federal', 'income', 'tax', '.', '|', 'state_info', ':', 'district', 'columbia', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'margaret-carlson', '|', 'subject', ':', 'medicaid', ',', 'social-security', ',', 'taxes', '|', 'context', ':', 'politics', 'column', '.', '|', 'speaker_job_title', ':', 'columnist', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['two', 'thirds', 'three', 'quarters', 'people', 'without', '[', 'health', ']', 'insurance', 'rhode', 'island', 'work', '.', '|', 'state_info', ':', 'rhode', 'island', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'elizabeth-roberts', '|', 'subject', ':', 'health-care', ',', 'poverty', ',', 'public-health', ',', 'welfare', '|', 'context', ':', 'panel', 'discussion', '``', 'a', 'lively', 'experiment', \"''\", '|', 'speaker_job_title']\n",
            "  ['congress', 'spent', '66', 'first', '100', 'days', 'term', 'recess', '.', '|', 'state_info', ':', 'georgia', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'john-barrow', '|', 'subject', ':', 'congress', '|', 'context', ':', 'letter', '|', 'speaker_job_title', ':', 'congressman', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['mark', 'sharpe', 'lowered', 'property', 'taxes', '17', 'percent', '.', '|', 'state_info', ':', 'florida', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'mark-sharpe', '|', 'subject', ':', 'candidates-biography', ',', 'taxes', '|', 'context', ':', 'campaign', 'mailer', '|', 'speaker_job_title', ':', 'hillsborough', 'county', 'commissioner', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['says', 'iowa', 'gov', '.', 'terry', 'branstad', 'chartered', 'plane', 'remove', '124', 'young', 'illegal', 'immigrants', 'state', 'take', 'back', 'honduras', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'chain-email', '|', 'subject', ':', 'immigration', '|', 'context', ':', 'chain', 'email', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "\n",
            "10000 unique tokens\n",
            "Unique tokens peek:\n",
            "  <PAD>\n",
            "  |\n",
            "  :\n",
            "  ,\n",
            "  .\n",
            "  speaker\n",
            "  state_info\n",
            "  party_affiliation\n",
            "  subject\n",
            "  context\n",
            "  speaker_job_title\n",
            "  republican\n",
            "  nan\n",
            "  democrat\n",
            "  says\n",
            "  u.s.\n",
            "  none\n",
            "  interview\n",
            "  new\n",
            "  state\n",
            "\n",
            "Final Index Sets(Set_Size = 49, 1284 index sets) peek:\n",
            "  [233, 152, 406, 0, 5, 2, 7, 3, 542, 2, 8, 3, 12, 2, 6, 3, 7845, 2, 9, 3, 25, 4, 29, 2, 10, 3, 18, 0, 40, 2, 11, 3, 16, 62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [47, 4897, 164, 4, 367, 0, 2946, 4, 1497, 0, 37, 5601, 0, 2946, 4, 986, 3042, 38, 5, 2, 7, 3, 13, 2, 8, 3, 17, 2, 6, 3, 267, 2, 9, 3, 1208, 4, 263, 2, 10, 3, 13, 2, 11, 3, 13, 1, 1, 1, 1]\n",
            "  [15, 2200, 0, 143, 417, 2200, 1784, 201, 2652, 0, 382, 6648, 3469, 59, 431, 91, 4005, 5, 2, 7, 3, 104, 2, 8, 3, 14, 2, 6, 3, 4008, 2, 9, 3, 197, 4, 81, 4, 23, 2, 10, 3, 16, 2904, 1000, 360, 2, 11, 3, 16]\n",
            "  [15, 208, 272, 1734, 113, 1149, 5, 2, 7, 3, 104, 2, 8, 3, 17, 2, 6, 3, 7618, 2, 9, 3, 159, 2, 10, 3, 446, 249, 2, 11, 3, 186, 20, 274, 337, 39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [1042, 262, 1272, 701, 365, 131, 128, 0, 4, 24, 2500, 1409, 6121, 712, 4, 1823, 233, 165, 30, 1782, 1897, 5, 27, 2, 7, 3, 61, 2, 8, 3, 14, 2, 6, 3, 73, 2, 9, 3, 25, 4, 131, 2, 10, 3, 18, 653, 40, 2, 11]\n",
            "  [15, 3343, 8780, 583, 1190, 1317, 85, 4, 181, 1929, 60, 1117, 956, 4391, 4, 181, 723, 60, 1117, 5, 2, 7, 3, 19, 216, 2, 8, 3, 12, 2, 6, 3, 8012, 2, 9, 3, 85, 2, 10, 3, 18, 286, 6258, 6434, 4, 474, 2, 11, 3]\n",
            "  [15, 412, 3615, 383, 214, 0, 137, 561, 3447, 1121, 1121, 5, 2, 7, 3, 412, 2, 8, 3, 14, 2, 6, 3, 0, 2, 9, 3, 39, 4, 52, 2, 10, 3, 297, 20, 66, 39, 221, 2932, 0, 0, 5, 2, 11, 3, 620, 20, 32, 1]\n",
            "  [57, 68, 329, 128, 65, 1226, 2697, 1696, 4097, 302, 3782, 4, 60, 636, 1117, 1943, 65, 230, 26, 4190, 5, 2, 7, 3, 13, 2, 8, 3, 17, 2, 6, 3, 1682, 2, 9, 3, 31, 2, 10, 3, 78, 42, 2, 11, 3, 13, 1, 1, 1]\n",
            "  [15, 259, 225, 783, 1298, 382, 3164, 3318, 656, 296, 4433, 2436, 65, 2397, 4408, 77, 0, 2098, 5, 2, 7, 3, 19, 45, 2, 8, 3, 14, 2, 6, 3, 153, 2, 9, 3, 54, 4, 420, 4, 348, 2, 10, 3, 129, 70, 46, 2, 11, 3]\n",
            "  [80, 260, 1080, 63, 904, 1470, 156, 0, 82, 362, 5, 2, 7, 3, 21, 2, 8, 3, 12, 2, 6, 3, 2796, 2, 9, 3, 82, 2, 10, 3, 281, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [238, 5764, 833, 365, 1498, 0, 970, 1252, 1329, 3110, 65, 987, 163, 807, 2907, 71, 29, 5, 2, 7, 3, 69, 2, 8, 3, 14, 2, 6, 3, 765, 2, 9, 3, 25, 2, 10, 3, 33, 117, 102, 218, 847, 2, 11, 3, 16, 32, 1, 1]\n",
            "  [15, 0, 34, 665, 340, 29, 354, 4, 3610, 44, 5, 2, 7, 3, 13, 2, 8, 3, 14, 2, 6, 3, 5288, 2, 9, 3, 124, 4, 29, 4, 44, 2, 10, 3, 276, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [20, 610, 4525, 2023, 954, 533, 533, 5, 2, 7, 3, 58, 2, 8, 3, 14, 2, 6, 3, 0, 2, 9, 3, 52, 2, 10, 3, 50, 53, 2, 11, 3, 20, 32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [1735, 103, 538, 607, 411, 388, 26, 6210, 1467, 1155, 5, 2, 7, 3, 496, 2, 8, 3, 14, 2, 6, 3, 563, 2, 9, 3, 103, 4, 558, 2, 10, 3, 2858, 19, 8844, 8712, 20, 306, 2, 11, 3, 16, 32, 1, 1, 1, 1, 1, 1]\n",
            "  [89, 2193, 0, 1235, 33, 4, 77, 235, 367, 110, 624, 2150, 0, 4557, 0, 0, 2268, 292, 152, 5, 2, 7, 3, 21, 2, 8, 3, 12, 2, 6, 3, 1062, 2, 9, 3, 339, 2, 10, 3, 50, 53, 2, 11, 3, 461, 35, 1, 1, 1]\n",
            "  [251, 541, 2342, 0, 143, 182, 4, 0, 223, 2222, 96, 103, 51, 5, 2, 7, 3, 127, 1406, 2, 8, 3, 17, 2, 6, 3, 0, 2, 9, 3, 223, 4, 312, 4, 23, 2, 10, 3, 1271, 224, 5, 2, 11, 3, 448, 1, 1, 1, 1]\n",
            "  [209, 5565, 207, 6449, 60, 317, 253, 57, 254, 177, 72, 74, 316, 5, 2, 7, 3, 72, 74, 2, 8, 3, 14, 2, 6, 3, 5065, 2, 9, 3, 31, 4, 159, 4, 169, 4, 417, 2, 10, 3, 824, 559, 24, 603, 8771, 5951, 27, 2, 11]\n",
            "  [81, 335, 4273, 129, 393, 524, 813, 0, 5, 2, 7, 3, 58, 2, 8, 3, 14, 2, 6, 3, 0, 2, 9, 3, 81, 2, 10, 3, 297, 2, 11, 3, 188, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [954, 0, 5036, 476, 23, 958, 30, 5, 2, 7, 3, 22, 2, 8, 3, 12, 2, 6, 3, 0, 2, 9, 3, 54, 4, 23, 2, 10, 3, 36, 356, 2, 11, 3, 2686, 87, 481, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [15, 307, 191, 5, 2806, 0, 0, 2575, 1744, 0, 655, 219, 353, 20, 344, 382, 4784, 5, 2, 7, 3, 13, 2, 8, 3, 17, 2, 6, 3, 267, 2, 9, 3, 56, 2, 10, 3, 414, 184, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1]\n",
            "VALID SPLIT: 1284 overall samples: torch.Size([1284, 49])\n",
            "Epoch 1/20 | Loss: 0.5331 | Accuracy: 0.6757\n",
            "  Per-Class Precision: {'false': 0.6231535860473394, 'true': 0.8575384615384616}\n",
            "  Per-Class Recall: {'false': 0.9379855344227163, 'true': 0.39689547137567643}\n",
            "  Per-Class F1: {'false': 0.7488237810094097, 'true': 0.5426401869158879}\n",
            "  Macro F1: 0.6457319839626487\n",
            "  Validation Loss: 0.5138\n",
            "  Best model saved to best_model.pth (val_loss=0.5138)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "cudnn RNN backward can only be called in training mode",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-e7b0b5700c3c>\u001b[0m in \u001b[0;36m<cell line: 103>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\"\"\"## Evaluate Model\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-e7b0b5700c3c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, optimizer, criterion, device, epochs)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cudnn RNN backward can only be called in training mode"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train final model with best hyperparameters\n",
        "print(\"Best Hyperparameters:\", best)\n",
        "best_params = {\n",
        "    'embedding_dim': int(best['embedding_dim']),\n",
        "    'hidden_dim': int(best['hidden_dim']),\n",
        "    'n_layers': int(best['n_layers']),\n",
        "    'dropout': best['dropout'],\n",
        "    'learning_rate': best['learning_rate']\n",
        "}\n",
        "\n",
        "final_model = BiLSTMModel(\n",
        "    input_dim=train_vocab_size + 1,\n",
        "    embedding_dim=best_params['embedding_dim'],\n",
        "    hidden_dim=best_params['hidden_dim'],\n",
        "    output_dim=train_label_counts.shape[0],\n",
        "    n_layers=best_params['n_layers'],\n",
        "    dropout=best_params['dropout']\n",
        ")\n",
        "final_model.to(device)\n",
        "\n",
        "optimizer = optim.AdamW(final_model.parameters(), lr=best_params['learning_rate'])\n",
        "\n",
        "# Example of using class weights:\n",
        "class_weights = torch.tensor([2.0, 1.0], dtype=torch.float).to(device) # You might need to adjust these\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "criterion.to(device)\n",
        "\n",
        "# Train the final model on the combined training and validation sets\n",
        "combined_X = torch.cat((X_train, X_val), dim=0)\n",
        "combined_y = torch.cat((y_train, y_val), dim=0)\n",
        "combined_dataset = TensorDataset(combined_X, combined_y)\n",
        "combined_loader = DataLoader(combined_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "def train_model(model, dataloader, optimizer, criterion, device, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        epoch_tps = 0\n",
        "        total_samples = 0\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(inputs)\n",
        "            loss = criterion(predictions, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()  # Track total loss\n",
        "            # Track total accuracy\n",
        "            _, predicted_classes = torch.max(predictions, 1)\n",
        "            epoch_tps += (predicted_classes == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(predicted_classes.cpu().numpy())\n",
        "\n",
        "        y_true = torch.tensor(y_true, dtype=torch.long)\n",
        "        y_pred = torch.tensor(y_pred, dtype=torch.long)\n",
        "\n",
        "        results, f1_macro = evaluate(y_true, train_label_counts.shape[0], y_pred, y_pred, y_pred, label_encoder.classes_) # Pass dummy values for baseline and random\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {epoch_loss/len(dataloader):.4f} | Accuracy: {epoch_tps/total_samples:.4f}\")\n",
        "        print(f\"  Per-Class Precision: {results['Model']['Per-Class Precision']}\")\n",
        "        print(f\"  Per-Class Recall: {results['Model']['Per-Class Recall']}\")\n",
        "        print(f\"  Per-Class F1: {results['Model']['Per-Class F1']}\")\n",
        "        print(f\"  Macro F1: {results['Model']['Macro F1']}\")\n",
        "\n",
        "train_model(final_model, combined_loader, optimizer, criterion, device, epochs=20)\n",
        "\n",
        "\"\"\"## Evaluate Model\"\"\"\n",
        "\n",
        "def evaluate_data(model, loader, num_classes, num_instances, label_ordering, orig_label_counts, device):\n",
        "    model_pred, labels = get_predictions(loader, model, num_instances, pred_type='model', device=device)\n",
        "    baseline_pred = get_predictions(\n",
        "        loader, model, num_instances, pred_type='baseline',\n",
        "        label_ordering=label_ordering, orig_label_counts=orig_label_counts\n",
        "    )\n",
        "    random_pred = get_predictions(loader, model, num_instances, pred_type='random', num_classes=num_classes)\n",
        "\n",
        "    print()\n",
        "\n",
        "    labels = labels.cpu()\n",
        "    model_pred = model_pred.cpu()\n",
        "    baseline_pred = baseline_pred.cpu()\n",
        "    random_pred = random_pred.cpu()\n",
        "\n",
        "    results, _ = evaluate(labels, num_classes, model_pred, baseline_pred, random_pred, label_ordering)\n",
        "    pprint.pprint(results)\n",
        "\n",
        "    conf_matrix = confusion_matrix(labels.cpu(), model_pred.cpu())\n",
        "    class_labels = label_ordering\n",
        "\n",
        "    def plot_confusion_matrix(conf_matrix, class_labels):\n",
        "        sns.heatmap(\n",
        "            conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
        "            xticklabels=class_labels, yticklabels=class_labels\n",
        "        )\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.xlabel('Predicted Labels')\n",
        "        plt.ylabel('True Labels')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    print(\"\\n\")\n",
        "    plot_confusion_matrix(conf_matrix, class_labels)\n",
        "\n",
        "X_test, _, _, _, y_test = as_tensors(\"test\", label_encoder, input_vector_size, token_to_idx)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "evaluate_data(final_model, test_loader, train_label_counts.shape[0], y_test.size(0), label_encoder.classes_, train_label_counts, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8Qdg3EwAurfy",
        "outputId": "7cb2dae7-f4d2-4991-839d-b0844e8f7583"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'dropout': 0.3637721950380055, 'embedding_dim': 150.0, 'hidden_dim': 256.0, 'learning_rate': 0.013031848705016969, 'n_layers': 1.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3637721950380055 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 | Loss: 0.5543 | Accuracy: 0.6553\n",
            "  Per-Class Precision: {'false': 0.6094386399858331, 'true': 0.8174702567313713}\n",
            "  Per-Class Recall: {'false': 0.9219126707741763, 'true': 0.37183138706921104}\n",
            "  Per-Class F1: {'false': 0.7337953091684435, 'true': 0.5111589663273297}\n",
            "  Macro F1: 0.6224771377478866\n",
            "Epoch 2/20 | Loss: 0.4560 | Accuracy: 0.7242\n",
            "  Per-Class Precision: {'false': 0.6630639097744361, 'true': 0.8931912681912682}\n",
            "  Per-Class Recall: {'false': 0.9449504420037503, 'true': 0.48946169182569066}\n",
            "  Per-Class F1: {'false': 0.7792996796641997, 'true': 0.6323827046918123}\n",
            "  Macro F1: 0.705841192178006\n",
            "Epoch 3/20 | Loss: 0.4162 | Accuracy: 0.7587\n",
            "  Per-Class Precision: {'false': 0.702468380252958, 'true': 0.8763877028181042}\n",
            "  Per-Class Recall: {'false': 0.9224484328957943, 'true': 0.5845912845343207}\n",
            "  Per-Class F1: {'false': 0.7975680370584829, 'true': 0.7013497351785409}\n",
            "  Macro F1: 0.7494588861185119\n",
            "Epoch 4/20 | Loss: 0.3672 | Accuracy: 0.7922\n",
            "  Per-Class Precision: {'false': 0.7388739946380697, 'true': 0.8884369552585706}\n",
            "  Per-Class Recall: {'false': 0.9228502544870077, 'true': 0.6532326972372543}\n",
            "  Per-Class F1: {'false': 0.8206777440295396, 'true': 0.7528929011079196}\n",
            "  Macro F1: 0.7867853225687296\n",
            "Epoch 5/20 | Loss: 0.3667 | Accuracy: 0.8080\n",
            "  Per-Class Precision: {'false': 0.758613074204947, 'true': 0.8902798232695139}\n",
            "  Per-Class Recall: {'false': 0.9201714438789178, 'true': 0.6886926801481059}\n",
            "  Per-Class F1: {'false': 0.8316184481297664, 'true': 0.7766179540709812}\n",
            "  Macro F1: 0.8041182011003738\n",
            "Epoch 6/20 | Loss: 0.3314 | Accuracy: 0.8212\n",
            "  Per-Class Precision: {'false': 0.7730734767025089, 'true': 0.8985611510791367}\n",
            "  Per-Class Recall: {'false': 0.9244575408518618, 'true': 0.7114782113358018}\n",
            "  Per-Class F1: {'false': 0.8420153714773698, 'true': 0.7941503735495152}\n",
            "  Macro F1: 0.8180828725134426\n",
            "Epoch 7/20 | Loss: 0.3141 | Accuracy: 0.8347\n",
            "  Per-Class Precision: {'false': 0.7892095357590966, 'true': 0.904387344869778}\n",
            "  Per-Class Recall: {'false': 0.9267345298687383, 'true': 0.7368271147821134}\n",
            "  Per-Class F1: {'false': 0.8524610361609068, 'true': 0.8120536765282901}\n",
            "  Macro F1: 0.8322573563445985\n",
            "Epoch 8/20 | Loss: 0.2897 | Accuracy: 0.8515\n",
            "  Per-Class Precision: {'false': 0.8090475636701943, 'true': 0.913567668534556}\n",
            "  Per-Class Recall: {'false': 0.9318242700241093, 'true': 0.7661634861862717}\n",
            "  Per-Class F1: {'false': 0.8661064425770308, 'true': 0.8333978777786384}\n",
            "  Macro F1: 0.8497521601778346\n",
            "Epoch 9/20 | Loss: 0.3087 | Accuracy: 0.8450\n",
            "  Per-Class Precision: {'false': 0.8037709497206704, 'true': 0.9050203527815468}\n",
            "  Per-Class Recall: {'false': 0.9249933029734798, 'true': 0.7598974651096554}\n",
            "  Per-Class F1: {'false': 0.860132021422344, 'true': 0.8261340764824276}\n",
            "  Macro F1: 0.8431330489523858\n",
            "Epoch 10/20 | Loss: 0.4020 | Accuracy: 0.8002\n",
            "  Per-Class Precision: {'false': 0.7550200803212851, 'true': 0.8736422881969588}\n",
            "  Per-Class Recall: {'false': 0.9065095097776588, 'true': 0.687268584448875}\n",
            "  Per-Class F1: {'false': 0.8238587948874011, 'true': 0.7693288697592858}\n",
            "  Macro F1: 0.7965938323233435\n",
            "Epoch 11/20 | Loss: 0.4245 | Accuracy: 0.7803\n",
            "  Per-Class Precision: {'false': 0.7320906036631625, 'true': 0.8648545903820567}\n",
            "  Per-Class Recall: {'false': 0.9047682828824002, 'true': 0.6479635431500997}\n",
            "  Per-Class F1: {'false': 0.8093212723896244, 'true': 0.7408613530896361}\n",
            "  Macro F1: 0.7750913127396302\n",
            "Epoch 12/20 | Loss: 0.4142 | Accuracy: 0.7864\n",
            "  Per-Class Precision: {'false': 0.7380459644918854, 'true': 0.8699830412662521}\n",
            "  Per-Class Recall: {'false': 0.9075810340208947, 'true': 0.6575049843349473}\n",
            "  Per-Class F1: {'false': 0.8140806151258485, 'true': 0.7489658528672236}\n",
            "  Macro F1: 0.7815232339965361\n",
            "Epoch 13/20 | Loss: 0.4206 | Accuracy: 0.7794\n",
            "  Per-Class Precision: {'false': 0.730561555075594, 'true': 0.8659143075745983}\n",
            "  Per-Class Recall: {'false': 0.9061076881864453, 'true': 0.6446881230418684}\n",
            "  Per-Class F1: {'false': 0.8089202439316034, 'true': 0.7391020408163266}\n",
            "  Macro F1: 0.7740111423739651\n",
            "Epoch 14/20 | Loss: 0.4520 | Accuracy: 0.7655\n",
            "  Per-Class Precision: {'false': 0.7175401069518716, 'true': 0.85266640716232}\n",
            "  Per-Class Recall: {'false': 0.8986070184837932, 'true': 0.623896325833096}\n",
            "  Per-Class F1: {'false': 0.797930542340628, 'true': 0.7205592105263158}\n",
            "  Macro F1: 0.7592448764334718\n",
            "Epoch 15/20 | Loss: 0.5911 | Accuracy: 0.6857\n",
            "  Per-Class Precision: {'false': 0.6504754030591153, 'true': 0.7564422277639236}\n",
            "  Per-Class Recall: {'false': 0.8430216983659256, 'true': 0.5183708345200797}\n",
            "  Per-Class F1: {'false': 0.7343367168358418, 'true': 0.6151766097684638}\n",
            "  Macro F1: 0.6747566633021528\n",
            "Epoch 16/20 | Loss: 0.5962 | Accuracy: 0.6706\n",
            "  Per-Class Precision: {'false': 0.6370483460559796, 'true': 0.7411537636714561}\n",
            "  Per-Class Recall: {'false': 0.838333779801768, 'true': 0.4921674736542296}\n",
            "  Per-Class F1: {'false': 0.7239604418483604, 'true': 0.5915275994865212}\n",
            "  Macro F1: 0.6577440206674408\n",
            "Epoch 17/20 | Loss: 0.5975 | Accuracy: 0.6713\n",
            "  Per-Class Precision: {'false': 0.6373425436814303, 'true': 0.7433247200689062}\n",
            "  Per-Class Recall: {'false': 0.8403428877578355, 'true': 0.49159783537453716}\n",
            "  Per-Class F1: {'false': 0.7248989023685731, 'true': 0.5918052460140579}\n",
            "  Macro F1: 0.6583520741913156\n",
            "Epoch 18/20 | Loss: 0.5975 | Accuracy: 0.6764\n",
            "  Per-Class Precision: {'false': 0.6415902140672783, 'true': 0.7494655835827276}\n",
            "  Per-Class Recall: {'false': 0.8430216983659256, 'true': 0.4992879521503845}\n",
            "  Per-Class F1: {'false': 0.7286408890946978, 'true': 0.5993162393162393}\n",
            "  Macro F1: 0.6639785642054685\n",
            "Epoch 19/20 | Loss: 0.6178 | Accuracy: 0.6573\n",
            "  Per-Class Precision: {'false': 0.627044600223509, 'true': 0.7214208826695372}\n",
            "  Per-Class Recall: {'false': 0.8266809536565765, 'true': 0.47721446881230417}\n",
            "  Per-Class F1: {'false': 0.7131550060662083, 'true': 0.5744407302648495}\n",
            "  Macro F1: 0.643797868165529\n",
            "Epoch 20/20 | Loss: 0.5992 | Accuracy: 0.6699\n",
            "  Per-Class Precision: {'false': 0.6369108345235667, 'true': 0.7390098164746052}\n",
            "  Per-Class Recall: {'false': 0.836190731315296, 'true': 0.49316434064369125}\n",
            "  Per-Class F1: {'false': 0.7230715774843641, 'true': 0.5915613255893406}\n",
            "  Macro F1: 0.6573164515368524\n",
            "The training dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1267 entries, 0 to 1266\n",
            "Data columns (total 14 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   id                    1267 non-null   object\n",
            " 1   label                 1267 non-null   object\n",
            " 2   claim                 1267 non-null   object\n",
            " 3   subject               1267 non-null   object\n",
            " 4   speaker               1267 non-null   object\n",
            " 5   speaker_job_title     942 non-null    object\n",
            " 6   state_info            1005 non-null   object\n",
            " 7   party_affiliation     1267 non-null   object\n",
            " 8   barely_true_counts    1267 non-null   int64 \n",
            " 9   false_counts          1267 non-null   int64 \n",
            " 10  half_true_counts      1267 non-null   int64 \n",
            " 11  mostly_true_counts    1267 non-null   int64 \n",
            " 12  pants_on_fire_counts  1267 non-null   int64 \n",
            " 13  context               1250 non-null   object\n",
            "dtypes: int64(5), object(9)\n",
            "memory usage: 138.7+ KB\n",
            "\n",
            "Data peek:\n",
            "            id        label  \\\n",
            "0   11972.json         true   \n",
            "1   11685.json        false   \n",
            "2   11096.json        false   \n",
            "3    5209.json    half-true   \n",
            "4    9524.json   pants-fire   \n",
            "5    5962.json         true   \n",
            "6    7070.json         true   \n",
            "7    1046.json  barely-true   \n",
            "8   12849.json         true   \n",
            "9   13270.json  barely-true   \n",
            "10   6649.json  barely-true   \n",
            "11   2508.json  barely-true   \n",
            "12  11269.json   pants-fire   \n",
            "13  11200.json        false   \n",
            "14   8047.json    half-true   \n",
            "15   4888.json         true   \n",
            "16   3331.json   pants-fire   \n",
            "17   9198.json    half-true   \n",
            "18     73.json         true   \n",
            "19   1328.json        false   \n",
            "\n",
            "                                                claim  \\\n",
            "0   Building a wall on the U.S.-Mexico border will...   \n",
            "1   Wisconsin is on pace to double the number of l...   \n",
            "2   Says John McCain has done nothing to help the ...   \n",
            "3   Suzanne Bonamici supports a plan that will cut...   \n",
            "4   When asked by a reporter whether hes at the ce...   \n",
            "5   Over the past five years the federal governmen...   \n",
            "6   Says that Tennessee law requires that schools ...   \n",
            "7   Says Vice President Joe Biden \"admits that the...   \n",
            "8   Donald Trump is against marriage equality. He ...   \n",
            "9   We know that more than half of Hillary Clinton...   \n",
            "10  We know there are more Democrats in Georgia th...   \n",
            "11  PolitiFact Texas says Congressman Edwards atta...   \n",
            "12         Denali is the Kenyan word for black power.   \n",
            "13  Says 57 percent of federal spending goes to th...   \n",
            "14       On residency requirements for public workers   \n",
            "15  Says the unemployment rate for college graduat...   \n",
            "16  Unfortunately we have documented instances whe...   \n",
            "17  A recent Gallup poll found that 72 percent of ...   \n",
            "18  Each year, 18,000 people die in America becaus...   \n",
            "19  Ronald Reagan faced an even worse recession th...   \n",
            "\n",
            "                                              subject  \\\n",
            "0                                         immigration   \n",
            "1                                                jobs   \n",
            "2                     military,veterans,voting-record   \n",
            "3   medicare,message-machine-2012,campaign-adverti...   \n",
            "4   campaign-finance,legal-issues,campaign-adverti...   \n",
            "5                  federal-budget,pensions,retirement   \n",
            "6     county-budget,county-government,education,taxes   \n",
            "7                                    economy,stimulus   \n",
            "8                          gays-and-lesbians,marriage   \n",
            "9                                      foreign-policy   \n",
            "10                                          elections   \n",
            "11                             ethics,message-machine   \n",
            "12                                        environment   \n",
            "13                    federal-budget,military,poverty   \n",
            "14           city-government,county-government,unions   \n",
            "15                                     education,jobs   \n",
            "16                                 labor,state-budget   \n",
            "17  government-efficiency,government-regulation,polls   \n",
            "18                                        health-care   \n",
            "19                                    economy,history   \n",
            "\n",
            "                             speaker  \\\n",
            "0                         rick-perry   \n",
            "1                  katrina-shankland   \n",
            "2                       donald-trump   \n",
            "3                      rob-cornilles   \n",
            "4   state-democratic-party-wisconsin   \n",
            "5                    brendan-doherty   \n",
            "6           stand-children-tennessee   \n",
            "7                       john-boehner   \n",
            "8               sean-patrick-maloney   \n",
            "9                         mike-pence   \n",
            "10                       mike-berlon   \n",
            "11                       bill-flores   \n",
            "12                       viral-image   \n",
            "13                    facebook-posts   \n",
            "14                       chris-abele   \n",
            "15                     rick-santorum   \n",
            "16                       tom-niehaus   \n",
            "17                  marsha-blackburn   \n",
            "18                   hillary-clinton   \n",
            "19                       sarah-palin   \n",
            "\n",
            "                             speaker_job_title    state_info  \\\n",
            "0                                     Governor         Texas   \n",
            "1                         State representative     Wisconsin   \n",
            "2                              President-Elect      New York   \n",
            "3                                   consultant        Oregon   \n",
            "4                                          NaN     Wisconsin   \n",
            "5                                          NaN  Rhode Island   \n",
            "6   Child and education advocacy organization.     Tennessee   \n",
            "7      Speaker of the House of Representatives          Ohio   \n",
            "8                        Congressman for NY-18      New York   \n",
            "9                                     Governor       Indiana   \n",
            "10                                         NaN       Georgia   \n",
            "11                                 Businessman         Texas   \n",
            "12                                         NaN           NaN   \n",
            "13                        Social media posting           NaN   \n",
            "14                              Philanthropist     Wisconsin   \n",
            "15                                         NaN  Pennsylvania   \n",
            "16                President of the Ohio Senate          Ohio   \n",
            "17                         U.S. Representative     Tennessee   \n",
            "18                      Presidential candidate      New York   \n",
            "19                                         NaN        Alaska   \n",
            "\n",
            "   party_affiliation  barely_true_counts  false_counts  half_true_counts  \\\n",
            "0         republican                  30            30                42   \n",
            "1           democrat                   2             1                 0   \n",
            "2         republican                  63           114                51   \n",
            "3         republican                   1             1                 3   \n",
            "4           democrat                   5             7                 2   \n",
            "5         republican                   1             2                 1   \n",
            "6               none                   0             0                 0   \n",
            "7         republican                  13            22                11   \n",
            "8           democrat                   0             0                 0   \n",
            "9         republican                   8            10                12   \n",
            "10          democrat                   1             0                 0   \n",
            "11        republican                   2             0                 0   \n",
            "12              none                   5             5                 0   \n",
            "13              none                  14            18                15   \n",
            "14              none                   3             5                 4   \n",
            "15        republican                  12            16                13   \n",
            "16        republican                   0             0                 0   \n",
            "17        republican                   2             2                 1   \n",
            "18          democrat                  40            29                69   \n",
            "19        republican                   9            19                 9   \n",
            "\n",
            "    mostly_true_counts  pants_on_fire_counts  \\\n",
            "0                   23                    18   \n",
            "1                    0                     0   \n",
            "2                   37                    61   \n",
            "3                    1                     1   \n",
            "4                    2                     7   \n",
            "5                    1                     0   \n",
            "6                    0                     0   \n",
            "7                    4                     2   \n",
            "8                    0                     0   \n",
            "9                    5                     0   \n",
            "10                   0                     0   \n",
            "11                   0                     0   \n",
            "12                   3                    15   \n",
            "13                  11                    36   \n",
            "14                   4                     2   \n",
            "15                   7                     5   \n",
            "16                   0                     1   \n",
            "17                   0                     0   \n",
            "18                  76                     7   \n",
            "19                   6                     6   \n",
            "\n",
            "                                            context  \n",
            "0                                   Radio interview  \n",
            "1                                 a news conference  \n",
            "2                      comments on ABC's This Week.  \n",
            "3                                      a radio show  \n",
            "4                                       a web video  \n",
            "5                                a campaign website  \n",
            "6                            in a post on Facebook.  \n",
            "7                                  a press release.  \n",
            "8    a speech at the Democratic National Convention  \n",
            "9                      comments on \"Meet the Press\"  \n",
            "10                                       an article  \n",
            "11                                         a TV ad.  \n",
            "12                      an image shared on Facebook  \n",
            "13                           a meme on social media  \n",
            "14                                         a letter  \n",
            "15                                         a speech  \n",
            "16                        interviews with reporters  \n",
            "17  a speech to the Freedom Summit in New Hampshire  \n",
            "18                    a speech in Des Moines, Iowa.  \n",
            "19                            her book, Going Rogue  \n",
            "\n",
            "Tokenized sentences(1267 sentences, 55177 total tokens) peek:\n",
            "  ['building', 'wall', 'u.s.-mexico', 'border', 'take', 'literally', 'years', '.', '|', 'state_info', ':', 'texas', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'rick-perry', '|', 'subject', ':', 'immigration', '|', 'context', ':', 'radio', 'interview', '|', 'speaker_job_title', ':', 'governor', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['wisconsin', 'pace', 'double', 'number', 'layoffs', 'year', '.', '|', 'state_info', ':', 'wisconsin', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'katrina-shankland', '|', 'subject', ':', 'jobs', '|', 'context', ':', 'news', 'conference', '|', 'speaker_job_title', ':', 'state', 'representative', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['says', 'john', 'mccain', 'done', 'nothing', 'help', 'vets', '.', '|', 'state_info', ':', 'new', 'york', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'donald-trump', '|', 'subject', ':', 'military', ',', 'veterans', ',', 'voting-record', '|', 'context', ':', 'comments', 'abc', \"'s\", 'week', '.', '|', 'speaker_job_title', ':', 'president-elect', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['suzanne', 'bonamici', 'supports', 'plan', 'cut', 'choice', 'medicare', 'advantage', 'seniors', '.', '|', 'state_info', ':', 'oregon', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'rob-cornilles', '|', 'subject', ':', 'medicare', ',', 'message-machine-2012', ',', 'campaign-advertising', '|', 'context', ':', 'radio', 'show', '|', 'speaker_job_title', ':', 'consultant', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['asked', 'reporter', 'whether', 'hes', 'center', 'criminal', 'scheme', 'violate', 'campaign', 'laws', ',', 'gov', '.', 'scott', 'walker', 'nodded', 'yes', '.', '|', 'state_info', ':', 'wisconsin', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'state-democratic-party-wisconsin', '|', 'subject', ':', 'campaign-finance', ',', 'legal-issues', ',', 'campaign-advertising', '|', 'context', ':', 'web', 'video', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>']\n",
            "  ['past', 'five', 'years', 'federal', 'government', 'paid', '$', '601', 'million', 'retirement', 'disability', 'benefits', 'deceased', 'former', 'federal', 'employees', '.', '|', 'state_info', ':', 'rhode', 'island', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'brendan-doherty', '|', 'subject', ':', 'federal-budget', ',', 'pensions', ',', 'retirement', '|', 'context', ':', 'campaign', 'website', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>']\n",
            "  ['says', 'tennessee', 'law', 'requires', 'schools', 'receive', 'half', 'proceeds', '--', '$', '31', 'million', 'per', 'year', '--', 'half-cent', 'increase', 'shelby', 'county', 'sales', 'tax', '.', '|', 'state_info', ':', 'tennessee', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'stand-children-tennessee', '|', 'subject', ':', 'county-budget', ',', 'county-government', ',', 'education', ',', 'taxes', '|', 'context', ':', 'post', 'facebook']\n",
            "  ['says', 'vice', 'president', 'joe', 'biden', '``', 'admits', 'american', 'people', 'scammed', \"''\", 'economic', 'stimulus', 'package', '.', '|', 'state_info', ':', 'ohio', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'john-boehner', '|', 'subject', ':', 'economy', ',', 'stimulus', '|', 'context', ':', 'press', 'release', '.', '|', 'speaker_job_title', ':', 'speaker', 'house', 'representatives', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['donald', 'trump', 'marriage', 'equality', '.', 'wants', 'go', 'back', '.', '|', 'state_info', ':', 'new', 'york', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'sean-patrick-maloney', '|', 'subject', ':', 'gays-and-lesbians', ',', 'marriage', '|', 'context', ':', 'speech', 'democratic', 'national', 'convention', '|', 'speaker_job_title', ':', 'congressman', 'ny-18', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['know', 'half', 'hillary', 'clintons', 'meetings', 'secretary', 'state', 'given', 'major', 'contributors', 'clinton', 'foundation', '.', '|', 'state_info', ':', 'indiana', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'mike-pence', '|', 'subject', ':', 'foreign-policy', '|', 'context', ':', 'comments', '``', 'meet', 'press', \"''\", '|', 'speaker_job_title', ':', 'governor', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['know', 'democrats', 'georgia', 'republicans', '.', 'know', 'fact', '.', '|', 'state_info', ':', 'georgia', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'mike-berlon', '|', 'subject', ':', 'elections', '|', 'context', ':', 'article', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['politifact', 'texas', 'says', 'congressman', 'edwards', 'attacks', 'bill', 'flores', 'false', '.', '|', 'state_info', ':', 'texas', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'bill-flores', '|', 'subject', ':', 'ethics', ',', 'message-machine', '|', 'context', ':', 'tv', 'ad', '.', '|', 'speaker_job_title', ':', 'businessman', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['denali', 'kenyan', 'word', 'black', 'power', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'viral-image', '|', 'subject', ':', 'environment', '|', 'context', ':', 'image', 'shared', 'facebook', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['says', '57', 'percent', 'federal', 'spending', 'goes', 'military', '1', 'percent', 'goes', 'food', 'agriculture', ',', 'including', 'food', 'stamps', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'facebook-posts', '|', 'subject', ':', 'federal-budget', ',', 'military', ',', 'poverty', '|', 'context', ':', 'meme', 'social', 'media', '|', 'speaker_job_title', ':', 'social', 'media', 'posting']\n",
            "  ['residency', 'requirements', 'public', 'workers', '|', 'state_info', ':', 'wisconsin', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'chris-abele', '|', 'subject', ':', 'city-government', ',', 'county-government', ',', 'unions', '|', 'context', ':', 'letter', '|', 'speaker_job_title', ':', 'philanthropist', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['says', 'unemployment', 'rate', 'college', 'graduates', '4.4', 'percent', '10', 'percent', 'noncollege-educated', '.', '|', 'state_info', ':', 'pennsylvania', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'rick-santorum', '|', 'subject', ':', 'education', ',', 'jobs', '|', 'context', ':', 'speech', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['unfortunately', 'documented', 'instances', 'people', 'defecated', '(', 'statehouse', ')', 'building', '.', '|', 'state_info', ':', 'ohio', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'tom-niehaus', '|', 'subject', ':', 'labor', ',', 'state-budget', '|', 'context', ':', 'interviews', 'reporters', '|', 'speaker_job_title', ':', 'president', 'ohio', 'senate', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['recent', 'gallup', 'poll', 'found', '72', 'percent', 'americans', '56', 'percent', 'democrats', 'say', 'biggest', 'threat', 'nations', 'security', 'big', 'government', '.', '|', 'state_info', ':', 'tennessee', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'marsha-blackburn', '|', 'subject', ':', 'government-efficiency', ',', 'government-regulation', ',', 'polls', '|', 'context', ':', 'speech', 'freedom', 'summit', 'new', 'hampshire', '|', 'speaker_job_title', ':']\n",
            "  ['year', ',', '18,000', 'people', 'die', 'america', 'health', 'care', '.', '|', 'state_info', ':', 'new', 'york', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'hillary-clinton', '|', 'subject', ':', 'health-care', '|', 'context', ':', 'speech', 'des', 'moines', ',', 'iowa', '.', '|', 'speaker_job_title', ':', 'presidential', 'candidate', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['ronald', 'reagan', 'faced', 'even', 'worse', 'recession', 'current', 'one', '.', '|', 'state_info', ':', 'alaska', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'sarah-palin', '|', 'subject', ':', 'economy', ',', 'history', '|', 'context', ':', 'book', ',', 'going', 'rogue', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "\n",
            "10000 unique tokens\n",
            "Unique tokens peek:\n",
            "  <PAD>\n",
            "  |\n",
            "  :\n",
            "  ,\n",
            "  .\n",
            "  speaker\n",
            "  state_info\n",
            "  party_affiliation\n",
            "  subject\n",
            "  context\n",
            "  speaker_job_title\n",
            "  republican\n",
            "  nan\n",
            "  democrat\n",
            "  says\n",
            "  u.s.\n",
            "  none\n",
            "  interview\n",
            "  new\n",
            "  state\n",
            "\n",
            "Final Index Sets(Set_Size = 49, 1267 index sets) peek:\n",
            "  [906, 494, 2122, 409, 344, 2143, 59, 5, 2, 7, 3, 21, 2, 8, 3, 12, 2, 6, 3, 268, 2, 9, 3, 56, 2, 10, 3, 92, 18, 2, 11, 3, 35, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [34, 2818, 1070, 303, 3051, 64, 5, 2, 7, 3, 34, 2, 8, 3, 14, 2, 6, 3, 0, 2, 9, 3, 29, 2, 10, 3, 40, 125, 2, 11, 3, 20, 62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [15, 238, 314, 645, 599, 544, 8812, 5, 2, 7, 3, 19, 45, 2, 8, 3, 12, 2, 6, 3, 132, 2, 9, 3, 82, 4, 273, 4, 185, 2, 10, 3, 118, 220, 41, 162, 5, 2, 11, 3, 155, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [7588, 7589, 516, 128, 145, 1546, 86, 1994, 699, 5, 2, 7, 3, 104, 2, 8, 3, 12, 2, 6, 3, 3126, 2, 9, 3, 86, 4, 142, 4, 550, 2, 10, 3, 92, 135, 2, 11, 3, 764, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [842, 1947, 568, 729, 924, 895, 2110, 6882, 36, 554, 4, 191, 5, 178, 358, 0, 2672, 5, 2, 7, 3, 34, 2, 8, 3, 14, 2, 6, 3, 1484, 2, 9, 3, 197, 4, 105, 4, 550, 2, 10, 3, 199, 187, 2, 11, 3, 13, 1, 1]\n",
            "  [387, 278, 59, 96, 110, 327, 26, 0, 71, 380, 1055, 520, 0, 111, 96, 397, 5, 2, 7, 3, 72, 74, 2, 8, 3, 12, 2, 6, 3, 3660, 2, 9, 3, 48, 4, 577, 4, 380, 2, 10, 3, 36, 150, 2, 11, 3, 13, 1, 1]\n",
            "  [15, 412, 109, 1630, 279, 858, 272, 0, 157, 26, 3401, 71, 241, 64, 157, 0, 243, 3893, 87, 623, 51, 5, 2, 7, 3, 412, 2, 8, 3, 17, 2, 6, 3, 0, 2, 9, 3, 649, 4, 672, 4, 39, 4, 23, 2, 10, 3, 106, 236]\n",
            "  [15, 725, 28, 466, 1647, 24, 2688, 161, 60, 0, 27, 365, 131, 1897, 5, 2, 7, 3, 43, 2, 8, 3, 12, 2, 6, 3, 675, 2, 9, 3, 25, 4, 131, 2, 10, 3, 50, 53, 5, 2, 11, 3, 6, 49, 190, 1, 1, 1, 1]\n",
            "  [259, 225, 370, 3357, 5, 321, 284, 382, 5, 2, 7, 3, 19, 45, 2, 8, 3, 14, 2, 6, 3, 0, 2, 9, 3, 339, 4, 370, 2, 10, 3, 33, 117, 102, 218, 2, 11, 3, 188, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [390, 272, 170, 992, 1953, 305, 20, 718, 564, 6953, 130, 828, 5, 2, 7, 3, 637, 2, 8, 3, 12, 2, 6, 3, 1133, 2, 9, 3, 76, 2, 10, 3, 118, 24, 248, 50, 27, 2, 11, 3, 35, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [390, 239, 58, 262, 5, 390, 635, 5, 2, 7, 3, 58, 2, 8, 3, 14, 2, 6, 3, 0, 2, 9, 3, 55, 2, 10, 3, 249, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [1875, 21, 15, 188, 6973, 1042, 80, 6813, 2632, 5, 2, 7, 3, 21, 2, 8, 3, 12, 2, 6, 3, 8924, 2, 9, 3, 200, 4, 193, 2, 10, 3, 78, 42, 5, 2, 11, 3, 758, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [0, 0, 1622, 662, 627, 5, 2, 7, 3, 13, 2, 8, 3, 17, 2, 6, 3, 1541, 2, 9, 3, 101, 2, 10, 3, 3769, 2611, 236, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [15, 2566, 30, 96, 166, 959, 82, 165, 30, 959, 539, 377, 4, 510, 539, 1282, 5, 2, 7, 3, 13, 2, 8, 3, 17, 2, 6, 3, 471, 2, 9, 3, 48, 4, 82, 4, 159, 2, 10, 3, 859, 143, 244, 2, 11, 3, 143, 244, 394]\n",
            "  [3988, 3125, 126, 88, 2, 7, 3, 34, 2, 8, 3, 17, 2, 6, 3, 1832, 2, 9, 3, 271, 4, 672, 4, 347, 2, 10, 3, 297, 2, 11, 3, 1753, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [15, 210, 141, 257, 2030, 0, 30, 151, 30, 0, 5, 2, 7, 3, 350, 2, 8, 3, 12, 2, 6, 3, 740, 2, 9, 3, 39, 4, 29, 2, 10, 3, 33, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [0, 4277, 4564, 60, 0, 37, 4819, 38, 906, 5, 2, 7, 3, 43, 2, 8, 3, 12, 2, 6, 3, 9108, 2, 9, 3, 147, 4, 52, 2, 10, 3, 1599, 449, 2, 11, 3, 28, 43, 66, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [572, 6641, 872, 695, 3009, 30, 152, 2561, 30, 239, 398, 832, 1660, 506, 182, 556, 110, 5, 2, 7, 3, 412, 2, 8, 3, 12, 2, 6, 3, 4655, 2, 9, 3, 250, 4, 211, 4, 245, 2, 10, 3, 33, 1235, 1172, 19, 216, 2, 11, 3]\n",
            "  [64, 4, 3610, 60, 1117, 163, 57, 68, 5, 2, 7, 3, 19, 45, 2, 8, 3, 14, 2, 6, 3, 153, 2, 9, 3, 31, 2, 10, 3, 33, 1446, 1504, 4, 307, 5, 2, 11, 3, 70, 75, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [774, 585, 2537, 156, 1591, 1340, 677, 77, 5, 2, 7, 3, 416, 2, 8, 3, 12, 2, 6, 3, 660, 2, 9, 3, 25, 4, 63, 2, 10, 3, 724, 4, 228, 8110, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "TEST SPLIT: 1267 overall samples: torch.Size([1267, 49])\n",
            "\n",
            "{'Baseline': {'Accuracy': 0.6456195737963694,\n",
            "              'Macro F1': 0.39232613908872904,\n",
            "              'Macro Precision': 0.3228097868981847,\n",
            "              'Macro Recall': 0.5,\n",
            "              'Micro F1': 0.6456195737963694,\n",
            "              'Micro Precision': 0.6456195737963694,\n",
            "              'Micro Recall': 0.6456195737963694,\n",
            "              'Per-Class F1': {'false': 0.7846522781774581, 'true': 0.0},\n",
            "              'Per-Class Precision': {'false': 0.6456195737963694, 'true': 0.0},\n",
            "              'Per-Class Recall': {'false': 1.0, 'true': 0.0}},\n",
            " 'Model': {'Accuracy': 0.5982636148382005,\n",
            "           'Macro F1': 0.5074643736257526,\n",
            "           'Macro Precision': 0.5230500363860895,\n",
            "           'Macro Recall': 0.5170754352241602,\n",
            "           'Micro F1': 0.5982636148382005,\n",
            "           'Micro Precision': 0.5982636148382005,\n",
            "           'Micro Recall': 0.5982636148382005,\n",
            "           'Per-Class F1': {'false': 0.7189398122584207,\n",
            "                            'true': 0.2959889349930844},\n",
            "           'Per-Class Precision': {'false': 0.6555891238670695,\n",
            "                                   'true': 0.3905109489051095},\n",
            "           'Per-Class Recall': {'false': 0.7958435207823961,\n",
            "                                'true': 0.2383073496659243}},\n",
            " 'Random': {'Accuracy': 0.48539857932123126,\n",
            "            'Macro F1': 0.47716467258393624,\n",
            "            'Macro Precision': 0.4912459567925884,\n",
            "            'Macro Recall': 0.4904501173485224,\n",
            "            'Micro F1': 0.48539857932123126,\n",
            "            'Micro Precision': 0.48539857932123126,\n",
            "            'Micro Recall': 0.48539857932123126,\n",
            "            'Per-Class F1': {'false': 0.5427769985974754,\n",
            "                             'true': 0.41155234657039713},\n",
            "            'Per-Class Precision': {'false': 0.6365131578947368,\n",
            "                                    'true': 0.34597875569044007},\n",
            "            'Per-Class Recall': {'false': 0.4731051344743276,\n",
            "                                 'true': 0.5077951002227171}}}\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IMPROVED HYPERPARAMETER STUFF BELOW\n"
      ],
      "metadata": {
        "id": "2jGtfNJV4fTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import nltk\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.optim as optim\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import pprint\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Hyperopt imports\n",
        "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
        "from hyperopt.pyll import scope\n",
        "\n",
        "random.seed(184)\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "peek = 20\n",
        "\n",
        "def present_list_like(name, list_like, peek=peek):\n",
        "    print(f\"{name} peek:\")\n",
        "    print('  ' + '\\n  '.join(str(v) for v in list_like[:peek]))\n",
        "\n",
        "columns = [\n",
        "    'id', 'label', 'claim', 'subject', 'speaker', 'speaker_job_title', 'state_info',\n",
        "    'party_affiliation', 'barely_true_counts', 'false_counts',\n",
        "    'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context'\n",
        "]\n",
        "present_list_like(f\"Dataset columns({len(columns)} in total)\", columns, len(columns))\n",
        "\n",
        "def load_data(split):\n",
        "    df = pd.read_csv(f\"./data/{split}.tsv\", sep='\\t', names=columns)\n",
        "    df = df.drop(index=[\n",
        "        idx for idx in df.index if type(df[\"claim\"][idx]) == type(None) or not len(df[\"claim\"][idx])\n",
        "    ])\n",
        "    print(\"The training dataset:\")\n",
        "    df.info()\n",
        "    print(\"\\nData peek:\")\n",
        "    print(df.head(peek))\n",
        "    print()\n",
        "    return df\n",
        "\n",
        "pad_tkn = \"<PAD>\"\n",
        "\n",
        "def tokenize_text(input_text, known_vector_size=None, token_to_idx={}):\n",
        "    def preprocess_text(text) -> str:\n",
        "        # Letter-level cleaning\n",
        "        text = text.lower()\n",
        "        valid_asciis = {9, *range(32, 127)}\n",
        "        text = ''.join(filter(lambda x: ord(x) in valid_asciis, text))\n",
        "\n",
        "        # Word/sequence-level cleaning\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = re.sub(r'http\\S+', '', text)\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        text = ' '.join(word for word in text.split() if word not in stop_words)\n",
        "        return text\n",
        "\n",
        "    # Preprocess the text\n",
        "    for i in range(len(input_text)):\n",
        "        input_text[i] = preprocess_text(input_text[i])\n",
        "\n",
        "    # Tokenize\n",
        "    final_tokens = input_tokens = [nltk.word_tokenize(text) for text in input_text]\n",
        "    total_tokens = sum(len(tkns) for tkns in final_tokens)\n",
        "\n",
        "    # Make all token sets the same length\n",
        "    forced_tkn_set_size = (\n",
        "        known_vector_size if known_vector_size\n",
        "        else int(np.percentile([len(tkns) for tkns in final_tokens], 80))\n",
        "    )\n",
        "    final_tokens = [\n",
        "        tkns[:forced_tkn_set_size] + [pad_tkn] * (forced_tkn_set_size - len(tkns))\n",
        "        for tkns in final_tokens\n",
        "    ]\n",
        "\n",
        "    # Present results\n",
        "    present_list_like(\n",
        "        f\"Tokenized sentences({len(final_tokens)} sentences, {total_tokens} total tokens)\",\n",
        "        final_tokens\n",
        "    )\n",
        "\n",
        "    # Index the tokens\n",
        "    # Map each token to its frequency in the dataset\n",
        "    if not len(token_to_idx):\n",
        "        flat_tokens = [word for token_set in final_tokens for word in token_set]\n",
        "        frequencies = Counter(flat_tokens)\n",
        "        token_to_idx = {}\n",
        "        for idx, (word, _) in enumerate(frequencies.most_common()):\n",
        "            if idx >= 10000:\n",
        "                break\n",
        "            token_to_idx[word] = idx + 1\n",
        "        if pad_tkn not in token_to_idx:\n",
        "            token_to_idx[pad_tkn] = len(token_to_idx) + 1\n",
        "    vocab_size = len(token_to_idx)\n",
        "    print()\n",
        "    print(vocab_size, \"unique tokens\")\n",
        "    present_list_like(\"Unique tokens\", list(token_to_idx.keys()))\n",
        "\n",
        "    # Index the tokens\n",
        "    freq_indexed = [\n",
        "        [(token_to_idx[token] if token in token_to_idx else 0) for token in token_set]\n",
        "        for token_set in final_tokens\n",
        "    ]\n",
        "\n",
        "    # Present results\n",
        "    present_list_like(\n",
        "        f\"\\nFinal Index Sets(Set_Size = {forced_tkn_set_size}, {len(freq_indexed)} index sets)\",\n",
        "        freq_indexed\n",
        "    )\n",
        "\n",
        "    return freq_indexed, token_to_idx\n",
        "\n",
        "def get_freq_indexed_and_labels(split, known_vector_size=None, token_to_idx={}):\n",
        "    df = load_data(split)\n",
        "    input_text = df[\"claim\"].to_numpy()\n",
        "    # Augment input text with the other columns\n",
        "    other_cols = {\n",
        "        \"context\",\n",
        "        \"subject\",\n",
        "        \"speaker\",\n",
        "        \"speaker_job_title\",\n",
        "        \"state_info\",\n",
        "        \"party_affiliation\",\n",
        "    }\n",
        "    for i in range(len(input_text)):\n",
        "        extra_data = [f\"{col}: {df[col].values[i]}\" for col in other_cols if df[col].values[i]]\n",
        "        input_text[i] += \" | \\n\" * (len(extra_data) > 0) + \" | \\n\".join(extra_data)\n",
        "    input_labels = df[\"label\"].to_numpy()\n",
        "    # Fuse some labels\n",
        "    input_labels = np.array([\n",
        "        \"false\" if x in (\"false\", \"half-true\", \"barely-true\", \"pants-fire\")\n",
        "        else \"true\" if x in (\"true\", \"mostly-true\")\n",
        "        else x\n",
        "        for x in input_labels\n",
        "    ])\n",
        "    freq_indexed, token_to_idx = tokenize_text(input_text, known_vector_size, token_to_idx)\n",
        "\n",
        "    return freq_indexed, token_to_idx, input_labels\n",
        "\n",
        "def as_tensors(split, label_encoder=None, known_vector_size=None, token_to_idx={}):\n",
        "    freq_indexed, token_to_idx, input_labels = get_freq_indexed_and_labels(split, known_vector_size, token_to_idx)\n",
        "    X = torch.tensor(freq_indexed, dtype=torch.long)\n",
        "    label_encoder_existed = (type(label_encoder) != type(None))\n",
        "    label_encoder = (LabelEncoder() if not label_encoder_existed else label_encoder)\n",
        "    y = (\n",
        "        label_encoder.fit_transform(input_labels) if not label_encoder_existed\n",
        "        else label_encoder.transform(input_labels)\n",
        "    )\n",
        "    y = torch.tensor(y, dtype=torch.long)\n",
        "    print(f\"{split.upper()} SPLIT:\", X.size(0), \"overall samples:\", X.shape)\n",
        "\n",
        "    return X, token_to_idx, label_encoder, input_labels, y\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "X_train, token_to_idx, label_encoder, train_input_labels, y_train = as_tensors(\"train\")\n",
        "X_val, _, _, _, y_val = as_tensors(\"valid\", label_encoder=label_encoder, known_vector_size=X_train.shape[1], token_to_idx=token_to_idx)\n",
        "\n",
        "label_to_idx = {l: i for i, l in enumerate(label_encoder.classes_)}\n",
        "train_vocab_size = len(token_to_idx)\n",
        "input_vector_size = X_train.shape[1]\n",
        "\n",
        "# Use validation set for evaluation during hyperparameter tuning\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "val_dataset = TensorDataset(X_val, y_val)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "train_label_counts = pd.DataFrame({\"label\": train_input_labels})[\"label\"].value_counts(normalize=True)\n",
        "print(train_label_counts.shape[0], \"labels\\n\")\n",
        "print(train_label_counts)\n",
        "\n",
        "# Balance if necessary\n",
        "print(f\"TRAIN SPLIT(pre-balancing):\", X_train.size(0), \"overall samples:\", X_train.shape)\n",
        "X_train, y_train = SMOTE(random_state=42).fit_resample(X_train, y_train)\n",
        "X_train = torch.tensor(X_train, dtype=torch.long)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "print()\n",
        "print(f\"TRAIN SPLIT(post-balancing):\", X_train.size(0), \"overall samples:\", X_train.shape)\n",
        "print(pd.DataFrame({\"label\": [label_encoder.classes_[y] for y in y_train]})[\"label\"].value_counts())\n",
        "\n",
        "# Define the model\n",
        "class BiLSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        super(BiLSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=token_to_idx[pad_tkn])\n",
        "        self.lstm = nn.LSTM(\n",
        "            embedding_dim, hidden_dim, num_layers=n_layers, batch_first=True, dropout=dropout, bidirectional=True\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # Multiply by 2 for bidirectional\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, (hidden, cell) = self.lstm(embedded)\n",
        "        # Concatenate the final forward and backward hidden states\n",
        "        hidden = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
        "        return self.fc(hidden)\n",
        "\n",
        "# Evaluation functions (modified to return Macro F1 for optimization)\n",
        "def per_class_metrics(labels, predictions, num_classes, label_ordering):\n",
        "    labels = labels.cpu().numpy()\n",
        "    predictions = predictions.cpu().numpy()\n",
        "\n",
        "    precision_per_class = precision_score(\n",
        "        labels, predictions, average=None, labels=np.arange(num_classes), zero_division=0\n",
        "    )\n",
        "    recall_per_class = recall_score(\n",
        "        labels, predictions, average=None, labels=np.arange(num_classes), zero_division=0\n",
        "    )\n",
        "    f1_per_class = f1_score(labels, predictions, average=None, labels=np.arange(num_classes), zero_division=0)\n",
        "\n",
        "    results = []\n",
        "    for metrics in [precision_per_class, recall_per_class, f1_per_class]:\n",
        "        results.append({label_ordering[i]: metrics[i] for i in range(len(metrics))})\n",
        "    return tuple(results)\n",
        "\n",
        "def macro_metrics(labels, predictions):\n",
        "    labels = labels.cpu().numpy()\n",
        "    predictions = predictions.cpu().numpy()\n",
        "\n",
        "    precision_macro = precision_score(labels, predictions, average='macro', zero_division=0)\n",
        "    recall_macro = recall_score(labels, predictions, average='macro', zero_division=0)\n",
        "    f1_macro = f1_score(labels, predictions, average='macro', zero_division=0)\n",
        "\n",
        "    return precision_macro, recall_macro, f1_macro\n",
        "\n",
        "def micro_metrics(labels, predictions):\n",
        "    labels = labels.cpu().numpy()\n",
        "    predictions = predictions.cpu().numpy()\n",
        "\n",
        "    precision_micro = precision_score(labels, predictions, average='micro', zero_division=0)\n",
        "    recall_micro = recall_score(labels, predictions, average='micro', zero_division=0)\n",
        "    f1_micro = f1_score(labels, predictions, average='micro', zero_division=0)\n",
        "\n",
        "    return precision_micro, recall_micro, f1_micro\n",
        "\n",
        "def evaluate(labels, num_classes, model_pred, baseline_pred, random_pred, label_ordering):\n",
        "    results = {}\n",
        "\n",
        "    for pred_type, predictions in [('Model', model_pred), ('Baseline', baseline_pred), ('Random', random_pred)]:\n",
        "        curr_results = results[pred_type] = {}\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = (predictions == labels).sum().item() / labels.size(0)\n",
        "        precision_per_class, recall_per_class, f1_per_class = per_class_metrics(\n",
        "            labels, predictions, num_classes, label_ordering\n",
        "        )\n",
        "        precision_macro, recall_macro, f1_macro = macro_metrics(labels, predictions)\n",
        "        precision_micro, recall_micro, f1_micro = micro_metrics(labels, predictions)\n",
        "\n",
        "        # Save all metrics\n",
        "        curr_results[\"Accuracy\"] = accuracy\n",
        "        curr_results[\"Per-Class Precision\"] = precision_per_class\n",
        "        curr_results[\"Per-Class Recall\"] = recall_per_class\n",
        "        curr_results[\"Per-Class F1\"] = f1_per_class\n",
        "        curr_results[\"Macro Precision\"] = precision_macro\n",
        "        curr_results[\"Macro Recall\"] = recall_macro\n",
        "        curr_results[\"Macro F1\"] = f1_macro\n",
        "        curr_results[\"Micro Precision\"] = precision_micro\n",
        "        curr_results[\"Micro Recall\"] = recall_micro\n",
        "        curr_results[\"Micro F1\"] = f1_micro\n",
        "\n",
        "    return results, f1_macro\n",
        "\n",
        "# Get predictions\n",
        "import typing as tp\n",
        "\n",
        "def get_predictions(\n",
        "    test_loader, model, num_samples,\n",
        "    pred_type: tp.Literal['model', 'baseline', 'random'] = 'model',\n",
        "    device=None,\n",
        "    label_ordering=None, orig_label_counts=None,\n",
        "    num_classes=None\n",
        "):\n",
        "    predictions = []\n",
        "    y_eval = []\n",
        "\n",
        "    if pred_type == 'model':\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in test_loader:\n",
        "                y_eval.extend(batch_y)\n",
        "\n",
        "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "                batch_size = batch_X.size(0)\n",
        "\n",
        "                outputs = model(batch_X)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                predictions.extend(predicted.cpu())\n",
        "        y_eval = torch.tensor(y_eval, dtype=torch.long)\n",
        "    elif pred_type == 'baseline':\n",
        "        orig_label_counts = orig_label_counts.sort_index(key=lambda idx: orig_label_counts[idx], inplace=False, ascending=False)\n",
        "        majority_class = list(label_ordering).index(orig_label_counts.index[0])\n",
        "        predictions += [majority_class for _ in range(num_samples)]\n",
        "    else:\n",
        "        predictions += [random.randint(0, num_classes - 1) for _ in range(num_samples)]\n",
        "\n",
        "    predictions = torch.tensor(predictions, dtype=torch.long)\n",
        "    if pred_type == 'model':\n",
        "        return predictions, y_eval\n",
        "    return predictions\n",
        "\n",
        "# Hyperparameter space\n",
        "space = {\n",
        "    'embedding_dim': scope.int(hp.quniform('embedding_dim', 50, 500, 50)),\n",
        "    'hidden_dim': scope.int(hp.quniform('hidden_dim', 32, 256, 32)),\n",
        "    'n_layers': scope.int(hp.quniform('n_layers', 1, 3, 1)),\n",
        "    'dropout': hp.uniform('dropout', 0.1, 0.7),\n",
        "    'learning_rate': hp.loguniform('learning_rate', -6, -2),  # 0.002 - 0.01\n",
        "}\n",
        "\n",
        "def train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=10):\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_path = \"best_model.pth\"\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # --- Training phase ---\n",
        "        model.train() # Ensure model is in training mode\n",
        "        train_epoch_loss = 0\n",
        "        train_epoch_tps = 0\n",
        "        train_total_samples = 0\n",
        "        y_true_train = []\n",
        "        y_pred_train = []\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(inputs)\n",
        "            loss = criterion(predictions, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_epoch_loss += loss.item()\n",
        "            _, predicted_classes = torch.max(predictions, 1)\n",
        "            train_epoch_tps += (predicted_classes == labels).sum().item()\n",
        "            train_total_samples += labels.size(0)\n",
        "\n",
        "            y_true_train.extend(labels.cpu().numpy())\n",
        "            y_pred_train.extend(predicted_classes.cpu().numpy())\n",
        "\n",
        "        y_true_train = torch.tensor(y_true_train, dtype=torch.long)\n",
        "        y_pred_train = torch.tensor(y_pred_train, dtype=torch.long)\n",
        "\n",
        "        train_results, train_f1_macro = evaluate(y_true_train, train_label_counts.shape[0], y_pred_train, y_pred_train, y_pred_train, label_encoder.classes_)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_epoch_loss/len(train_loader):.4f} | Train Accuracy: {train_epoch_tps/train_total_samples:.4f}\")\n",
        "        print(f\"  Train Per-Class Precision: {train_results['Model']['Per-Class Precision']}\")\n",
        "        print(f\"  Train Per-Class Recall: {train_results['Model']['Per-Class Recall']}\")\n",
        "        print(f\"  Train Per-Class F1: {train_results['Model']['Per-Class F1']}\")\n",
        "        print(f\"  Train Macro F1: {train_results['Model']['Macro F1']}\")\n",
        "\n",
        "        # --- Validation phase ---\n",
        "        val_loss = 0\n",
        "        model.eval() # Switch to evaluation mode\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                predictions = model(inputs)\n",
        "                loss = criterion(predictions, labels)\n",
        "                val_loss += loss.item()\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        print(f\"  Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "        # Save the model if the validation loss is better than the best so far\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "            print(f\"  Best model saved to {best_model_path} (val_loss={best_val_loss:.4f})\")\n",
        "\n",
        "    # Load the best model\n",
        "    print(f\"Loading best model from {best_model_path}\")\n",
        "    model.load_state_dict(torch.load(best_model_path))\n",
        "\n",
        "# Objective function for Hyperopt\n",
        "def objective(params):\n",
        "    print(\"Training with params:\")\n",
        "    print(params)\n",
        "\n",
        "    # Create model\n",
        "    model = BiLSTMModel(\n",
        "        input_dim=train_vocab_size + 1,\n",
        "        embedding_dim=params['embedding_dim'],\n",
        "        hidden_dim=params['hidden_dim'],\n",
        "        output_dim=train_label_counts.shape[0],\n",
        "        n_layers=params['n_layers'],\n",
        "        dropout=params['dropout']\n",
        "    )\n",
        "    model.to(device)\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=params['learning_rate'])\n",
        "\n",
        "    # Loss function (consider class weights if imbalanced)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    criterion.to(device)\n",
        "\n",
        "    # Train\n",
        "    train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=10)\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    model_pred, labels = get_predictions(val_loader, model, y_val.size(0), pred_type='model', device=device)\n",
        "    baseline_pred = get_predictions(\n",
        "        val_loader, model, y_val.size(0), pred_type='baseline',\n",
        "        label_ordering=label_encoder.classes_, orig_label_counts=train_label_counts\n",
        "    )\n",
        "    random_pred = get_predictions(val_loader, model, y_val.size(0), pred_type='random', num_classes=train_label_counts.shape[0])\n",
        "\n",
        "    _, f1_macro = evaluate(labels, train_label_counts.shape[0], model_pred, baseline_pred, random_pred, label_encoder.classes_)\n",
        "\n",
        "    # Hyperopt minimizes the objective, so return negative F1 Macro\n",
        "    return {'loss': -f1_macro, 'status': STATUS_OK}\n",
        "\n",
        "# Move model to GPU if possible\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if torch.cuda.is_available():\n",
        "    num_gpus = torch.cuda.device_count()\n",
        "    print(f\"Number of available GPUs: {num_gpus}\")\n",
        "    for i in range(num_gpus):\n",
        "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "    t4_available = any(\"t4\" in torch.cuda.get_device_name(i).lower() for i in range(num_gpus))\n",
        "    print(f\"Is a T4 GPU available? {t4_available}\")\n",
        "    device = torch.device('cuda:0')\n",
        "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"No GPU available, using CPU.\")\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "# Run hyperparameter optimization\n",
        "trials = Trials()\n",
        "best = fmin(fn=objective,\n",
        "            space=space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=50,\n",
        "            trials=trials)\n",
        "\n",
        "print(\"Best hyperparameters found:\")\n",
        "print(best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ8BgEzF4mpv",
        "outputId": "2d3e46da-290f-4c0d-a11f-46089d012ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset columns(14 in total) peek:\n",
            "  id\n",
            "  label\n",
            "  claim\n",
            "  subject\n",
            "  speaker\n",
            "  speaker_job_title\n",
            "  state_info\n",
            "  party_affiliation\n",
            "  barely_true_counts\n",
            "  false_counts\n",
            "  half_true_counts\n",
            "  mostly_true_counts\n",
            "  pants_on_fire_counts\n",
            "  context\n",
            "The training dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10240 entries, 0 to 10239\n",
            "Data columns (total 14 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   id                    10240 non-null  object \n",
            " 1   label                 10240 non-null  object \n",
            " 2   claim                 10240 non-null  object \n",
            " 3   subject               10238 non-null  object \n",
            " 4   speaker               10238 non-null  object \n",
            " 5   speaker_job_title     7342 non-null   object \n",
            " 6   state_info            8030 non-null   object \n",
            " 7   party_affiliation     10238 non-null  object \n",
            " 8   barely_true_counts    10238 non-null  float64\n",
            " 9   false_counts          10238 non-null  float64\n",
            " 10  half_true_counts      10238 non-null  float64\n",
            " 11  mostly_true_counts    10238 non-null  float64\n",
            " 12  pants_on_fire_counts  10238 non-null  float64\n",
            " 13  context               10138 non-null  object \n",
            "dtypes: float64(5), object(9)\n",
            "memory usage: 1.1+ MB\n",
            "\n",
            "Data peek:\n",
            "            id        label  \\\n",
            "0    2635.json        false   \n",
            "1   10540.json    half-true   \n",
            "2     324.json  mostly-true   \n",
            "3    1123.json        false   \n",
            "4    9028.json    half-true   \n",
            "5   12465.json         true   \n",
            "6    2342.json  barely-true   \n",
            "7     153.json    half-true   \n",
            "8    5602.json    half-true   \n",
            "9    9741.json  mostly-true   \n",
            "10   7115.json  mostly-true   \n",
            "11   4148.json    half-true   \n",
            "12   5947.json        false   \n",
            "13   8616.json  mostly-true   \n",
            "14   8705.json  barely-true   \n",
            "15  10683.json    half-true   \n",
            "16    620.json         true   \n",
            "17   3863.json  barely-true   \n",
            "18  12372.json    half-true   \n",
            "19  12385.json  mostly-true   \n",
            "\n",
            "                                                claim  \\\n",
            "0   Says the Annies List political group supports ...   \n",
            "1   When did the decline of coal start? It started...   \n",
            "2   Hillary Clinton agrees with John McCain \"by vo...   \n",
            "3   Health care reform legislation is likely to ma...   \n",
            "4   The economic turnaround started at the end of ...   \n",
            "5   The Chicago Bears have had more starting quart...   \n",
            "6   Jim Dunnam has not lived in the district he re...   \n",
            "7   I'm the only person on this stage who has work...   \n",
            "8   However, it took $19.5 million in Oregon Lotte...   \n",
            "9   Says GOP primary opponents Glenn Grothman and ...   \n",
            "10  For the first time in history, the share of th...   \n",
            "11  Since 2000, nearly 12 million Americans have s...   \n",
            "12  When Mitt Romney was governor of Massachusetts...   \n",
            "13  The economy bled $24 billion due to the govern...   \n",
            "14  Most of the (Affordable Care Act) has already ...   \n",
            "15  In this last election in November, ... 63 perc...   \n",
            "16  McCain opposed a requirement that the governme...   \n",
            "17  U.S. Rep. Ron Kind, D-Wis., and his fellow Dem...   \n",
            "18  Water rates in Manila, Philippines, were raise...   \n",
            "19  Almost 100,000 people left Puerto Rico last year.   \n",
            "\n",
            "                                      subject  \\\n",
            "0                                    abortion   \n",
            "1          energy,history,job-accomplishments   \n",
            "2                              foreign-policy   \n",
            "3                                 health-care   \n",
            "4                                economy,jobs   \n",
            "5                                   education   \n",
            "6                        candidates-biography   \n",
            "7                                      ethics   \n",
            "8                                        jobs   \n",
            "9   energy,message-machine-2014,voting-record   \n",
            "10                                  elections   \n",
            "11    economy,jobs,new-hampshire-2012,poverty   \n",
            "12                       history,state-budget   \n",
            "13         economy,federal-budget,health-care   \n",
            "14                                health-care   \n",
            "15                                  elections   \n",
            "16                             federal-budget   \n",
            "17                             federal-budget   \n",
            "18  financial-regulation,foreign-policy,water   \n",
            "19              bankruptcy,economy,population   \n",
            "\n",
            "                                        speaker  \\\n",
            "0                                  dwayne-bohac   \n",
            "1                                scott-surovell   \n",
            "2                                  barack-obama   \n",
            "3                                  blog-posting   \n",
            "4                                 charlie-crist   \n",
            "5                                     robin-vos   \n",
            "6                        republican-party-texas   \n",
            "7                                  barack-obama   \n",
            "8                                oregon-lottery   \n",
            "9                                 duey-stroebel   \n",
            "10                              robert-menendez   \n",
            "11                                     bernie-s   \n",
            "12                                  mitt-romney   \n",
            "13                                   doonesbury   \n",
            "14                                  george-will   \n",
            "15                                     bernie-s   \n",
            "16                                 barack-obama   \n",
            "17  national-republican-congressional-committee   \n",
            "18                                   gwen-moore   \n",
            "19                                     jack-lew   \n",
            "\n",
            "                    speaker_job_title         state_info party_affiliation  \\\n",
            "0                State representative              Texas        republican   \n",
            "1                      State delegate           Virginia          democrat   \n",
            "2                           President           Illinois          democrat   \n",
            "3                                 NaN                NaN              none   \n",
            "4                                 NaN            Florida          democrat   \n",
            "5          Wisconsin Assembly speaker          Wisconsin        republican   \n",
            "6                                 NaN              Texas        republican   \n",
            "7                           President           Illinois          democrat   \n",
            "8                                 NaN                NaN      organization   \n",
            "9                State representative          Wisconsin        republican   \n",
            "10                       U.S. Senator         New Jersey          democrat   \n",
            "11                       U.S. Senator            Vermont       independent   \n",
            "12                    Former governor      Massachusetts        republican   \n",
            "13                                NaN                NaN              none   \n",
            "14                          Columnist           Maryland         columnist   \n",
            "15                       U.S. Senator            Vermont       independent   \n",
            "16                          President           Illinois          democrat   \n",
            "17                                NaN                NaN        republican   \n",
            "18  U.S. House member -- 4th District          Wisconsin          democrat   \n",
            "19                Treasury secretary   Washington, D.C.           democrat   \n",
            "\n",
            "    barely_true_counts  false_counts  half_true_counts  mostly_true_counts  \\\n",
            "0                  0.0           1.0               0.0                 0.0   \n",
            "1                  0.0           0.0               1.0                 1.0   \n",
            "2                 70.0          71.0             160.0               163.0   \n",
            "3                  7.0          19.0               3.0                 5.0   \n",
            "4                 15.0           9.0              20.0                19.0   \n",
            "5                  0.0           3.0               2.0                 5.0   \n",
            "6                  3.0           1.0               1.0                 3.0   \n",
            "7                 70.0          71.0             160.0               163.0   \n",
            "8                  0.0           0.0               1.0                 0.0   \n",
            "9                  0.0           0.0               0.0                 1.0   \n",
            "10                 1.0           3.0               1.0                 3.0   \n",
            "11                18.0          12.0              22.0                41.0   \n",
            "12                34.0          32.0              58.0                33.0   \n",
            "13                 0.0           0.0               2.0                 4.0   \n",
            "14                 7.0           6.0               3.0                 5.0   \n",
            "15                18.0          12.0              22.0                41.0   \n",
            "16                70.0          71.0             160.0               163.0   \n",
            "17                18.0           9.0               8.0                 5.0   \n",
            "18                 3.0           4.0               4.0                 3.0   \n",
            "19                 0.0           1.0               0.0                 1.0   \n",
            "\n",
            "    pants_on_fire_counts                                   context  \n",
            "0                    0.0                                  a mailer  \n",
            "1                    0.0                           a floor speech.  \n",
            "2                    9.0                                    Denver  \n",
            "3                   44.0                            a news release  \n",
            "4                    2.0                       an interview on CNN  \n",
            "5                    1.0                 a an online opinion-piece  \n",
            "6                    1.0                          a press release.  \n",
            "7                    9.0  a Democratic debate in Philadelphia, Pa.  \n",
            "8                    1.0                                a website   \n",
            "9                    0.0                           an online video  \n",
            "10                   0.0                                  a speech  \n",
            "11                   0.0                                   a tweet  \n",
            "12                  19.0                an interview with CBN News  \n",
            "13                   0.0   a Doonesbury strip in the Sunday comics  \n",
            "14                   1.0             comments on \"Fox News Sunday\"  \n",
            "15                   0.0              a town hall in Austin, Texas  \n",
            "16                   9.0                                a radio ad  \n",
            "17                   8.0                            a news release  \n",
            "18                   1.0                   a congressional hearing  \n",
            "19                   0.0          an interview with Bloomberg News  \n",
            "\n",
            "Tokenized sentences(10240 sentences, 442958 total tokens) peek:\n",
            "  ['says', 'annies', 'list', 'political', 'group', 'supports', 'third-trimester', 'abortions', 'demand', '.', '|', 'state_info', ':', 'texas', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'dwayne-bohac', '|', 'subject', ':', 'abortion', '|', 'context', ':', 'mailer', '|', 'speaker_job_title', ':', 'state', 'representative', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['decline', 'coal', 'start', '?', 'started', 'natural', 'gas', 'took', 'started', 'begin', '(', 'president', 'george', 'w.', ')', 'bushs', 'administration', '.', '|', 'state_info', ':', 'virginia', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'scott-surovell', '|', 'subject', ':', 'energy', ',', 'history', ',', 'job-accomplishments', '|', 'context', ':', 'floor', 'speech', '.', '|', 'speaker_job_title', ':', 'state', 'delegate']\n",
            "  ['hillary', 'clinton', 'agrees', 'john', 'mccain', '``', 'by', 'voting', 'give', 'george', 'bush', 'benefit', 'doubt', 'iran', '.', \"''\", '|', 'state_info', ':', 'illinois', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'barack-obama', '|', 'subject', ':', 'foreign-policy', '|', 'context', ':', 'denver', '|', 'speaker_job_title', ':', 'president', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['health', 'care', 'reform', 'legislation', 'likely', 'mandate', 'free', 'sex', 'change', 'surgeries', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'blog-posting', '|', 'subject', ':', 'health-care', '|', 'context', ':', 'news', 'release', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['economic', 'turnaround', 'started', 'end', 'term', '.', '|', 'state_info', ':', 'florida', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'charlie-crist', '|', 'subject', ':', 'economy', ',', 'jobs', '|', 'context', ':', 'interview', 'cnn', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['chicago', 'bears', 'starting', 'quarterbacks', 'last', '10', 'years', 'total', 'number', 'tenured', '(', 'uw', ')', 'faculty', 'fired', 'last', 'two', 'decades', '.', '|', 'state_info', ':', 'wisconsin', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'robin-vos', '|', 'subject', ':', 'education', '|', 'context', ':', 'online', 'opinion-piece', '|', 'speaker_job_title', ':', 'wisconsin', 'assembly', 'speaker', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['jim', 'dunnam', 'lived', 'district', 'represents', 'years', 'now', '.', '|', 'state_info', ':', 'texas', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'republican-party-texas', '|', 'subject', ':', 'candidates-biography', '|', 'context', ':', 'press', 'release', '.', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['i', \"'m\", 'person', 'stage', 'worked', 'actively', 'last', 'year', 'passing', ',', 'along', 'russ', 'feingold', ',', 'toughest', 'ethics', 'reform', 'since', 'watergate', '.', '|', 'state_info', ':', 'illinois', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'barack-obama', '|', 'subject', ':', 'ethics', '|', 'context', ':', 'democratic', 'debate', 'philadelphia', ',', 'pa.', '|', 'speaker_job_title', ':', 'president', '<PAD>']\n",
            "  ['however', ',', 'took', '$', '19.5', 'million', 'oregon', 'lottery', 'funds', 'port', 'newport', 'eventually', 'land', 'new', 'noaa', 'marine', 'operations', 'center-pacific', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'organization', '|', 'speaker', ':', 'oregon-lottery', '|', 'subject', ':', 'jobs', '|', 'context', ':', 'website', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['says', 'gop', 'primary', 'opponents', 'glenn', 'grothman', 'joe', 'leibham', 'cast', 'compromise', 'vote', 'cost', '$', '788', 'million', 'higher', 'electricity', 'costs', '.', '|', 'state_info', ':', 'wisconsin', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'duey-stroebel', '|', 'subject', ':', 'energy', ',', 'message-machine-2014', ',', 'voting-record', '|', 'context', ':', 'online', 'video', '|', 'speaker_job_title', ':', 'state', 'representative']\n",
            "  ['first', 'time', 'history', ',', 'share', 'national', 'popular', 'vote', 'margin', 'smaller', 'latino', 'vote', 'margin', '.', '|', 'state_info', ':', 'new', 'jersey', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'robert-menendez', '|', 'subject', ':', 'elections', '|', 'context', ':', 'speech', '|', 'speaker_job_title', ':', 'u.s.', 'senator', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['since', '2000', ',', 'nearly', '12', 'million', 'americans', 'slipped', 'middle', 'class', 'poverty', '.', '|', 'state_info', ':', 'vermont', '|', 'party_affiliation', ':', 'independent', '|', 'speaker', ':', 'bernie-s', '|', 'subject', ':', 'economy', ',', 'jobs', ',', 'new-hampshire-2012', ',', 'poverty', '|', 'context', ':', 'tweet', '|', 'speaker_job_title', ':', 'u.s.', 'senator', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['mitt', 'romney', 'governor', 'massachusetts', ',', 'didnt', 'slow', 'rate', 'growth', 'government', ',', 'actually', 'cut', 'it', '.', '|', 'state_info', ':', 'massachusetts', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'mitt-romney', '|', 'subject', ':', 'history', ',', 'state-budget', '|', 'context', ':', 'interview', 'cbn', 'news', '|', 'speaker_job_title', ':', 'former', 'governor', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['economy', 'bled', '$', '24', 'billion', 'due', 'government', 'shutdown', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'doonesbury', '|', 'subject', ':', 'economy', ',', 'federal-budget', ',', 'health-care', '|', 'context', ':', 'doonesbury', 'strip', 'sunday', 'comics', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['(', 'affordable', 'care', 'act', ')', 'already', 'sense', 'waived', 'otherwise', 'suspended', '.', '|', 'state_info', ':', 'maryland', '|', 'party_affiliation', ':', 'columnist', '|', 'speaker', ':', 'george-will', '|', 'subject', ':', 'health-care', '|', 'context', ':', 'comments', '``', 'fox', 'news', 'sunday', \"''\", '|', 'speaker_job_title', ':', 'columnist', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['last', 'election', 'november', ',', '...', '63', 'percent', 'american', 'people', 'chose', 'vote', ',', '...', '80', 'percent', 'young', 'people', ',', '(', 'and', ')', '75', 'percent', 'low-income', 'workers', 'chose', 'vote', '.', '|', 'state_info', ':', 'vermont', '|', 'party_affiliation', ':', 'independent', '|', 'speaker', ':', 'bernie-s', '|', 'subject', ':', 'elections', '|', 'context', ':', 'town', 'hall']\n",
            "  ['mccain', 'opposed', 'requirement', 'government', 'buy', 'american-made', 'motorcycles', '.', 'said', 'buy-american', 'provisions', 'quote', \"'disgraceful\", '.', \"'\", '|', 'state_info', ':', 'illinois', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'barack-obama', '|', 'subject', ':', 'federal-budget', '|', 'context', ':', 'radio', 'ad', '|', 'speaker_job_title', ':', 'president', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['u.s.', 'rep.', 'ron', 'kind', ',', 'd-wis.', ',', 'fellow', 'democrats', 'went', 'spending', 'spree', 'credit', 'card', 'maxed', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'national-republican-congressional-committee', '|', 'subject', ':', 'federal-budget', '|', 'context', ':', 'news', 'release', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['water', 'rates', 'manila', ',', 'philippines', ',', 'raised', '845', 'percent', 'subsidiary', 'world', 'bank', 'became', 'partial', 'owner', '.', '|', 'state_info', ':', 'wisconsin', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'gwen-moore', '|', 'subject', ':', 'financial-regulation', ',', 'foreign-policy', ',', 'water', '|', 'context', ':', 'congressional', 'hearing', '|', 'speaker_job_title', ':', 'u.s.', 'house', 'member', '--', '4th']\n",
            "  ['almost', '100,000', 'people', 'left', 'puerto', 'rico', 'last', 'year', '.', '|', 'state_info', ':', 'washington', ',', 'd.c.', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'jack-lew', '|', 'subject', ':', 'bankruptcy', ',', 'economy', ',', 'population', '|', 'context', ':', 'interview', 'bloomberg', 'news', '|', 'speaker_job_title', ':', 'treasury', 'secretary', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "\n",
            "10000 unique tokens\n",
            "Unique tokens peek:\n",
            "  <PAD>\n",
            "  |\n",
            "  :\n",
            "  ,\n",
            "  .\n",
            "  speaker\n",
            "  state_info\n",
            "  party_affiliation\n",
            "  subject\n",
            "  context\n",
            "  speaker_job_title\n",
            "  republican\n",
            "  nan\n",
            "  democrat\n",
            "  says\n",
            "  u.s.\n",
            "  none\n",
            "  interview\n",
            "  new\n",
            "  state\n",
            "\n",
            "Final Index Sets(Set_Size = 49, 10240 index sets) peek:\n",
            "  [15, 8935, 1182, 201, 326, 516, 6415, 766, 1978, 5, 2, 7, 3, 21, 2, 8, 3, 12, 2, 6, 3, 8936, 2, 9, 3, 100, 2, 10, 3, 356, 2, 11, 3, 20, 62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [2580, 1333, 1183, 479, 783, 1431, 407, 247, 783, 2393, 37, 28, 333, 784, 38, 1704, 232, 5, 2, 7, 3, 69, 2, 8, 3, 14, 2, 6, 3, 8937, 2, 9, 3, 79, 4, 63, 4, 124, 2, 10, 3, 192, 33, 5, 2, 11, 3, 20, 1492]\n",
            "  [170, 130, 4384, 238, 314, 24, 4385, 438, 456, 333, 227, 1381, 4386, 547, 5, 27, 2, 7, 3, 61, 2, 8, 3, 14, 2, 6, 3, 73, 2, 9, 3, 76, 2, 10, 3, 1046, 2, 11, 3, 28, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [57, 68, 329, 385, 866, 867, 580, 868, 540, 5156, 5, 2, 7, 3, 13, 2, 8, 3, 17, 2, 6, 3, 581, 2, 9, 3, 31, 2, 10, 3, 40, 53, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [365, 5157, 783, 557, 813, 5, 2, 7, 3, 22, 2, 8, 3, 14, 2, 6, 3, 522, 2, 9, 3, 25, 4, 29, 2, 10, 3, 18, 121, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [1334, 4387, 1979, 6416, 108, 151, 59, 705, 303, 6417, 37, 5158, 38, 2581, 1705, 108, 209, 1231, 5, 2, 7, 3, 34, 2, 8, 3, 12, 2, 6, 3, 2230, 2, 9, 3, 39, 2, 10, 3, 410, 8938, 2, 11, 3, 34, 501, 6, 1, 1, 1]\n",
            "  [889, 8939, 2795, 127, 1882, 59, 517, 5, 2, 7, 3, 21, 2, 8, 3, 12, 2, 6, 3, 2796, 2, 9, 3, 54, 2, 10, 3, 50, 53, 5, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [606, 1626, 654, 2103, 890, 3811, 108, 64, 2231, 4, 1627, 1287, 1288, 4, 3812, 200, 329, 99, 8940, 5, 2, 7, 3, 61, 2, 8, 3, 14, 2, 6, 3, 73, 2, 9, 3, 200, 2, 10, 3, 117, 46, 847, 4, 1493, 2, 11, 3, 28, 1]\n",
            "  [6418, 4, 247, 26, 8941, 71, 104, 1794, 624, 3061, 4388, 4389, 848, 19, 6419, 3813, 1795, 8942, 5, 2, 7, 3, 13, 2, 8, 3, 149, 2, 6, 3, 6420, 2, 9, 3, 29, 2, 10, 3, 150, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1]\n",
            "  [15, 442, 493, 3364, 1706, 6421, 466, 8943, 1707, 3365, 229, 230, 26, 8944, 71, 337, 2394, 357, 5, 2, 7, 3, 34, 2, 8, 3, 12, 2, 6, 3, 8945, 2, 9, 3, 79, 4, 814, 4, 185, 2, 10, 3, 410, 187, 2, 11, 3, 20, 62]\n",
            "  [129, 138, 63, 4, 1382, 102, 1140, 229, 2232, 1708, 2582, 229, 2232, 5, 2, 7, 3, 19, 84, 2, 8, 3, 14, 2, 6, 3, 2233, 2, 9, 3, 55, 2, 10, 3, 33, 2, 11, 3, 16, 32, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [99, 977, 4, 208, 548, 71, 152, 8946, 538, 607, 159, 5, 2, 7, 3, 371, 2, 8, 3, 202, 2, 6, 3, 418, 2, 9, 3, 25, 4, 29, 4, 558, 4, 159, 2, 10, 3, 173, 2, 11, 3, 16, 32, 1, 1, 1, 1, 1, 1]\n",
            "  [293, 246, 35, 134, 4, 457, 5159, 141, 451, 110, 4, 298, 145, 290, 5, 2, 7, 3, 134, 2, 8, 3, 12, 2, 6, 3, 204, 2, 9, 3, 63, 4, 52, 2, 10, 3, 18, 8947, 40, 2, 11, 3, 111, 35, 1, 1, 1, 1, 1]\n",
            "  [25, 8948, 26, 1141, 93, 767, 110, 1980, 5, 2, 7, 3, 13, 2, 8, 3, 17, 2, 6, 3, 3062, 2, 9, 3, 25, 4, 48, 4, 31, 2, 10, 3, 3062, 1981, 372, 5160, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [37, 639, 68, 300, 38, 467, 3063, 4390, 4391, 4392, 5, 2, 7, 3, 447, 2, 8, 3, 448, 2, 6, 3, 1232, 2, 9, 3, 31, 2, 10, 3, 118, 24, 90, 40, 372, 27, 2, 11, 3, 448, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [108, 373, 1563, 4, 97, 3366, 30, 161, 60, 2583, 229, 4, 97, 640, 30, 655, 60, 4, 37, 753, 38, 1289, 30, 2104, 88, 2583, 229, 5, 2, 7, 3, 371, 2, 8, 3, 202, 2, 6, 3, 418, 2, 9, 3, 55, 2, 10, 3, 366, 419]\n",
            "  [314, 683, 2395, 110, 549, 8949, 6422, 5, 91, 8950, 2234, 2584, 8951, 5, 139, 2, 7, 3, 61, 2, 8, 3, 14, 2, 6, 3, 73, 2, 9, 3, 48, 2, 10, 3, 92, 42, 2, 11, 3, 28, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [16, 345, 1184, 1233, 4, 8952, 4, 1982, 239, 388, 166, 4393, 754, 1709, 3367, 2, 7, 3, 13, 2, 8, 3, 12, 2, 6, 3, 721, 2, 9, 3, 48, 2, 10, 3, 40, 53, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [330, 389, 8953, 4, 6423, 4, 439, 6424, 30, 8954, 205, 1001, 755, 5161, 869, 5, 2, 7, 3, 34, 2, 8, 3, 14, 2, 6, 3, 1628, 2, 9, 3, 395, 4, 76, 4, 330, 2, 10, 3, 310, 360, 2, 11, 3, 16, 49, 186, 157, 1494]\n",
            "  [304, 706, 60, 582, 3368, 4394, 108, 64, 5, 2, 7, 3, 120, 4, 198, 2, 8, 3, 14, 2, 6, 3, 6425, 2, 9, 3, 800, 4, 25, 4, 285, 2, 10, 3, 18, 3064, 40, 2, 11, 3, 2105, 305, 1, 1, 1, 1, 1, 1, 1]\n",
            "TRAIN SPLIT: 10240 overall samples: torch.Size([10240, 49])\n",
            "The training dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1284 entries, 0 to 1283\n",
            "Data columns (total 14 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   id                    1284 non-null   object\n",
            " 1   label                 1284 non-null   object\n",
            " 2   claim                 1284 non-null   object\n",
            " 3   subject               1284 non-null   object\n",
            " 4   speaker               1284 non-null   object\n",
            " 5   speaker_job_title     939 non-null    object\n",
            " 6   state_info            1005 non-null   object\n",
            " 7   party_affiliation     1284 non-null   object\n",
            " 8   barely_true_counts    1284 non-null   int64 \n",
            " 9   false_counts          1284 non-null   int64 \n",
            " 10  half_true_counts      1284 non-null   int64 \n",
            " 11  mostly_true_counts    1284 non-null   int64 \n",
            " 12  pants_on_fire_counts  1284 non-null   int64 \n",
            " 13  context               1272 non-null   object\n",
            "dtypes: int64(5), object(9)\n",
            "memory usage: 140.6+ KB\n",
            "\n",
            "Data peek:\n",
            "            id        label  \\\n",
            "0   12134.json  barely-true   \n",
            "1     238.json   pants-fire   \n",
            "2    7891.json        false   \n",
            "3    8169.json    half-true   \n",
            "4     929.json    half-true   \n",
            "5    9416.json        false   \n",
            "6    6861.json         true   \n",
            "7    1122.json        false   \n",
            "8   13138.json         true   \n",
            "9    1880.json    half-true   \n",
            "10  12803.json    half-true   \n",
            "11   5409.json        false   \n",
            "12   7313.json    half-true   \n",
            "13   4809.json         true   \n",
            "14   1671.json  barely-true   \n",
            "15   4348.json    half-true   \n",
            "16   6225.json    half-true   \n",
            "17   7675.json  mostly-true   \n",
            "18   2255.json  barely-true   \n",
            "19   9827.json   pants-fire   \n",
            "\n",
            "                                                claim  \\\n",
            "0   We have less Americans working now than in the...   \n",
            "1   When Obama was sworn into office, he DID NOT u...   \n",
            "2   Says Having organizations parading as being so...   \n",
            "3      Says nearly half of Oregons children are poor.   \n",
            "4   On attacks by Republicans that various program...   \n",
            "5   Says when armed civilians stop mass shootings ...   \n",
            "6   Says Tennessee is providing millions of dollar...   \n",
            "7   The health care reform plan would set limits s...   \n",
            "8   Says Donald Trump started his career back in 1...   \n",
            "9   Bill White has a long history of trying to lim...   \n",
            "10  John McCains chief economic adviser during the...   \n",
            "11  Says 21,000 Wisconsin residents got jobs in 20...   \n",
            "12  State revenue projections have missed the mark...   \n",
            "13  The median income of a middle class family wen...   \n",
            "14  Every citizen is entitled to the freedom of sp...   \n",
            "15  Rick Perry has advocated abandoning Social Sec...   \n",
            "16  Two thirds to three quarters of people without...   \n",
            "17  Congress has spent 66 of the first 100 days of...   \n",
            "18  Mark Sharpe has lowered property taxes by 17 p...   \n",
            "19  Says Iowa Gov. Terry Branstad chartered a plan...   \n",
            "\n",
            "                                      subject                 speaker  \\\n",
            "0                                economy,jobs          vicky-hartzler   \n",
            "1            obama-birth-certificate,religion             chain-email   \n",
            "2             campaign-finance,congress,taxes         earl-blumenauer   \n",
            "3                                     poverty         jim-francesconi   \n",
            "4                            economy,stimulus            barack-obama   \n",
            "5                                        guns              jim-rubens   \n",
            "6                      education,state-budget              andy-berke   \n",
            "7                                 health-care             club-growth   \n",
            "8      candidates-biography,diversity,housing         hillary-clinton   \n",
            "9                                    military  republican-party-texas   \n",
            "10                                    economy               tim-kaine   \n",
            "11            job-accomplishments,jobs,states       kathleen-vinehout   \n",
            "12                               state-budget            steve-henson   \n",
            "13                  income,new-hampshire-2012               joe-biden   \n",
            "14                          gays-and-lesbians          david-dewhurst   \n",
            "15             medicaid,social-security,taxes        margaret-carlson   \n",
            "16  health-care,poverty,public-health,welfare       elizabeth-roberts   \n",
            "17                                   congress             john-barrow   \n",
            "18                 candidates-biography,taxes             mark-sharpe   \n",
            "19                                immigration             chain-email   \n",
            "\n",
            "                                speaker_job_title            state_info  \\\n",
            "0                             U.S. Representative              Missouri   \n",
            "1                                             NaN                   NaN   \n",
            "2                             U.S. representative                Oregon   \n",
            "3   Member of the State Board of Higher Education                Oregon   \n",
            "4                                       President              Illinois   \n",
            "5                            Small business owner         New Hampshire   \n",
            "6                        Lawyer and state senator             Tennessee   \n",
            "7                                             NaN                   NaN   \n",
            "8                          Presidential candidate              New York   \n",
            "9                                             NaN                 Texas   \n",
            "10                                   U.S. Senator              Virginia   \n",
            "11                                            NaN                   NaN   \n",
            "12                                  State Senator               Georgia   \n",
            "13                                   U.S. senator              Delaware   \n",
            "14                            Lieutenant governor                 Texas   \n",
            "15                                      Columnist  District of Columbia   \n",
            "16                            Lieutenant Governor          Rhode Island   \n",
            "17                                    Congressman               Georgia   \n",
            "18               Hillsborough County commissioner               Florida   \n",
            "19                                            NaN                   NaN   \n",
            "\n",
            "   party_affiliation  barely_true_counts  false_counts  half_true_counts  \\\n",
            "0         republican                   1             0                 1   \n",
            "1               none                  11            43                 8   \n",
            "2           democrat                   0             1                 1   \n",
            "3               none                   0             1                 1   \n",
            "4           democrat                  70            71               160   \n",
            "5         republican                   1             1                 0   \n",
            "6           democrat                   0             0                 0   \n",
            "7               none                   4             5                 4   \n",
            "8           democrat                  40            29                69   \n",
            "9         republican                   3             1                 1   \n",
            "10          democrat                   8             3                15   \n",
            "11          democrat                   1             1                 1   \n",
            "12          democrat                   0             0                 1   \n",
            "13          democrat                  11            10                21   \n",
            "14        republican                   8             8                10   \n",
            "15              none                   0             0                 1   \n",
            "16          democrat                   1             0                 2   \n",
            "17          democrat                   0             0                 1   \n",
            "18        republican                   1             0                 0   \n",
            "19              none                  11            43                 8   \n",
            "\n",
            "    mostly_true_counts  pants_on_fire_counts  \\\n",
            "0                    0                     0   \n",
            "1                    5                   105   \n",
            "2                    1                     0   \n",
            "3                    1                     0   \n",
            "4                  163                     9   \n",
            "5                    1                     0   \n",
            "6                    0                     0   \n",
            "7                    2                     0   \n",
            "8                   76                     7   \n",
            "9                    3                     1   \n",
            "10                  15                     0   \n",
            "11                   1                     0   \n",
            "12                   0                     0   \n",
            "13                  16                     4   \n",
            "14                   5                     5   \n",
            "15                   0                     0   \n",
            "16                   0                     0   \n",
            "17                   1                     0   \n",
            "18                   0                     0   \n",
            "19                   5                   105   \n",
            "\n",
            "                                              context  \n",
            "0                        an interview with ABC17 News  \n",
            "1                                                 NaN  \n",
            "2                       a U.S. Ways and Means hearing  \n",
            "3                                  an opinion article  \n",
            "4                             interview with CBS News  \n",
            "5         in an interview at gun shop in Hudson, N.H.  \n",
            "6   a letter to state Senate education committee c...  \n",
            "7                                             a TV ad  \n",
            "8                       the first presidential debate  \n",
            "9                                           an e-mail  \n",
            "10  a speech at the Democratic National Convention...  \n",
            "11                                            remarks  \n",
            "12                                    a press release  \n",
            "13  speaking at New Hampshires Plymouth State Uni...  \n",
            "14                                    a press release  \n",
            "15                                 a politics column.  \n",
            "16        a panel discussion on \"A Lively Experiment\"  \n",
            "17                                           a letter  \n",
            "18                                  a campaign mailer  \n",
            "19                                      a chain email  \n",
            "\n",
            "Tokenized sentences(1284 sentences, 55513 total tokens) peek:\n",
            "  ['less', 'americans', 'working', '70s', '.', '|', 'state_info', ':', 'missouri', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'vicky-hartzler', '|', 'subject', ':', 'economy', ',', 'jobs', '|', 'context', ':', 'interview', 'abc17', 'news', '|', 'speaker_job_title', ':', 'u.s.', 'representative', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['obama', 'sworn', 'office', ',', 'use', 'holy', 'bible', ',', 'instead', 'kuran', '(', 'their', 'equivalency', 'bible', ',', 'different', 'beliefs', ')', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'chain-email', '|', 'subject', ':', 'obama-birth-certificate', ',', 'religion', '|', 'context', ':', 'nan', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['says', 'organizations', 'parading', 'social', 'welfare', 'organizations', 'involved', 'political', 'combat', 'harkens', 'back', 'statute', 'hundred', 'years', 'ago', 'said', 'prohibited', '.', '|', 'state_info', ':', 'oregon', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'earl-blumenauer', '|', 'subject', ':', 'campaign-finance', ',', 'congress', ',', 'taxes', '|', 'context', ':', 'u.s.', 'ways', 'means', 'hearing', '|', 'speaker_job_title', ':', 'u.s.']\n",
            "  ['says', 'nearly', 'half', 'oregons', 'children', 'poor', '.', '|', 'state_info', ':', 'oregon', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'jim-francesconi', '|', 'subject', ':', 'poverty', '|', 'context', ':', 'opinion', 'article', '|', 'speaker_job_title', ':', 'member', 'state', 'board', 'higher', 'education', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['attacks', 'republicans', 'various', 'programs', 'economic', 'stimulus', 'plan', 'stimulative', ',', '``', 'if', 'add', 'stuff', 'up', ',', 'accounts', 'less', '1', 'percent', 'overall', 'package', '.', \"''\", '|', 'state_info', ':', 'illinois', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'barack-obama', '|', 'subject', ':', 'economy', ',', 'stimulus', '|', 'context', ':', 'interview', 'cbs', 'news', '|', 'speaker_job_title']\n",
            "  ['says', 'armed', 'civilians', 'stop', 'mass', 'shootings', 'guns', ',', 'average', '2.5', 'people', 'die', ';', 'otherwise', ',', 'average', '18', 'people', 'die', '.', '|', 'state_info', ':', 'new', 'hampshire', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'jim-rubens', '|', 'subject', ':', 'guns', '|', 'context', ':', 'interview', 'gun', 'shop', 'hudson', ',', 'n.h.', '|', 'speaker_job_title', ':']\n",
            "  ['says', 'tennessee', 'providing', 'millions', 'dollars', 'virtual', 'school', 'company', 'results', 'bottom', 'bottom', '.', '|', 'state_info', ':', 'tennessee', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'andy-berke', '|', 'subject', ':', 'education', ',', 'state-budget', '|', 'context', ':', 'letter', 'state', 'senate', 'education', 'committee', 'chairwoman', 'dolores', 'gresham', '.', '|', 'speaker_job_title', ':', 'lawyer', 'state', 'senator', '<PAD>']\n",
            "  ['health', 'care', 'reform', 'plan', 'would', 'set', 'limits', 'similar', 'socialized', 'system', 'britain', ',', 'people', 'allowed', 'die', 'treatment', 'would', 'cost', '$', '22,000', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'club-growth', '|', 'subject', ':', 'health-care', '|', 'context', ':', 'tv', 'ad', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['says', 'donald', 'trump', 'started', 'career', 'back', '1973', 'sued', 'justice', 'department', 'racial', 'discrimination', 'would', 'rent', 'apartments', 'one', 'developments', 'african-americans', '.', '|', 'state_info', ':', 'new', 'york', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'hillary-clinton', '|', 'subject', ':', 'candidates-biography', ',', 'diversity', ',', 'housing', '|', 'context', ':', 'first', 'presidential', 'debate', '|', 'speaker_job_title', ':']\n",
            "  ['bill', 'white', 'long', 'history', 'trying', 'limit', 'even', 'disenfranchise', 'military', 'voters', '.', '|', 'state_info', ':', 'texas', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'republican-party-texas', '|', 'subject', ':', 'military', '|', 'context', ':', 'e-mail', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['john', 'mccains', 'chief', 'economic', 'adviser', '08', 'race', 'estimated', 'trumps', 'promises', 'would', 'cause', 'america', 'lose', '3.5', 'million', 'jobs', '.', '|', 'state_info', ':', 'virginia', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'tim-kaine', '|', 'subject', ':', 'economy', '|', 'context', ':', 'speech', 'democratic', 'national', 'convention', 'philadelphia', '|', 'speaker_job_title', ':', 'u.s.', 'senator', '<PAD>', '<PAD>']\n",
            "  ['says', '21,000', 'wisconsin', 'residents', 'got', 'jobs', '2011', ',', '18,000', 'states', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'kathleen-vinehout', '|', 'subject', ':', 'job-accomplishments', ',', 'jobs', ',', 'states', '|', 'context', ':', 'remarks', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['state', 'revenue', 'projections', 'missed', 'mark', 'month', 'month', '.', '|', 'state_info', ':', 'georgia', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'steve-henson', '|', 'subject', ':', 'state-budget', '|', 'context', ':', 'press', 'release', '|', 'speaker_job_title', ':', 'state', 'senator', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['median', 'income', 'middle', 'class', 'family', 'went', '$', '2,100', '2001', '2007', '.', '|', 'state_info', ':', 'delaware', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'joe-biden', '|', 'subject', ':', 'income', ',', 'new-hampshire-2012', '|', 'context', ':', 'speaking', 'new', 'hampshires', 'plymouth', 'state', 'university', '|', 'speaker_job_title', ':', 'u.s.', 'senator', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['every', 'citizen', 'entitled', 'freedom', 'speech', ',', 'one', 'right', 'use', 'government', 'funds', 'institutions', 'portray', 'acts', 'morally', 'reprehensible', 'vast', 'majority', 'americans', '.', '|', 'state_info', ':', 'texas', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'david-dewhurst', '|', 'subject', ':', 'gays-and-lesbians', '|', 'context', ':', 'press', 'release', '|', 'speaker_job_title', ':', 'lieutenant', 'governor', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['rick', 'perry', 'advocated', 'abandoning', 'social', 'security', ',', 'scuttling', 'medicaid', 'ending', 'federal', 'income', 'tax', '.', '|', 'state_info', ':', 'district', 'columbia', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'margaret-carlson', '|', 'subject', ':', 'medicaid', ',', 'social-security', ',', 'taxes', '|', 'context', ':', 'politics', 'column', '.', '|', 'speaker_job_title', ':', 'columnist', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['two', 'thirds', 'three', 'quarters', 'people', 'without', '[', 'health', ']', 'insurance', 'rhode', 'island', 'work', '.', '|', 'state_info', ':', 'rhode', 'island', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'elizabeth-roberts', '|', 'subject', ':', 'health-care', ',', 'poverty', ',', 'public-health', ',', 'welfare', '|', 'context', ':', 'panel', 'discussion', '``', 'a', 'lively', 'experiment', \"''\", '|', 'speaker_job_title']\n",
            "  ['congress', 'spent', '66', 'first', '100', 'days', 'term', 'recess', '.', '|', 'state_info', ':', 'georgia', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'john-barrow', '|', 'subject', ':', 'congress', '|', 'context', ':', 'letter', '|', 'speaker_job_title', ':', 'congressman', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['mark', 'sharpe', 'lowered', 'property', 'taxes', '17', 'percent', '.', '|', 'state_info', ':', 'florida', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'mark-sharpe', '|', 'subject', ':', 'candidates-biography', ',', 'taxes', '|', 'context', ':', 'campaign', 'mailer', '|', 'speaker_job_title', ':', 'hillsborough', 'county', 'commissioner', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['says', 'iowa', 'gov', '.', 'terry', 'branstad', 'chartered', 'plane', 'remove', '124', 'young', 'illegal', 'immigrants', 'state', 'take', 'back', 'honduras', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'chain-email', '|', 'subject', ':', 'immigration', '|', 'context', ':', 'chain', 'email', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "\n",
            "10000 unique tokens\n",
            "Unique tokens peek:\n",
            "  <PAD>\n",
            "  |\n",
            "  :\n",
            "  ,\n",
            "  .\n",
            "  speaker\n",
            "  state_info\n",
            "  party_affiliation\n",
            "  subject\n",
            "  context\n",
            "  speaker_job_title\n",
            "  republican\n",
            "  nan\n",
            "  democrat\n",
            "  says\n",
            "  u.s.\n",
            "  none\n",
            "  interview\n",
            "  new\n",
            "  state\n",
            "\n",
            "Final Index Sets(Set_Size = 49, 1284 index sets) peek:\n",
            "  [233, 152, 406, 0, 5, 2, 7, 3, 542, 2, 8, 3, 12, 2, 6, 3, 7845, 2, 9, 3, 25, 4, 29, 2, 10, 3, 18, 0, 40, 2, 11, 3, 16, 62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [47, 4897, 164, 4, 367, 0, 2946, 4, 1497, 0, 37, 5601, 0, 2946, 4, 986, 3042, 38, 5, 2, 7, 3, 13, 2, 8, 3, 17, 2, 6, 3, 267, 2, 9, 3, 1208, 4, 263, 2, 10, 3, 13, 2, 11, 3, 13, 1, 1, 1, 1]\n",
            "  [15, 2200, 0, 143, 417, 2200, 1784, 201, 2652, 0, 382, 6648, 3469, 59, 431, 91, 4005, 5, 2, 7, 3, 104, 2, 8, 3, 14, 2, 6, 3, 4008, 2, 9, 3, 197, 4, 81, 4, 23, 2, 10, 3, 16, 2904, 1000, 360, 2, 11, 3, 16]\n",
            "  [15, 208, 272, 1734, 113, 1149, 5, 2, 7, 3, 104, 2, 8, 3, 17, 2, 6, 3, 7618, 2, 9, 3, 159, 2, 10, 3, 446, 249, 2, 11, 3, 186, 20, 274, 337, 39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [1042, 262, 1272, 701, 365, 131, 128, 0, 4, 24, 2500, 1409, 6121, 712, 4, 1823, 233, 165, 30, 1782, 1897, 5, 27, 2, 7, 3, 61, 2, 8, 3, 14, 2, 6, 3, 73, 2, 9, 3, 25, 4, 131, 2, 10, 3, 18, 653, 40, 2, 11]\n",
            "  [15, 3343, 8780, 583, 1190, 1317, 85, 4, 181, 1929, 60, 1117, 956, 4391, 4, 181, 723, 60, 1117, 5, 2, 7, 3, 19, 216, 2, 8, 3, 12, 2, 6, 3, 8012, 2, 9, 3, 85, 2, 10, 3, 18, 286, 6258, 6434, 4, 474, 2, 11, 3]\n",
            "  [15, 412, 3615, 383, 214, 0, 137, 561, 3447, 1121, 1121, 5, 2, 7, 3, 412, 2, 8, 3, 14, 2, 6, 3, 0, 2, 9, 3, 39, 4, 52, 2, 10, 3, 297, 20, 66, 39, 221, 2932, 0, 0, 5, 2, 11, 3, 620, 20, 32, 1]\n",
            "  [57, 68, 329, 128, 65, 1226, 2697, 1696, 4097, 302, 3782, 4, 60, 636, 1117, 1943, 65, 230, 26, 4190, 5, 2, 7, 3, 13, 2, 8, 3, 17, 2, 6, 3, 1682, 2, 9, 3, 31, 2, 10, 3, 78, 42, 2, 11, 3, 13, 1, 1, 1]\n",
            "  [15, 259, 225, 783, 1298, 382, 3164, 3318, 656, 296, 4433, 2436, 65, 2397, 4408, 77, 0, 2098, 5, 2, 7, 3, 19, 45, 2, 8, 3, 14, 2, 6, 3, 153, 2, 9, 3, 54, 4, 420, 4, 348, 2, 10, 3, 129, 70, 46, 2, 11, 3]\n",
            "  [80, 260, 1080, 63, 904, 1470, 156, 0, 82, 362, 5, 2, 7, 3, 21, 2, 8, 3, 12, 2, 6, 3, 2796, 2, 9, 3, 82, 2, 10, 3, 281, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [238, 5764, 833, 365, 1498, 0, 970, 1252, 1329, 3110, 65, 987, 163, 807, 2907, 71, 29, 5, 2, 7, 3, 69, 2, 8, 3, 14, 2, 6, 3, 765, 2, 9, 3, 25, 2, 10, 3, 33, 117, 102, 218, 847, 2, 11, 3, 16, 32, 1, 1]\n",
            "  [15, 0, 34, 665, 340, 29, 354, 4, 3610, 44, 5, 2, 7, 3, 13, 2, 8, 3, 14, 2, 6, 3, 5288, 2, 9, 3, 124, 4, 29, 4, 44, 2, 10, 3, 276, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [20, 610, 4525, 2023, 954, 533, 533, 5, 2, 7, 3, 58, 2, 8, 3, 14, 2, 6, 3, 0, 2, 9, 3, 52, 2, 10, 3, 50, 53, 2, 11, 3, 20, 32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [1735, 103, 538, 607, 411, 388, 26, 6210, 1467, 1155, 5, 2, 7, 3, 496, 2, 8, 3, 14, 2, 6, 3, 563, 2, 9, 3, 103, 4, 558, 2, 10, 3, 2858, 19, 8844, 8712, 20, 306, 2, 11, 3, 16, 32, 1, 1, 1, 1, 1, 1]\n",
            "  [89, 2193, 0, 1235, 33, 4, 77, 235, 367, 110, 624, 2150, 0, 4557, 0, 0, 2268, 292, 152, 5, 2, 7, 3, 21, 2, 8, 3, 12, 2, 6, 3, 1062, 2, 9, 3, 339, 2, 10, 3, 50, 53, 2, 11, 3, 461, 35, 1, 1, 1]\n",
            "  [251, 541, 2342, 0, 143, 182, 4, 0, 223, 2222, 96, 103, 51, 5, 2, 7, 3, 127, 1406, 2, 8, 3, 17, 2, 6, 3, 0, 2, 9, 3, 223, 4, 312, 4, 23, 2, 10, 3, 1271, 224, 5, 2, 11, 3, 448, 1, 1, 1, 1]\n",
            "  [209, 5565, 207, 6449, 60, 317, 253, 57, 254, 177, 72, 74, 316, 5, 2, 7, 3, 72, 74, 2, 8, 3, 14, 2, 6, 3, 5065, 2, 9, 3, 31, 4, 159, 4, 169, 4, 417, 2, 10, 3, 824, 559, 24, 603, 8771, 5951, 27, 2, 11]\n",
            "  [81, 335, 4273, 129, 393, 524, 813, 0, 5, 2, 7, 3, 58, 2, 8, 3, 14, 2, 6, 3, 0, 2, 9, 3, 81, 2, 10, 3, 297, 2, 11, 3, 188, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [954, 0, 5036, 476, 23, 958, 30, 5, 2, 7, 3, 22, 2, 8, 3, 12, 2, 6, 3, 0, 2, 9, 3, 54, 4, 23, 2, 10, 3, 36, 356, 2, 11, 3, 2686, 87, 481, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [15, 307, 191, 5, 2806, 0, 0, 2575, 1744, 0, 655, 219, 353, 20, 344, 382, 4784, 5, 2, 7, 3, 13, 2, 8, 3, 17, 2, 6, 3, 267, 2, 9, 3, 56, 2, 10, 3, 414, 184, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1]\n",
            "VALID SPLIT: 1284 overall samples: torch.Size([1284, 49])\n",
            "2 labels\n",
            "\n",
            "label\n",
            "false    0.644727\n",
            "true     0.355273\n",
            "Name: proportion, dtype: float64\n",
            "TRAIN SPLIT(pre-balancing): 10240 overall samples: torch.Size([10240, 49])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRAIN SPLIT(post-balancing): 13204 overall samples: torch.Size([13204, 49])\n",
            "label\n",
            "false    6602\n",
            "true     6602\n",
            "Name: count, dtype: int64\n",
            "Number of available GPUs: 1\n",
            "GPU 0: Tesla T4\n",
            "Is a T4 GPU available? True\n",
            "Using GPU: Tesla T4\n",
            "Training with params:\n",
            "{'dropout': 0.17359782539133228, 'embedding_dim': 250, 'hidden_dim': 96, 'learning_rate': 0.02103633411648602, 'n_layers': 3}\n",
            "Epoch 1/10 | Train Loss: 0.6624 | Train Accuracy: 0.6362\n",
            "  Train Per-Class Precision: {'false': 0.6474023977866584, 'true': 0.4095634095634096}\n",
            "  Train Per-Class Recall: {'false': 0.9569827325053014, 'true': 0.05415063221550302}\n",
            "  Train Per-Class F1: {'false': 0.7723244300470632, 'true': 0.09565428502063608}\n",
            "  Train Macro F1: 0.43398935753384965\n",
            "  Validation Loss: 0.6303\n",
            "  Best model saved to best_model.pth (val_loss=0.6303)\n",
            "Epoch 2/10 | Train Loss: 0.6439 | Train Accuracy: 0.6418\n",
            "  Train Per-Class Precision: {'false': 0.6590416305290546, 'true': 0.48523622047244097}\n",
            "  Train Per-Class Recall: {'false': 0.9207815813389881, 'true': 0.13551401869158877}\n",
            "  Train Per-Class F1: {'false': 0.7682294957664603, 'true': 0.21186076493339062}\n",
            "  Train Macro F1: 0.4900451303499255\n",
            "  Validation Loss: 0.6838\n",
            "Epoch 3/10 | Train Loss: 0.6128 | Train Accuracy: 0.6653\n",
            "  Train Per-Class Precision: {'false': 0.6980661260137243, 'true': 0.5474157303370787}\n",
            "  Train Per-Class Recall: {'false': 0.8474704634959104, 'true': 0.3347993402968664}\n",
            "  Train Per-Class F1: {'false': 0.7655469658616679, 'true': 0.41548695207231795}\n",
            "  Train Macro F1: 0.590516958966993\n",
            "  Validation Loss: 0.6251\n",
            "  Best model saved to best_model.pth (val_loss=0.6251)\n",
            "Epoch 4/10 | Train Loss: 0.5937 | Train Accuracy: 0.6884\n",
            "  Train Per-Class Precision: {'false': 0.7231453617689388, 'true': 0.5860608394301117}\n",
            "  Train Per-Class Recall: {'false': 0.8371705543774614, 'true': 0.41836173721825176}\n",
            "  Train Per-Class F1: {'false': 0.775991575991576, 'true': 0.48821170809943865}\n",
            "  Train Macro F1: 0.6321016420455073\n",
            "  Validation Loss: 0.6685\n",
            "Epoch 5/10 | Train Loss: 0.6491 | Train Accuracy: 0.6422\n",
            "  Train Per-Class Precision: {'false': 0.6815373208106772, 'true': 0.49394785847299816}\n",
            "  Train Per-Class Recall: {'false': 0.8353529233565586, 'true': 0.2916437603078615}\n",
            "  Train Per-Class F1: {'false': 0.7506465223900912, 'true': 0.3667473211199447}\n",
            "  Train Macro F1: 0.558696921755018\n",
            "  Validation Loss: 0.6708\n",
            "Epoch 6/10 | Train Loss: 0.6640 | Train Accuracy: 0.6305\n",
            "  Train Per-Class Precision: {'false': 0.6523572664359861, 'true': 0.4264112903225806}\n",
            "  Train Per-Class Recall: {'false': 0.9138139957588609, 'true': 0.11627267729521715}\n",
            "  Train Per-Class F1: {'false': 0.7612618296529968, 'true': 0.18272138228941684}\n",
            "  Train Macro F1: 0.4719916059712068\n",
            "  Validation Loss: 0.6391\n",
            "Epoch 7/10 | Train Loss: 0.6494 | Train Accuracy: 0.6429\n",
            "  Train Per-Class Precision: {'false': 0.6557706548185761, 'true': 0.48792884371029227}\n",
            "  Train Per-Class Recall: {'false': 0.9389578915480158, 'true': 0.10555250137438153}\n",
            "  Train Per-Class F1: {'false': 0.7722204920585487, 'true': 0.17355932203389832}\n",
            "  Train Macro F1: 0.4728899070462235\n",
            "  Validation Loss: 0.6394\n",
            "Epoch 8/10 | Train Loss: 0.6432 | Train Accuracy: 0.6409\n",
            "  Train Per-Class Precision: {'false': 0.662807525325615, 'true': 0.48448687350835323}\n",
            "  Train Per-Class Recall: {'false': 0.9018479248712511, 'true': 0.1673996701484332}\n",
            "  Train Per-Class F1: {'false': 0.7640680141161373, 'true': 0.2488253319713994}\n",
            "  Train Macro F1: 0.5064466730437683\n",
            "  Validation Loss: 0.6387\n",
            "Epoch 9/10 | Train Loss: 0.6344 | Train Accuracy: 0.6455\n",
            "  Train Per-Class Precision: {'false': 0.6681375876895225, 'true': 0.5028530670470756}\n",
            "  Train Per-Class Recall: {'false': 0.8944259315358982, 'true': 0.1937877954920286}\n",
            "  Train Per-Class F1: {'false': 0.7648963730569949, 'true': 0.27976190476190477}\n",
            "  Train Macro F1: 0.5223291389094498\n",
            "  Validation Loss: 0.6321\n",
            "Epoch 10/10 | Train Loss: 0.6334 | Train Accuracy: 0.6528\n",
            "  Train Per-Class Precision: {'false': 0.6768837803320562, 'true': 0.5255070682237246}\n",
            "  Train Per-Class Recall: {'false': 0.883065737655256, 'true': 0.23501924134139637}\n",
            "  Train Per-Class F1: {'false': 0.7663489976996385, 'true': 0.3247863247863248}\n",
            "  Train Macro F1: 0.5455676612429816\n",
            "  Validation Loss: 0.6523\n",
            "Loading best model from best_model.pth\n",
            "Training with params:\n",
            "{'dropout': 0.3429770677409516, 'embedding_dim': 100, 'hidden_dim': 128, 'learning_rate': 0.0025525382645110234, 'n_layers': 3}\n",
            "  2%|         | 1/50 [00:26<21:29, 26.31s/trial, best loss: -0.493802732020892]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-0b51d53853bb>:386: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(best_model_path))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train Loss: 0.6480 | Train Accuracy: 0.6439\n",
            "  Train Per-Class Precision: {'false': 0.6486024532475367, 'true': 0.48639455782312924}\n",
            "  Train Per-Class Recall: {'false': 0.9771281429869736, 'true': 0.03930731170973062}\n",
            "  Train Per-Class F1: {'false': 0.7796712593666908, 'true': 0.07273652085452696}\n",
            "  Train Macro F1: 0.4262038901106089\n",
            "  Validation Loss: 0.6137\n",
            "  Best model saved to best_model.pth (val_loss=0.6137)\n",
            "Epoch 2/10 | Train Loss: 0.6064 | Train Accuracy: 0.6725\n",
            "  Train Per-Class Precision: {'false': 0.690924053609217, 'true': 0.5818915801614764}\n",
            "  Train Per-Class Recall: {'false': 0.8901847924871251, 'true': 0.27735019241341397}\n",
            "  Train Per-Class F1: {'false': 0.7779984114376489, 'true': 0.37565152643335814}\n",
            "  Train Macro F1: 0.5768249689355035\n",
            "  Validation Loss: 0.6110\n",
            "  Best model saved to best_model.pth (val_loss=0.6110)\n",
            "Epoch 3/10 | Train Loss: 0.5263 | Train Accuracy: 0.7394\n",
            "  Train Per-Class Precision: {'false': 0.7722552955835525, 'true': 0.6605899900563473}\n",
            "  Train Per-Class Recall: {'false': 0.8448954862162981, 'true': 0.5478284771852666}\n",
            "  Train Per-Class F1: {'false': 0.8069439421338156, 'true': 0.5989481592787378}\n",
            "  Train Macro F1: 0.7029460507062767\n",
            "  Validation Loss: 0.6291\n",
            "Epoch 4/10 | Train Loss: 0.3980 | Train Accuracy: 0.8283\n",
            "  Train Per-Class Precision: {'false': 0.8557579318448884, 'true': 0.7738927738927739}\n",
            "  Train Per-Class Recall: {'false': 0.8824598606482884, 'true': 0.7300714678394722}\n",
            "  Train Per-Class F1: {'false': 0.868903803131991, 'true': 0.7513437057991513}\n",
            "  Train Macro F1: 0.8101237544655712\n",
            "  Validation Loss: 0.7219\n",
            "Epoch 5/10 | Train Loss: 0.2644 | Train Accuracy: 0.8980\n",
            "  Train Per-Class Precision: {'false': 0.9144050104384134, 'true': 0.8670062252405206}\n",
            "  Train Per-Class Recall: {'false': 0.9288094516813087, 'true': 0.8422210005497526}\n",
            "  Train Per-Class F1: {'false': 0.9215509467989179, 'true': 0.8544339096486335}\n",
            "  Train Macro F1: 0.8879924282237757\n",
            "  Validation Loss: 0.8978\n",
            "Epoch 6/10 | Train Loss: 0.1726 | Train Accuracy: 0.9354\n",
            "  Train Per-Class Precision: {'false': 0.9417100371747212, 'true': 0.9234708392603129}\n",
            "  Train Per-Class Recall: {'false': 0.9592547712814299, 'true': 0.8922484881803189}\n",
            "  Train Per-Class F1: {'false': 0.9504014406843251, 'true': 0.907591220466937}\n",
            "  Train Macro F1: 0.928996330575631\n",
            "  Validation Loss: 1.1591\n",
            "Epoch 7/10 | Train Loss: 0.0973 | Train Accuracy: 0.9657\n",
            "  Train Per-Class Precision: {'false': 0.9675392670157068, 'true': 0.9623066104078762}\n",
            "  Train Per-Class Recall: {'false': 0.9797031202665859, 'true': 0.940351841671248}\n",
            "  Train Per-Class F1: {'false': 0.9735832016256492, 'true': 0.9512025580425414}\n",
            "  Train Macro F1: 0.9623928798340953\n",
            "  Validation Loss: 1.3987\n",
            "Epoch 8/10 | Train Loss: 0.0845 | Train Accuracy: 0.9710\n",
            "  Train Per-Class Precision: {'false': 0.9732772856928389, 'true': 0.9667504889633975}\n",
            "  Train Per-Class Recall: {'false': 0.9819751590427144, 'true': 0.9510720175920836}\n",
            "  Train Per-Class F1: {'false': 0.9776068762723366, 'true': 0.9588471664126368}\n",
            "  Train Macro F1: 0.9682270213424866\n",
            "  Validation Loss: 1.4872\n",
            "Epoch 9/10 | Train Loss: 0.0659 | Train Accuracy: 0.9774\n",
            "  Train Per-Class Precision: {'false': 0.9793829947328818, 'true': 0.9738525730180807}\n",
            "  Train Per-Class Recall: {'false': 0.9857618903362617, 'true': 0.9623419461242441}\n",
            "  Train Per-Class F1: {'false': 0.9825620895297048, 'true': 0.9680630443799253}\n",
            "  Train Macro F1: 0.975312566954815\n",
            "  Validation Loss: 1.4933\n",
            "Epoch 10/10 | Train Loss: 0.0450 | Train Accuracy: 0.9852\n",
            "  Train Per-Class Precision: {'false': 0.9864253393665159, 'true': 0.9828254847645429}\n",
            "  Train Per-Class Recall: {'false': 0.9906089063920024, 'true': 0.9752611324903794}\n",
            "  Train Per-Class F1: {'false': 0.9885126964933495, 'true': 0.9790286975717439}\n",
            "  Train Macro F1: 0.9837706970325467\n",
            "  Validation Loss: 1.7223\n",
            "Loading best model from best_model.pth\n",
            "Training with params:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-0b51d53853bb>:386: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(best_model_path))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'dropout': 0.23222950781790103, 'embedding_dim': 300, 'hidden_dim': 64, 'learning_rate': 0.011813170424378244, 'n_layers': 2}\n",
            "Epoch 1/10 | Train Loss: 0.6496 | Train Accuracy: 0.6417\n",
            "  Train Per-Class Precision: {'false': 0.6501484590969592, 'true': 0.46723044397463004}\n",
            "  Train Per-Class Recall: {'false': 0.9618297485610421, 'true': 0.06074766355140187}\n",
            "  Train Per-Class F1: {'false': 0.7758568024925163, 'true': 0.10751641936268548}\n",
            "  Train Macro F1: 0.4416866109276009\n",
            "  Validation Loss: 0.6124\n",
            "  Best model saved to best_model.pth (val_loss=0.6124)\n",
            "Epoch 2/10 | Train Loss: 0.5949 | Train Accuracy: 0.6819\n",
            "  Train Per-Class Precision: {'false': 0.7087754337785545, 'true': 0.585464333781965}\n",
            "  Train Per-Class Recall: {'false': 0.8600424113904878, 'true': 0.35871357888949973}\n",
            "  Train Per-Class F1: {'false': 0.777116266338192, 'true': 0.44486108743821373}\n",
            "  Train Macro F1: 0.6109886768882029\n",
            "  Validation Loss: 0.6367\n",
            "Epoch 3/10 | Train Loss: 0.5150 | Train Accuracy: 0.7484\n",
            "  Train Per-Class Precision: {'false': 0.7798943270300334, 'true': 0.6742125984251969}\n",
            "  Train Per-Class Recall: {'false': 0.8495910330202969, 'true': 0.5648708081363386}\n",
            "  Train Per-Class F1: {'false': 0.8132521386109903, 'true': 0.6147173197726593}\n",
            "  Train Macro F1: 0.7139847291918249\n",
            "  Validation Loss: 0.6336\n",
            "Epoch 4/10 | Train Loss: 0.4368 | Train Accuracy: 0.8007\n",
            "  Train Per-Class Precision: {'false': 0.831516208751272, 'true': 0.7375781017554299}\n",
            "  Train Per-Class Recall: {'false': 0.8664041199636474, 'true': 0.6814183617372183}\n",
            "  Train Per-Class F1: {'false': 0.8486017357762777, 'true': 0.7083869124160594}\n",
            "  Train Macro F1: 0.7784943240961686\n",
            "  Validation Loss: 0.6996\n",
            "Epoch 5/10 | Train Loss: 0.3847 | Train Accuracy: 0.8294\n",
            "  Train Per-Class Precision: {'false': 0.8560950564764559, 'true': 0.7762196903301197}\n",
            "  Train Per-Class Recall: {'false': 0.8839745531657074, 'true': 0.7303463441451347}\n",
            "  Train Per-Class F1: {'false': 0.8698114613607572, 'true': 0.7525846197422461}\n",
            "  Train Macro F1: 0.8111980405515016\n",
            "  Validation Loss: 0.8028\n",
            "Epoch 6/10 | Train Loss: 0.3410 | Train Accuracy: 0.8500\n",
            "  Train Per-Class Precision: {'false': 0.8776088252832439, 'true': 0.7975651189127972}\n",
            "  Train Per-Class Recall: {'false': 0.8916994850045441, 'true': 0.774326553051127}\n",
            "  Train Per-Class F1: {'false': 0.8845980465815176, 'true': 0.7857740585774059}\n",
            "  Train Macro F1: 0.8351860525794618\n",
            "  Validation Loss: 0.8441\n",
            "Epoch 7/10 | Train Loss: 0.3096 | Train Accuracy: 0.8676\n",
            "  Train Per-Class Precision: {'false': 0.8932533733133433, 'true': 0.8196078431372549}\n",
            "  Train Per-Class Recall: {'false': 0.9024538018782188, 'true': 0.8042880703683343}\n",
            "  Train Per-Class F1: {'false': 0.8978300180831826, 'true': 0.8118756936736959}\n",
            "  Train Macro F1: 0.8548528558784393\n",
            "  Validation Loss: 0.8713\n",
            "Epoch 8/10 | Train Loss: 0.2827 | Train Accuracy: 0.8820\n",
            "  Train Per-Class Precision: {'false': 0.9067873303167421, 'true': 0.8365650969529086}\n",
            "  Train Per-Class Recall: {'false': 0.9106331414722811, 'true': 0.8301264431006047}\n",
            "  Train Per-Class F1: {'false': 0.9087061668681983, 'true': 0.8333333333333334}\n",
            "  Train Macro F1: 0.8710197501007658\n",
            "  Validation Loss: 0.9068\n",
            "Epoch 9/10 | Train Loss: 0.2677 | Train Accuracy: 0.8850\n",
            "  Train Per-Class Precision: {'false': 0.9105358764759309, 'true': 0.8384700055035773}\n",
            "  Train Per-Class Recall: {'false': 0.9110875492275068, 'true': 0.837548103353491}\n",
            "  Train Per-Class F1: {'false': 0.9108116293155664, 'true': 0.838008800880088}\n",
            "  Train Macro F1: 0.8744102150978272\n",
            "  Validation Loss: 1.0394\n",
            "Epoch 10/10 | Train Loss: 0.2622 | Train Accuracy: 0.8938\n",
            "  Train Per-Class Precision: {'false': 0.9153486970929356, 'true': 0.8542071646764787}\n",
            "  Train Per-Class Recall: {'false': 0.9204786428355044, 'true': 0.845519516217702}\n",
            "  Train Per-Class F1: {'false': 0.9179065025300204, 'true': 0.8498411382787678}\n",
            "  Train Macro F1: 0.8838738204043941\n",
            "  Validation Loss: 0.9447\n",
            "Loading best model from best_model.pth\n",
            "Training with params:\n",
            "{'dropout': 0.5757689911471838, 'embedding_dim': 500, 'hidden_dim': 128, 'learning_rate': 0.017965359418866466, 'n_layers': 2}\n",
            "  6%|         | 3/50 [01:12<18:26, 23.54s/trial, best loss: -0.493802732020892]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-0b51d53853bb>:386: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(best_model_path))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train Loss: 0.6802 | Train Accuracy: 0.6169\n",
            "  Train Per-Class Precision: {'false': 0.6496480840129595, 'true': 0.3894491854150504}\n",
            "  Train Per-Class Recall: {'false': 0.8807936988791275, 'true': 0.13798790544255085}\n",
            "  Train Per-Class F1: {'false': 0.7477657043657172, 'true': 0.2037751167038766}\n",
            "  Train Macro F1: 0.4757704105347969\n",
            "  Validation Loss: 0.6383\n",
            "  Best model saved to best_model.pth (val_loss=0.6383)\n",
            "Epoch 2/10 | Train Loss: 0.6729 | Train Accuracy: 0.6195\n",
            "  Train Per-Class Precision: {'false': 0.6560913705583756, 'true': 0.4179389312977099}\n",
            "  Train Per-Class Recall: {'false': 0.8614056346561648, 'true': 0.1805937328202309}\n",
            "  Train Per-Class F1: {'false': 0.7448592010478061, 'true': 0.25220729366602684}\n",
            "  Train Macro F1: 0.4985332473569165\n",
            "  Validation Loss: 0.6839\n",
            "Epoch 3/10 | Train Loss: 0.6839 | Train Accuracy: 0.6130\n",
            "  Train Per-Class Precision: {'false': 0.6541291905151267, 'true': 0.4032162001191185}\n",
            "  Train Per-Class Recall: {'false': 0.8482278097546199, 'true': 0.18609125893347994}\n",
            "  Train Per-Class F1: {'false': 0.7386401107960167, 'true': 0.254654880571751}\n",
            "  Train Macro F1: 0.49664749568388383\n",
            "  Validation Loss: 0.6425\n",
            "Epoch 4/10 | Train Loss: 0.6720 | Train Accuracy: 0.6236\n",
            "  Train Per-Class Precision: {'false': 0.6588806660499538, 'true': 0.4321608040201005}\n",
            "  Train Per-Class Recall: {'false': 0.8630717964253256, 'true': 0.18911489829576691}\n",
            "  Train Per-Class F1: {'false': 0.7472786885245901, 'true': 0.2630975143403442}\n",
            "  Train Macro F1: 0.5051881014324672\n",
            "  Validation Loss: 0.6422\n",
            "Epoch 5/10 | Train Loss: 0.6691 | Train Accuracy: 0.6270\n",
            "  Train Per-Class Precision: {'false': 0.6602534562211981, 'true': 0.44166666666666665}\n",
            "  Train Per-Class Recall: {'false': 0.8680702817328082, 'true': 0.18938977460142936}\n",
            "  Train Per-Class F1: {'false': 0.7500327182305981, 'true': 0.26510196229318966}\n",
            "  Train Macro F1: 0.5075673402618939\n",
            "  Validation Loss: 0.6280\n",
            "  Best model saved to best_model.pth (val_loss=0.6280)\n",
            "Epoch 6/10 | Train Loss: 0.6642 | Train Accuracy: 0.6287\n",
            "  Train Per-Class Precision: {'false': 0.6612160294795025, 'true': 0.4473007712082262}\n",
            "  Train Per-Class Recall: {'false': 0.8697364435019691, 'true': 0.19131390874106652}\n",
            "  Train Per-Class F1: {'false': 0.7512756770901479, 'true': 0.268001540238737}\n",
            "  Train Macro F1: 0.5096386086644424\n",
            "  Validation Loss: 0.6568\n",
            "Epoch 7/10 | Train Loss: 0.6623 | Train Accuracy: 0.6333\n",
            "  Train Per-Class Precision: {'false': 0.6665107030061995, 'true': 0.46540508574807804}\n",
            "  Train Per-Class Recall: {'false': 0.8630717964253256, 'true': 0.21632765255634964}\n",
            "  Train Per-Class F1: {'false': 0.7521615734934988, 'true': 0.29536498404954026}\n",
            "  Train Macro F1: 0.5237632787715195\n",
            "  Validation Loss: 0.6446\n",
            "Epoch 8/10 | Train Loss: 0.6658 | Train Accuracy: 0.6274\n",
            "  Train Per-Class Precision: {'false': 0.6648917287894923, 'true': 0.4505310229178312}\n",
            "  Train Per-Class Recall: {'false': 0.8511057255377158, 'true': 0.22155030236393622}\n",
            "  Train Per-Class F1: {'false': 0.7465621470803162, 'true': 0.2970333517597199}\n",
            "  Train Macro F1: 0.5217977494200181\n",
            "  Validation Loss: 0.6451\n",
            "Epoch 9/10 | Train Loss: 0.6742 | Train Accuracy: 0.6259\n",
            "  Train Per-Class Precision: {'false': 0.6635580214850667, 'true': 0.44544940644431885}\n",
            "  Train Per-Class Recall: {'false': 0.8514086640411996, 'true': 0.2166025288620121}\n",
            "  Train Per-Class F1: {'false': 0.7458369269554833, 'true': 0.2914740151655262}\n",
            "  Train Macro F1: 0.5186554710605047\n",
            "  Validation Loss: 0.6490\n",
            "Epoch 10/10 | Train Loss: 0.6757 | Train Accuracy: 0.6218\n",
            "  Train Per-Class Precision: {'false': 0.6589400116482237, 'true': 0.42900302114803623}\n",
            "  Train Per-Class Recall: {'false': 0.8568615571039079, 'true': 0.19516217702034086}\n",
            "  Train Per-Class F1: {'false': 0.744979258576414, 'true': 0.2682788588702059}\n",
            "  Train Macro F1: 0.50662905872331\n",
            "  Validation Loss: 0.6631\n",
            "Loading best model from best_model.pth\n",
            "Training with params:\n",
            "{'dropout': 0.6727236395056491, 'embedding_dim': 150, 'hidden_dim': 224, 'learning_rate': 0.017922780544731492, 'n_layers': 2}\n",
            "  8%|         | 4/50 [01:40<19:08, 24.97s/trial, best loss: -0.49904337452450087]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-0b51d53853bb>:386: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(best_model_path))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train Loss: 0.6924 | Train Accuracy: 0.6083\n",
            "  Train Per-Class Precision: {'false': 0.6474001592900216, 'true': 0.3714679531357684}\n",
            "  Train Per-Class Recall: {'false': 0.8618600424113905, 'true': 0.14815832875206159}\n",
            "  Train Per-Class F1: {'false': 0.7393931518419856, 'true': 0.21182943603851445}\n",
            "  Train Macro F1: 0.47561129394025004\n",
            "  Validation Loss: 0.6390\n",
            "  Best model saved to best_model.pth (val_loss=0.6390)\n",
            "Epoch 2/10 | Train Loss: 0.6739 | Train Accuracy: 0.6234\n",
            "  Train Per-Class Precision: {'false': 0.656129178985672, 'true': 0.42461964038727523}\n",
            "  Train Per-Class Recall: {'false': 0.8739775825507422, 'true': 0.16877405167674547}\n",
            "  Train Per-Class F1: {'false': 0.7495453364510263, 'true': 0.24154209284028325}\n",
            "  Train Macro F1: 0.4955437146456548\n",
            "  Validation Loss: 0.6385\n",
            "  Best model saved to best_model.pth (val_loss=0.6385)\n",
            "Epoch 3/10 | Train Loss: 0.6656 | Train Accuracy: 0.6292\n",
            "  Train Per-Class Precision: {'false': 0.6589235127478753, 'true': 0.44381625441696115}\n",
            "  Train Per-Class Recall: {'false': 0.8807936988791275, 'true': 0.1726223199560198}\n",
            "  Train Per-Class F1: {'false': 0.7538730796655215, 'true': 0.24856520878685928}\n",
            "  Train Macro F1: 0.5012191442261904\n",
            "  Validation Loss: 0.7323\n",
            "Epoch 4/10 | Train Loss: 0.6566 | Train Accuracy: 0.6400\n",
            "  Train Per-Class Precision: {'false': 0.6666285714285715, 'true': 0.48389261744966444}\n",
            "  Train Per-Class Recall: {'false': 0.8835201454104816, 'true': 0.1981858163826278}\n",
            "  Train Per-Class F1: {'false': 0.7599009900990099, 'true': 0.28120124804992197}\n",
            "  Train Macro F1: 0.5205511190744659\n",
            "  Validation Loss: 0.6631\n",
            "Epoch 5/10 | Train Loss: 0.6368 | Train Accuracy: 0.6578\n",
            "  Train Per-Class Precision: {'false': 0.6883053732069049, 'true': 0.5332671300893744}\n",
            "  Train Per-Class Recall: {'false': 0.8576189033626174, 'true': 0.2952171522814733}\n",
            "  Train Per-Class F1: {'false': 0.763690315619099, 'true': 0.38004246284501064}\n",
            "  Train Macro F1: 0.5718663892320548\n",
            "  Validation Loss: 0.6795\n",
            "Epoch 6/10 | Train Loss: 0.6259 | Train Accuracy: 0.6750\n",
            "  Train Per-Class Precision: {'false': 0.70370831259333, 'true': 0.5703266787658802}\n",
            "  Train Per-Class Recall: {'false': 0.8565586186004241, 'true': 0.34551951621770205}\n",
            "  Train Per-Class F1: {'false': 0.7726465364120781, 'true': 0.4303320780554605}\n",
            "  Train Macro F1: 0.6014893072337693\n",
            "  Validation Loss: 0.6943\n",
            "Epoch 7/10 | Train Loss: 0.6279 | Train Accuracy: 0.6745\n",
            "  Train Per-Class Precision: {'false': 0.7075028564174178, 'true': 0.5645366060093102}\n",
            "  Train Per-Class Recall: {'false': 0.8441381399575886, 'true': 0.36668499175371083}\n",
            "  Train Per-Class F1: {'false': 0.7698045445127426, 'true': 0.4445925679053491}\n",
            "  Train Macro F1: 0.6071985562090458\n",
            "  Validation Loss: 0.6637\n",
            "Epoch 8/10 | Train Loss: 0.6082 | Train Accuracy: 0.6872\n",
            "  Train Per-Class Precision: {'false': 0.7161388782907288, 'true': 0.5915018931426167}\n",
            "  Train Per-Class Recall: {'false': 0.8529233565586186, 'true': 0.38647608576140735}\n",
            "  Train Per-Class F1: {'false': 0.7785689595575527, 'true': 0.4674979218620116}\n",
            "  Train Macro F1: 0.6230334407097822\n",
            "  Validation Loss: 0.7024\n",
            "Epoch 9/10 | Train Loss: 0.6031 | Train Accuracy: 0.6926\n",
            "  Train Per-Class Precision: {'false': 0.7216944801026958, 'true': 0.6}\n",
            "  Train Per-Class Recall: {'false': 0.8515601332929416, 'true': 0.4040681693238043}\n",
            "  Train Per-Class F1: {'false': 0.7812673707615342, 'true': 0.48291721419185285}\n",
            "  Train Macro F1: 0.6320922924766935\n",
            "  Validation Loss: 0.7602\n",
            "Epoch 10/10 | Train Loss: 0.7586 | Train Accuracy: 0.6299\n",
            "  Train Per-Class Precision: {'false': 0.6909807117631078, 'true': 0.4735927727588603}\n",
            "  Train Per-Class Recall: {'false': 0.770524083611027, 'true': 0.37465640461792193}\n",
            "  Train Per-Class F1: {'false': 0.7285877971927814, 'true': 0.4183548189073051}\n",
            "  Train Macro F1: 0.5734713080500433\n",
            "  Validation Loss: 0.7965\n",
            "Loading best model from best_model.pth\n",
            " 10%|         | 5/50 [02:19<22:32, 30.05s/trial, best loss: -0.49904337452450087]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-0b51d53853bb>:386: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(best_model_path))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with params:\n",
            "{'dropout': 0.33936392123706527, 'embedding_dim': 250, 'hidden_dim': 96, 'learning_rate': 0.04472961886479249, 'n_layers': 2}\n",
            "Epoch 1/10 | Train Loss: 0.7028 | Train Accuracy: 0.6139\n",
            "  Train Per-Class Precision: {'false': 0.6522889348976305, 'true': 0.3978007761966365}\n",
            "  Train Per-Class Recall: {'false': 0.8589821266282944, 'true': 0.16904892798240792}\n",
            "  Train Per-Class F1: {'false': 0.7415010460251046, 'true': 0.23726851851851852}\n",
            "  Train Macro F1: 0.48938478227181154\n",
            "  Validation Loss: 0.6592\n",
            "  Best model saved to best_model.pth (val_loss=0.6592)\n",
            "Epoch 2/10 | Train Loss: 0.7412 | Train Accuracy: 0.5878\n",
            "  Train Per-Class Precision: {'false': 0.6487939007624047, 'true': 0.3698079499776686}\n",
            "  Train Per-Class Recall: {'false': 0.7862768857921841, 'true': 0.22759758108851016}\n",
            "  Train Per-Class F1: {'false': 0.710949804834623, 'true': 0.28177641653905056}\n",
            "  Train Macro F1: 0.4963631106868368\n",
            "  Validation Loss: 0.7960\n",
            "Epoch 3/10 | Train Loss: 0.8954 | Train Accuracy: 0.5617\n",
            "  Train Per-Class Precision: {'false': 0.6468463462072798, 'true': 0.36028928336620647}\n",
            "  Train Per-Class Recall: {'false': 0.7052408361102697, 'true': 0.3012644310060473}\n",
            "  Train Per-Class F1: {'false': 0.6747826086956522, 'true': 0.3281437125748503}\n",
            "  Train Macro F1: 0.5014631606352513\n",
            "  Validation Loss: 0.8202\n",
            "Epoch 4/10 | Train Loss: 0.8715 | Train Accuracy: 0.5671\n",
            "  Train Per-Class Precision: {'false': 0.6489084168611836, 'true': 0.365573216097396}\n",
            "  Train Per-Class Recall: {'false': 0.7158436837322024, 'true': 0.2971412864211105}\n",
            "  Train Per-Class F1: {'false': 0.6807346056895931, 'true': 0.3278241091736164}\n",
            "  Train Macro F1: 0.5042793574316047\n",
            "  Validation Loss: 0.9311\n",
            "Epoch 5/10 | Train Loss: 0.8306 | Train Accuracy: 0.5691\n",
            "  Train Per-Class Precision: {'false': 0.6487367563162184, 'true': 0.3655316191799861}\n",
            "  Train Per-Class Recall: {'false': 0.7234171463192972, 'true': 0.2891698735568994}\n",
            "  Train Per-Class F1: {'false': 0.6840446863362933, 'true': 0.3228974831184776}\n",
            "  Train Macro F1: 0.5034710847273854\n",
            "  Validation Loss: 0.7687\n",
            "Epoch 6/10 | Train Loss: 0.8372 | Train Accuracy: 0.5675\n",
            "  Train Per-Class Precision: {'false': 0.6483276450511946, 'true': 0.36432246998284734}\n",
            "  Train Per-Class Recall: {'false': 0.719327476522266, 'true': 0.2919186366135239}\n",
            "  Train Per-Class F1: {'false': 0.6819846341638544, 'true': 0.324126354341523}\n",
            "  Train Macro F1: 0.5030554942526887\n",
            "  Validation Loss: 0.7923\n",
            "Epoch 7/10 | Train Loss: 0.8352 | Train Accuracy: 0.5636\n",
            "  Train Per-Class Precision: {'false': 0.6441800730025686, 'true': 0.3538515652479775}\n",
            "  Train Per-Class Recall: {'false': 0.7217509845501363, 'true': 0.2765255634964266}\n",
            "  Train Per-Class F1: {'false': 0.6807629116365455, 'true': 0.31044591883968525}\n",
            "  Train Macro F1: 0.4956044152381154\n",
            "  Validation Loss: 0.8019\n",
            "Epoch 8/10 | Train Loss: 0.8291 | Train Accuracy: 0.5604\n",
            "  Train Per-Class Precision: {'false': 0.6415475869506606, 'true': 0.34691708008504607}\n",
            "  Train Per-Class Recall: {'false': 0.7208421690396849, 'true': 0.2691039032435404}\n",
            "  Train Per-Class F1: {'false': 0.6788873038516405, 'true': 0.30309597523219817}\n",
            "  Train Macro F1: 0.4909916395419194\n",
            "  Validation Loss: 0.7887\n",
            "Epoch 9/10 | Train Loss: 0.8216 | Train Accuracy: 0.5673\n",
            "  Train Per-Class Precision: {'false': 0.6455679227571409, 'true': 0.3575278476464247}\n",
            "  Train Per-Class Recall: {'false': 0.7291729778854893, 'true': 0.27350192413413965}\n",
            "  Train Per-Class F1: {'false': 0.6848282239135074, 'true': 0.3099205731194518}\n",
            "  Train Macro F1: 0.4973743985164796\n",
            "  Validation Loss: 0.8506\n",
            "Epoch 10/10 | Train Loss: 0.8093 | Train Accuracy: 0.5696\n",
            "  Train Per-Class Precision: {'false': 0.6459635589839074, 'true': 0.35869165747886805}\n",
            "  Train Per-Class Recall: {'false': 0.7356861557103908, 'true': 0.2682792743265531}\n",
            "  Train Per-Class F1: {'false': 0.6879116209900149, 'true': 0.3069665041673219}\n",
            "  Train Macro F1: 0.49743906257866843\n",
            "  Validation Loss: 0.8184\n",
            "Loading best model from best_model.pth\n",
            "Training with params:\n",
            "{'dropout': 0.6675897457743496, 'embedding_dim': 450, 'hidden_dim': 192, 'learning_rate': 0.005743419494870472, 'n_layers': 2}\n",
            " 12%|        | 6/50 [02:38<19:20, 26.37s/trial, best loss: -0.49904337452450087]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-0b51d53853bb>:386: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(best_model_path))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train Loss: 0.6517 | Train Accuracy: 0.6362\n",
            "  Train Per-Class Precision: {'false': 0.65613806577662, 'true': 0.45764362220058424}\n",
            "  Train Per-Class Recall: {'false': 0.9156316267797637, 'true': 0.12919186366135238}\n",
            "  Train Per-Class F1: {'false': 0.7644641163452418, 'true': 0.2015005359056806}\n",
            "  Train Macro F1: 0.4829823261254612\n",
            "  Validation Loss: 0.6210\n",
            "  Best model saved to best_model.pth (val_loss=0.6210)\n",
            " 12%|        | 6/50 [02:46<19:20, 26.37s/trial, best loss: -0.49904337452450087]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "# ... (rest of your imports and functions)\n",
        "\n",
        "# Train final model with best hyperparameters\n",
        "print(\"Best Hyperparameters:\", best)\n",
        "best_params = {\n",
        "    'embedding_dim': int(best['embedding_dim']),\n",
        "    'hidden_dim': int(best['hidden_dim']),\n",
        "    'n_layers': int(best['n_layers']),\n",
        "    'dropout': best['dropout'],\n",
        "    'learning_rate': best['learning_rate']\n",
        "}\n",
        "\n",
        "final_model = BiLSTMModel(\n",
        "    input_dim=train_vocab_size + 1,\n",
        "    embedding_dim=best_params['embedding_dim'],\n",
        "    hidden_dim=best_params['hidden_dim'],\n",
        "    output_dim=train_label_counts.shape[0],\n",
        "    n_layers=best_params['n_layers'],\n",
        "    dropout=best_params['dropout']\n",
        ")\n",
        "final_model.to(device)\n",
        "\n",
        "optimizer = optim.AdamW(final_model.parameters(), lr=best_params['learning_rate'])\n",
        "\n",
        "# Example of using class weights:\n",
        "class_weights = torch.tensor([2.0, 1.0], dtype=torch.float).to(device) # You might need to adjust these\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "criterion.to(device)\n",
        "\n",
        "# --- Validation data setup ---\n",
        "X_val, _, _, _, y_val = as_tensors(\"valid\", label_encoder=label_encoder, known_vector_size=X_train.shape[1], token_to_idx=token_to_idx)\n",
        "val_dataset = TensorDataset(X_val, y_val)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Train the final model on the combined training and validation sets\n",
        "combined_X = torch.cat((X_train, X_val), dim=0)\n",
        "combined_y = torch.cat((y_train, y_val), dim=0)\n",
        "combined_dataset = TensorDataset(combined_X, combined_y)\n",
        "combined_loader = DataLoader(combined_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "def train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=10):\n",
        "    # Move model to device\n",
        "    model.to(device)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_path = \"best_model.pth\"\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # --- Training phase ---\n",
        "        model.train()  # Put model in training mode\n",
        "        train_epoch_loss = 0\n",
        "        train_epoch_tps = 0\n",
        "        train_total_samples = 0\n",
        "        y_true_train = []\n",
        "        y_pred_train = []\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(inputs)\n",
        "            loss = criterion(predictions, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_epoch_loss += loss.item()\n",
        "            _, predicted_classes = torch.max(predictions, 1)\n",
        "            train_epoch_tps += (predicted_classes == labels).sum().item()\n",
        "            train_total_samples += labels.size(0)\n",
        "\n",
        "            y_true_train.extend(labels.cpu().numpy())\n",
        "            y_pred_train.extend(predicted_classes.cpu().numpy())\n",
        "\n",
        "        y_true_train = torch.tensor(y_true_train, dtype=torch.long)\n",
        "        y_pred_train = torch.tensor(y_pred_train, dtype=torch.long)\n",
        "\n",
        "        train_results, train_f1_macro = evaluate(y_true_train, train_label_counts.shape[0], y_pred_train, y_pred_train, y_pred_train, label_encoder.classes_)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_epoch_loss/len(train_loader):.4f} | Train Accuracy: {train_epoch_tps/train_total_samples:.4f}\")\n",
        "        print(f\"  Train Per-Class Precision: {train_results['Model']['Per-Class Precision']}\")\n",
        "        print(f\"  Train Per-Class Recall: {train_results['Model']['Per-Class Recall']}\")\n",
        "        print(f\"  Train Per-Class F1: {train_results['Model']['Per-Class F1']}\")\n",
        "        print(f\"  Train Macro F1: {train_results['Model']['Macro F1']}\")\n",
        "\n",
        "        # --- Validation phase ---\n",
        "        val_loss = 0\n",
        "        model.eval()  # Put model in evaluation mode\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                predictions = model(inputs)\n",
        "                loss = criterion(predictions, labels)\n",
        "                val_loss += loss.item()\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        print(f\"  Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "        # Save the model if the validation loss is better than the best so far\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "            print(f\"  Best model saved to {best_model_path} (val_loss={best_val_loss:.4f})\")\n",
        "\n",
        "    # Load the best model\n",
        "    print(f\"Loading best model from {best_model_path}\")\n",
        "    model.load_state_dict(torch.load(best_model_path))\n",
        "    return model\n",
        "\n",
        "# Call train_model and assign the returned model back to final_model\n",
        "final_model = train_model(final_model, combined_loader, val_loader, optimizer, criterion, device, epochs=20)\n",
        "\n",
        "\"\"\"## Evaluate Model\"\"\"\n",
        "\n",
        "def evaluate_data(model, loader, num_classes, num_instances, label_ordering, orig_label_counts, device):\n",
        "    model.eval()\n",
        "    model_pred, labels = get_predictions(loader, model, num_instances, pred_type='model', device=device)\n",
        "    baseline_pred = get_predictions(\n",
        "        loader, model, num_instances, pred_type='baseline',\n",
        "        label_ordering=label_ordering, orig_label_counts=orig_label_counts\n",
        "    )\n",
        "    random_pred = get_predictions(loader, model, num_instances, pred_type='random', num_classes=num_classes)\n",
        "\n",
        "    print()\n",
        "\n",
        "    labels = labels.cpu()\n",
        "    model_pred = model_pred.cpu()\n",
        "    baseline_pred = baseline_pred.cpu()\n",
        "    random_pred = random_pred.cpu()\n",
        "\n",
        "    results, _ = evaluate(labels, num_classes, model_pred, baseline_pred, random_pred, label_ordering)\n",
        "    pprint.pprint(results)\n",
        "\n",
        "    conf_matrix = confusion_matrix(labels.cpu(), model_pred.cpu())\n",
        "    class_labels = label_ordering\n",
        "\n",
        "    def plot_confusion_matrix(conf_matrix, class_labels):\n",
        "        sns.heatmap(\n",
        "            conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
        "            xticklabels=class_labels, yticklabels=class_labels\n",
        "        )\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.xlabel('Predicted Labels')\n",
        "        plt.ylabel('True Labels')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    print(\"\\n\")\n",
        "    plot_confusion_matrix(conf_matrix, class_labels)\n",
        "\n",
        "X_test, _, _, _, y_test = as_tensors(\"test\", label_encoder, input_vector_size, token_to_idx)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "evaluate_data(final_model, test_loader, train_label_counts.shape[0], y_test.size(0), label_encoder.classes_, train_label_counts, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xPnBoead4qDl",
        "outputId": "5de5a1d4-3fa8-4093-feeb-f1f44da0edda"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'dropout': 0.3637721950380055, 'embedding_dim': 150.0, 'hidden_dim': 256.0, 'learning_rate': 0.013031848705016969, 'n_layers': 1.0}\n",
            "The training dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1284 entries, 0 to 1283\n",
            "Data columns (total 14 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   id                    1284 non-null   object\n",
            " 1   label                 1284 non-null   object\n",
            " 2   claim                 1284 non-null   object\n",
            " 3   subject               1284 non-null   object\n",
            " 4   speaker               1284 non-null   object\n",
            " 5   speaker_job_title     939 non-null    object\n",
            " 6   state_info            1005 non-null   object\n",
            " 7   party_affiliation     1284 non-null   object\n",
            " 8   barely_true_counts    1284 non-null   int64 \n",
            " 9   false_counts          1284 non-null   int64 \n",
            " 10  half_true_counts      1284 non-null   int64 \n",
            " 11  mostly_true_counts    1284 non-null   int64 \n",
            " 12  pants_on_fire_counts  1284 non-null   int64 \n",
            " 13  context               1272 non-null   object\n",
            "dtypes: int64(5), object(9)\n",
            "memory usage: 140.6+ KB\n",
            "\n",
            "Data peek:\n",
            "            id        label  \\\n",
            "0   12134.json  barely-true   \n",
            "1     238.json   pants-fire   \n",
            "2    7891.json        false   \n",
            "3    8169.json    half-true   \n",
            "4     929.json    half-true   \n",
            "5    9416.json        false   \n",
            "6    6861.json         true   \n",
            "7    1122.json        false   \n",
            "8   13138.json         true   \n",
            "9    1880.json    half-true   \n",
            "10  12803.json    half-true   \n",
            "11   5409.json        false   \n",
            "12   7313.json    half-true   \n",
            "13   4809.json         true   \n",
            "14   1671.json  barely-true   \n",
            "15   4348.json    half-true   \n",
            "16   6225.json    half-true   \n",
            "17   7675.json  mostly-true   \n",
            "18   2255.json  barely-true   \n",
            "19   9827.json   pants-fire   \n",
            "\n",
            "                                                claim  \\\n",
            "0   We have less Americans working now than in the...   \n",
            "1   When Obama was sworn into office, he DID NOT u...   \n",
            "2   Says Having organizations parading as being so...   \n",
            "3      Says nearly half of Oregons children are poor.   \n",
            "4   On attacks by Republicans that various program...   \n",
            "5   Says when armed civilians stop mass shootings ...   \n",
            "6   Says Tennessee is providing millions of dollar...   \n",
            "7   The health care reform plan would set limits s...   \n",
            "8   Says Donald Trump started his career back in 1...   \n",
            "9   Bill White has a long history of trying to lim...   \n",
            "10  John McCains chief economic adviser during the...   \n",
            "11  Says 21,000 Wisconsin residents got jobs in 20...   \n",
            "12  State revenue projections have missed the mark...   \n",
            "13  The median income of a middle class family wen...   \n",
            "14  Every citizen is entitled to the freedom of sp...   \n",
            "15  Rick Perry has advocated abandoning Social Sec...   \n",
            "16  Two thirds to three quarters of people without...   \n",
            "17  Congress has spent 66 of the first 100 days of...   \n",
            "18  Mark Sharpe has lowered property taxes by 17 p...   \n",
            "19  Says Iowa Gov. Terry Branstad chartered a plan...   \n",
            "\n",
            "                                      subject                 speaker  \\\n",
            "0                                economy,jobs          vicky-hartzler   \n",
            "1            obama-birth-certificate,religion             chain-email   \n",
            "2             campaign-finance,congress,taxes         earl-blumenauer   \n",
            "3                                     poverty         jim-francesconi   \n",
            "4                            economy,stimulus            barack-obama   \n",
            "5                                        guns              jim-rubens   \n",
            "6                      education,state-budget              andy-berke   \n",
            "7                                 health-care             club-growth   \n",
            "8      candidates-biography,diversity,housing         hillary-clinton   \n",
            "9                                    military  republican-party-texas   \n",
            "10                                    economy               tim-kaine   \n",
            "11            job-accomplishments,jobs,states       kathleen-vinehout   \n",
            "12                               state-budget            steve-henson   \n",
            "13                  income,new-hampshire-2012               joe-biden   \n",
            "14                          gays-and-lesbians          david-dewhurst   \n",
            "15             medicaid,social-security,taxes        margaret-carlson   \n",
            "16  health-care,poverty,public-health,welfare       elizabeth-roberts   \n",
            "17                                   congress             john-barrow   \n",
            "18                 candidates-biography,taxes             mark-sharpe   \n",
            "19                                immigration             chain-email   \n",
            "\n",
            "                                speaker_job_title            state_info  \\\n",
            "0                             U.S. Representative              Missouri   \n",
            "1                                             NaN                   NaN   \n",
            "2                             U.S. representative                Oregon   \n",
            "3   Member of the State Board of Higher Education                Oregon   \n",
            "4                                       President              Illinois   \n",
            "5                            Small business owner         New Hampshire   \n",
            "6                        Lawyer and state senator             Tennessee   \n",
            "7                                             NaN                   NaN   \n",
            "8                          Presidential candidate              New York   \n",
            "9                                             NaN                 Texas   \n",
            "10                                   U.S. Senator              Virginia   \n",
            "11                                            NaN                   NaN   \n",
            "12                                  State Senator               Georgia   \n",
            "13                                   U.S. senator              Delaware   \n",
            "14                            Lieutenant governor                 Texas   \n",
            "15                                      Columnist  District of Columbia   \n",
            "16                            Lieutenant Governor          Rhode Island   \n",
            "17                                    Congressman               Georgia   \n",
            "18               Hillsborough County commissioner               Florida   \n",
            "19                                            NaN                   NaN   \n",
            "\n",
            "   party_affiliation  barely_true_counts  false_counts  half_true_counts  \\\n",
            "0         republican                   1             0                 1   \n",
            "1               none                  11            43                 8   \n",
            "2           democrat                   0             1                 1   \n",
            "3               none                   0             1                 1   \n",
            "4           democrat                  70            71               160   \n",
            "5         republican                   1             1                 0   \n",
            "6           democrat                   0             0                 0   \n",
            "7               none                   4             5                 4   \n",
            "8           democrat                  40            29                69   \n",
            "9         republican                   3             1                 1   \n",
            "10          democrat                   8             3                15   \n",
            "11          democrat                   1             1                 1   \n",
            "12          democrat                   0             0                 1   \n",
            "13          democrat                  11            10                21   \n",
            "14        republican                   8             8                10   \n",
            "15              none                   0             0                 1   \n",
            "16          democrat                   1             0                 2   \n",
            "17          democrat                   0             0                 1   \n",
            "18        republican                   1             0                 0   \n",
            "19              none                  11            43                 8   \n",
            "\n",
            "    mostly_true_counts  pants_on_fire_counts  \\\n",
            "0                    0                     0   \n",
            "1                    5                   105   \n",
            "2                    1                     0   \n",
            "3                    1                     0   \n",
            "4                  163                     9   \n",
            "5                    1                     0   \n",
            "6                    0                     0   \n",
            "7                    2                     0   \n",
            "8                   76                     7   \n",
            "9                    3                     1   \n",
            "10                  15                     0   \n",
            "11                   1                     0   \n",
            "12                   0                     0   \n",
            "13                  16                     4   \n",
            "14                   5                     5   \n",
            "15                   0                     0   \n",
            "16                   0                     0   \n",
            "17                   1                     0   \n",
            "18                   0                     0   \n",
            "19                   5                   105   \n",
            "\n",
            "                                              context  \n",
            "0                        an interview with ABC17 News  \n",
            "1                                                 NaN  \n",
            "2                       a U.S. Ways and Means hearing  \n",
            "3                                  an opinion article  \n",
            "4                             interview with CBS News  \n",
            "5         in an interview at gun shop in Hudson, N.H.  \n",
            "6   a letter to state Senate education committee c...  \n",
            "7                                             a TV ad  \n",
            "8                       the first presidential debate  \n",
            "9                                           an e-mail  \n",
            "10  a speech at the Democratic National Convention...  \n",
            "11                                            remarks  \n",
            "12                                    a press release  \n",
            "13  speaking at New Hampshires Plymouth State Uni...  \n",
            "14                                    a press release  \n",
            "15                                 a politics column.  \n",
            "16        a panel discussion on \"A Lively Experiment\"  \n",
            "17                                           a letter  \n",
            "18                                  a campaign mailer  \n",
            "19                                      a chain email  \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3637721950380055 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized sentences(1284 sentences, 55513 total tokens) peek:\n",
            "  ['less', 'americans', 'working', '70s', '.', '|', 'state_info', ':', 'missouri', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'vicky-hartzler', '|', 'subject', ':', 'economy', ',', 'jobs', '|', 'context', ':', 'interview', 'abc17', 'news', '|', 'speaker_job_title', ':', 'u.s.', 'representative', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['obama', 'sworn', 'office', ',', 'use', 'holy', 'bible', ',', 'instead', 'kuran', '(', 'their', 'equivalency', 'bible', ',', 'different', 'beliefs', ')', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'chain-email', '|', 'subject', ':', 'obama-birth-certificate', ',', 'religion', '|', 'context', ':', 'nan', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['says', 'organizations', 'parading', 'social', 'welfare', 'organizations', 'involved', 'political', 'combat', 'harkens', 'back', 'statute', 'hundred', 'years', 'ago', 'said', 'prohibited', '.', '|', 'state_info', ':', 'oregon', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'earl-blumenauer', '|', 'subject', ':', 'campaign-finance', ',', 'congress', ',', 'taxes', '|', 'context', ':', 'u.s.', 'ways', 'means', 'hearing', '|', 'speaker_job_title', ':', 'u.s.']\n",
            "  ['says', 'nearly', 'half', 'oregons', 'children', 'poor', '.', '|', 'state_info', ':', 'oregon', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'jim-francesconi', '|', 'subject', ':', 'poverty', '|', 'context', ':', 'opinion', 'article', '|', 'speaker_job_title', ':', 'member', 'state', 'board', 'higher', 'education', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['attacks', 'republicans', 'various', 'programs', 'economic', 'stimulus', 'plan', 'stimulative', ',', '``', 'if', 'add', 'stuff', 'up', ',', 'accounts', 'less', '1', 'percent', 'overall', 'package', '.', \"''\", '|', 'state_info', ':', 'illinois', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'barack-obama', '|', 'subject', ':', 'economy', ',', 'stimulus', '|', 'context', ':', 'interview', 'cbs', 'news', '|', 'speaker_job_title']\n",
            "  ['says', 'armed', 'civilians', 'stop', 'mass', 'shootings', 'guns', ',', 'average', '2.5', 'people', 'die', ';', 'otherwise', ',', 'average', '18', 'people', 'die', '.', '|', 'state_info', ':', 'new', 'hampshire', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'jim-rubens', '|', 'subject', ':', 'guns', '|', 'context', ':', 'interview', 'gun', 'shop', 'hudson', ',', 'n.h.', '|', 'speaker_job_title', ':']\n",
            "  ['says', 'tennessee', 'providing', 'millions', 'dollars', 'virtual', 'school', 'company', 'results', 'bottom', 'bottom', '.', '|', 'state_info', ':', 'tennessee', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'andy-berke', '|', 'subject', ':', 'education', ',', 'state-budget', '|', 'context', ':', 'letter', 'state', 'senate', 'education', 'committee', 'chairwoman', 'dolores', 'gresham', '.', '|', 'speaker_job_title', ':', 'lawyer', 'state', 'senator', '<PAD>']\n",
            "  ['health', 'care', 'reform', 'plan', 'would', 'set', 'limits', 'similar', 'socialized', 'system', 'britain', ',', 'people', 'allowed', 'die', 'treatment', 'would', 'cost', '$', '22,000', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'club-growth', '|', 'subject', ':', 'health-care', '|', 'context', ':', 'tv', 'ad', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['says', 'donald', 'trump', 'started', 'career', 'back', '1973', 'sued', 'justice', 'department', 'racial', 'discrimination', 'would', 'rent', 'apartments', 'one', 'developments', 'african-americans', '.', '|', 'state_info', ':', 'new', 'york', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'hillary-clinton', '|', 'subject', ':', 'candidates-biography', ',', 'diversity', ',', 'housing', '|', 'context', ':', 'first', 'presidential', 'debate', '|', 'speaker_job_title', ':']\n",
            "  ['bill', 'white', 'long', 'history', 'trying', 'limit', 'even', 'disenfranchise', 'military', 'voters', '.', '|', 'state_info', ':', 'texas', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'republican-party-texas', '|', 'subject', ':', 'military', '|', 'context', ':', 'e-mail', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['john', 'mccains', 'chief', 'economic', 'adviser', '08', 'race', 'estimated', 'trumps', 'promises', 'would', 'cause', 'america', 'lose', '3.5', 'million', 'jobs', '.', '|', 'state_info', ':', 'virginia', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'tim-kaine', '|', 'subject', ':', 'economy', '|', 'context', ':', 'speech', 'democratic', 'national', 'convention', 'philadelphia', '|', 'speaker_job_title', ':', 'u.s.', 'senator', '<PAD>', '<PAD>']\n",
            "  ['says', '21,000', 'wisconsin', 'residents', 'got', 'jobs', '2011', ',', '18,000', 'states', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'kathleen-vinehout', '|', 'subject', ':', 'job-accomplishments', ',', 'jobs', ',', 'states', '|', 'context', ':', 'remarks', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['state', 'revenue', 'projections', 'missed', 'mark', 'month', 'month', '.', '|', 'state_info', ':', 'georgia', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'steve-henson', '|', 'subject', ':', 'state-budget', '|', 'context', ':', 'press', 'release', '|', 'speaker_job_title', ':', 'state', 'senator', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['median', 'income', 'middle', 'class', 'family', 'went', '$', '2,100', '2001', '2007', '.', '|', 'state_info', ':', 'delaware', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'joe-biden', '|', 'subject', ':', 'income', ',', 'new-hampshire-2012', '|', 'context', ':', 'speaking', 'new', 'hampshires', 'plymouth', 'state', 'university', '|', 'speaker_job_title', ':', 'u.s.', 'senator', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['every', 'citizen', 'entitled', 'freedom', 'speech', ',', 'one', 'right', 'use', 'government', 'funds', 'institutions', 'portray', 'acts', 'morally', 'reprehensible', 'vast', 'majority', 'americans', '.', '|', 'state_info', ':', 'texas', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'david-dewhurst', '|', 'subject', ':', 'gays-and-lesbians', '|', 'context', ':', 'press', 'release', '|', 'speaker_job_title', ':', 'lieutenant', 'governor', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['rick', 'perry', 'advocated', 'abandoning', 'social', 'security', ',', 'scuttling', 'medicaid', 'ending', 'federal', 'income', 'tax', '.', '|', 'state_info', ':', 'district', 'columbia', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'margaret-carlson', '|', 'subject', ':', 'medicaid', ',', 'social-security', ',', 'taxes', '|', 'context', ':', 'politics', 'column', '.', '|', 'speaker_job_title', ':', 'columnist', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['two', 'thirds', 'three', 'quarters', 'people', 'without', '[', 'health', ']', 'insurance', 'rhode', 'island', 'work', '.', '|', 'state_info', ':', 'rhode', 'island', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'elizabeth-roberts', '|', 'subject', ':', 'health-care', ',', 'poverty', ',', 'public-health', ',', 'welfare', '|', 'context', ':', 'panel', 'discussion', '``', 'a', 'lively', 'experiment', \"''\", '|', 'speaker_job_title']\n",
            "  ['congress', 'spent', '66', 'first', '100', 'days', 'term', 'recess', '.', '|', 'state_info', ':', 'georgia', '|', 'party_affiliation', ':', 'democrat', '|', 'speaker', ':', 'john-barrow', '|', 'subject', ':', 'congress', '|', 'context', ':', 'letter', '|', 'speaker_job_title', ':', 'congressman', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['mark', 'sharpe', 'lowered', 'property', 'taxes', '17', 'percent', '.', '|', 'state_info', ':', 'florida', '|', 'party_affiliation', ':', 'republican', '|', 'speaker', ':', 'mark-sharpe', '|', 'subject', ':', 'candidates-biography', ',', 'taxes', '|', 'context', ':', 'campaign', 'mailer', '|', 'speaker_job_title', ':', 'hillsborough', 'county', 'commissioner', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "  ['says', 'iowa', 'gov', '.', 'terry', 'branstad', 'chartered', 'plane', 'remove', '124', 'young', 'illegal', 'immigrants', 'state', 'take', 'back', 'honduras', '.', '|', 'state_info', ':', 'nan', '|', 'party_affiliation', ':', 'none', '|', 'speaker', ':', 'chain-email', '|', 'subject', ':', 'immigration', '|', 'context', ':', 'chain', 'email', '|', 'speaker_job_title', ':', 'nan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "\n",
            "10000 unique tokens\n",
            "Unique tokens peek:\n",
            "  <PAD>\n",
            "  |\n",
            "  :\n",
            "  ,\n",
            "  .\n",
            "  speaker\n",
            "  state_info\n",
            "  party_affiliation\n",
            "  subject\n",
            "  context\n",
            "  speaker_job_title\n",
            "  republican\n",
            "  nan\n",
            "  democrat\n",
            "  says\n",
            "  u.s.\n",
            "  none\n",
            "  interview\n",
            "  new\n",
            "  state\n",
            "\n",
            "Final Index Sets(Set_Size = 49, 1284 index sets) peek:\n",
            "  [233, 152, 406, 0, 5, 2, 7, 3, 542, 2, 8, 3, 12, 2, 6, 3, 7845, 2, 9, 3, 25, 4, 29, 2, 10, 3, 18, 0, 40, 2, 11, 3, 16, 62, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [47, 4897, 164, 4, 367, 0, 2946, 4, 1497, 0, 37, 5601, 0, 2946, 4, 986, 3042, 38, 5, 2, 7, 3, 13, 2, 8, 3, 17, 2, 6, 3, 267, 2, 9, 3, 1208, 4, 263, 2, 10, 3, 13, 2, 11, 3, 13, 1, 1, 1, 1]\n",
            "  [15, 2200, 0, 143, 417, 2200, 1784, 201, 2652, 0, 382, 6648, 3469, 59, 431, 91, 4005, 5, 2, 7, 3, 104, 2, 8, 3, 14, 2, 6, 3, 4008, 2, 9, 3, 197, 4, 81, 4, 23, 2, 10, 3, 16, 2904, 1000, 360, 2, 11, 3, 16]\n",
            "  [15, 208, 272, 1734, 113, 1149, 5, 2, 7, 3, 104, 2, 8, 3, 17, 2, 6, 3, 7618, 2, 9, 3, 159, 2, 10, 3, 446, 249, 2, 11, 3, 186, 20, 274, 337, 39, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [1042, 262, 1272, 701, 365, 131, 128, 0, 4, 24, 2500, 1409, 6121, 712, 4, 1823, 233, 165, 30, 1782, 1897, 5, 27, 2, 7, 3, 61, 2, 8, 3, 14, 2, 6, 3, 73, 2, 9, 3, 25, 4, 131, 2, 10, 3, 18, 653, 40, 2, 11]\n",
            "  [15, 3343, 8780, 583, 1190, 1317, 85, 4, 181, 1929, 60, 1117, 956, 4391, 4, 181, 723, 60, 1117, 5, 2, 7, 3, 19, 216, 2, 8, 3, 12, 2, 6, 3, 8012, 2, 9, 3, 85, 2, 10, 3, 18, 286, 6258, 6434, 4, 474, 2, 11, 3]\n",
            "  [15, 412, 3615, 383, 214, 0, 137, 561, 3447, 1121, 1121, 5, 2, 7, 3, 412, 2, 8, 3, 14, 2, 6, 3, 0, 2, 9, 3, 39, 4, 52, 2, 10, 3, 297, 20, 66, 39, 221, 2932, 0, 0, 5, 2, 11, 3, 620, 20, 32, 1]\n",
            "  [57, 68, 329, 128, 65, 1226, 2697, 1696, 4097, 302, 3782, 4, 60, 636, 1117, 1943, 65, 230, 26, 4190, 5, 2, 7, 3, 13, 2, 8, 3, 17, 2, 6, 3, 1682, 2, 9, 3, 31, 2, 10, 3, 78, 42, 2, 11, 3, 13, 1, 1, 1]\n",
            "  [15, 259, 225, 783, 1298, 382, 3164, 3318, 656, 296, 4433, 2436, 65, 2397, 4408, 77, 0, 2098, 5, 2, 7, 3, 19, 45, 2, 8, 3, 14, 2, 6, 3, 153, 2, 9, 3, 54, 4, 420, 4, 348, 2, 10, 3, 129, 70, 46, 2, 11, 3]\n",
            "  [80, 260, 1080, 63, 904, 1470, 156, 0, 82, 362, 5, 2, 7, 3, 21, 2, 8, 3, 12, 2, 6, 3, 2796, 2, 9, 3, 82, 2, 10, 3, 281, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [238, 5764, 833, 365, 1498, 0, 970, 1252, 1329, 3110, 65, 987, 163, 807, 2907, 71, 29, 5, 2, 7, 3, 69, 2, 8, 3, 14, 2, 6, 3, 765, 2, 9, 3, 25, 2, 10, 3, 33, 117, 102, 218, 847, 2, 11, 3, 16, 32, 1, 1]\n",
            "  [15, 0, 34, 665, 340, 29, 354, 4, 3610, 44, 5, 2, 7, 3, 13, 2, 8, 3, 14, 2, 6, 3, 5288, 2, 9, 3, 124, 4, 29, 4, 44, 2, 10, 3, 276, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [20, 610, 4525, 2023, 954, 533, 533, 5, 2, 7, 3, 58, 2, 8, 3, 14, 2, 6, 3, 0, 2, 9, 3, 52, 2, 10, 3, 50, 53, 2, 11, 3, 20, 32, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [1735, 103, 538, 607, 411, 388, 26, 6210, 1467, 1155, 5, 2, 7, 3, 496, 2, 8, 3, 14, 2, 6, 3, 563, 2, 9, 3, 103, 4, 558, 2, 10, 3, 2858, 19, 8844, 8712, 20, 306, 2, 11, 3, 16, 32, 1, 1, 1, 1, 1, 1]\n",
            "  [89, 2193, 0, 1235, 33, 4, 77, 235, 367, 110, 624, 2150, 0, 4557, 0, 0, 2268, 292, 152, 5, 2, 7, 3, 21, 2, 8, 3, 12, 2, 6, 3, 1062, 2, 9, 3, 339, 2, 10, 3, 50, 53, 2, 11, 3, 461, 35, 1, 1, 1]\n",
            "  [251, 541, 2342, 0, 143, 182, 4, 0, 223, 2222, 96, 103, 51, 5, 2, 7, 3, 127, 1406, 2, 8, 3, 17, 2, 6, 3, 0, 2, 9, 3, 223, 4, 312, 4, 23, 2, 10, 3, 1271, 224, 5, 2, 11, 3, 448, 1, 1, 1, 1]\n",
            "  [209, 5565, 207, 6449, 60, 317, 253, 57, 254, 177, 72, 74, 316, 5, 2, 7, 3, 72, 74, 2, 8, 3, 14, 2, 6, 3, 5065, 2, 9, 3, 31, 4, 159, 4, 169, 4, 417, 2, 10, 3, 824, 559, 24, 603, 8771, 5951, 27, 2, 11]\n",
            "  [81, 335, 4273, 129, 393, 524, 813, 0, 5, 2, 7, 3, 58, 2, 8, 3, 14, 2, 6, 3, 0, 2, 9, 3, 81, 2, 10, 3, 297, 2, 11, 3, 188, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [954, 0, 5036, 476, 23, 958, 30, 5, 2, 7, 3, 22, 2, 8, 3, 12, 2, 6, 3, 0, 2, 9, 3, 54, 4, 23, 2, 10, 3, 36, 356, 2, 11, 3, 2686, 87, 481, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "  [15, 307, 191, 5, 2806, 0, 0, 2575, 1744, 0, 655, 219, 353, 20, 344, 382, 4784, 5, 2, 7, 3, 13, 2, 8, 3, 17, 2, 6, 3, 267, 2, 9, 3, 56, 2, 10, 3, 414, 184, 2, 11, 3, 13, 1, 1, 1, 1, 1, 1]\n",
            "VALID SPLIT: 1284 overall samples: torch.Size([1284, 49])\n",
            "Epoch 1/20 | Train Loss: 0.5392 | Train Accuracy: 0.6719\n",
            "  Train Per-Class Precision: {'false': 0.6228483420909585, 'true': 0.828695652173913}\n",
            "  Train Per-Class Recall: {'false': 0.9208411465309403, 'true': 0.40714896041013954}\n",
            "  Train Per-Class F1: {'false': 0.7430825767401643, 'true': 0.5460275019098548}\n",
            "  Train Macro F1: 0.6445550393250096\n",
            "  Validation Loss: 0.4756\n",
            "  Best model saved to best_model.pth (val_loss=0.4756)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "cudnn RNN backward can only be called in training mode",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a74350a66ce9>\u001b[0m in \u001b[0;36m<cell line: 103>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\"\"\"## Evaluate Model\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-a74350a66ce9>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, optimizer, criterion, device, epochs)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cudnn RNN backward can only be called in training mode"
          ]
        }
      ]
    }
  ]
}