{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ozyb-vXSAMtT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "import torch.optim as optim\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "import random\n",
        "import pprint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "cF0LGpIbKgBP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "475d440b-2275-4506-8636-0fa7ec249dca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vGZJybiAMtV"
      },
      "source": [
        "## Read in data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "peek = 10\n",
        "def present_list_like(name, list_like, peek=peek):\n",
        "    print(f\"{name} peek:\")\n",
        "    print('  ' + '\\n  '.join([str(seq) for seq in list_like[0:peek]]))"
      ],
      "metadata": {
        "id": "BCo7k9jXdxOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lNu54LNAMtV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87593dae-c088-4b04-b863-69dc99335123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6591 entries, 0 to 6590\n",
            "Data columns (total 4 columns):\n",
            " #   Column            Non-Null Count  Dtype \n",
            "---  ------            --------------  ----- \n",
            " 0   misconception_id  6591 non-null   int64 \n",
            " 1   misconception     6591 non-null   object\n",
            " 2   tweet_id          6591 non-null   int64 \n",
            " 3   label             6591 non-null   object\n",
            "dtypes: int64(2), object(2)\n",
            "memory usage: 206.1+ KB\n",
            "\n",
            "Data peek:\n",
            "   misconception_id                                      misconception  \\\n",
            "0                 3             Coronavirus is genetically engineered.   \n",
            "1                30  Blowing conch shells destroys coronavirus pote...   \n",
            "2                57  Swans and dolphins swimming in Venice canals f...   \n",
            "3                22                         Cocaine cures coronavirus.   \n",
            "4                32  Observing janata curfew will result in the red...   \n",
            "5                25  Holy communion cannot be the cause of the spre...   \n",
            "6                61  Lions were freed to keep people off the street...   \n",
            "7                 3             Coronavirus is genetically engineered.   \n",
            "8                40                Cannabis protects against COVID-19.   \n",
            "9                50  It is safe for individuals infected with COVID...   \n",
            "\n",
            "              tweet_id label  \n",
            "0  1233965490948591616    na  \n",
            "1  1233907923765559296    na  \n",
            "2  1233911842910720000    na  \n",
            "3  1233947734094290944    na  \n",
            "4  1233937085297332224    na  \n",
            "5  1233955845756653568    na  \n",
            "6  1233917889557692416    na  \n",
            "7  1233952635725778944    na  \n",
            "8  1233940738439815168    na  \n",
            "9  1233920123183828992    na  \n",
            "\n",
            "Unique labels: ['na' 'neg' 'pos']\n",
            "Counts of 'labels': label\n",
            "na     0.932939\n",
            "pos    0.043696\n",
            "neg    0.023365\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "#Read data from covid_lies.csv dataset into dataframe\n",
        "df = pd.read_csv('./data/covid_lies.csv')\n",
        "print(\"The dataset:\")\n",
        "df.info()\n",
        "print(\"\\nData peek:\")\n",
        "print(df.head(peek))\n",
        "print()\n",
        "\n",
        "#Seperate out text data and labels\n",
        "input_text = df['misconception'].to_numpy()\n",
        "input_label = df['label'].to_numpy()\n",
        "print(\"Unique labels:\", np.unique(input_label))\n",
        "orig_label_counts = df['label'].value_counts(normalize=True)\n",
        "print(\"Counts of 'labels':\", orig_label_counts)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Balance the dataset\n",
        "\n",
        "from sklearn.utils import resample\n",
        "\n",
        "df_majority = df[df['label'] == 'na']\n",
        "df_minority_1 = df[df['label'] == 'pos']\n",
        "df_minority_2 = df[df['label'] == 'neg']\n",
        "\n",
        "# Upsample minority classes\n",
        "df_minority_1_upsampled = resample(\n",
        "    df_minority_1, replace=True, n_samples=len(df_majority),  random_state=42\n",
        ")\n",
        "df_minority_2_upsampled = resample(\n",
        "    df_minority_2, replace=True, n_samples=len(df_majority), random_state=42\n",
        ")\n",
        "\n",
        "# Create the balanced df out of the new sample sets\n",
        "df_balanced = pd.concat([df_majority, df_minority_1_upsampled, df_minority_2_upsampled])\n",
        "\n",
        "# Present the new df\n",
        "print(\"The dataset has been balanced\\n\")\n",
        "print(\"The dataset:\")\n",
        "df_balanced.info()\n",
        "print(\"\\nData peek:\")\n",
        "print(df_balanced.head(peek))\n",
        "print()\n",
        "\n",
        "# Seperate out text data and labels\n",
        "input_text = df_balanced['misconception'].to_numpy()\n",
        "input_label = df_balanced['label'].to_numpy()\n",
        "print(\"Unique labels:\", np.unique(input_label))\n",
        "print(\"Counts of labels:\")\n",
        "print(df_balanced['label'].value_counts(normalize=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hxqtJcLvmir",
        "outputId": "cd7758b6-9bd2-4913-ce95-c7e92be64067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset has been balanced\n",
            "\n",
            "The dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 18447 entries, 0 to 2179\n",
            "Data columns (total 4 columns):\n",
            " #   Column            Non-Null Count  Dtype \n",
            "---  ------            --------------  ----- \n",
            " 0   misconception_id  18447 non-null  int64 \n",
            " 1   misconception     18447 non-null  object\n",
            " 2   tweet_id          18447 non-null  int64 \n",
            " 3   label             18447 non-null  object\n",
            "dtypes: int64(2), object(2)\n",
            "memory usage: 720.6+ KB\n",
            "\n",
            "Data peek:\n",
            "   misconception_id                                      misconception  \\\n",
            "0                 3             Coronavirus is genetically engineered.   \n",
            "1                30  Blowing conch shells destroys coronavirus pote...   \n",
            "2                57  Swans and dolphins swimming in Venice canals f...   \n",
            "3                22                         Cocaine cures coronavirus.   \n",
            "4                32  Observing janata curfew will result in the red...   \n",
            "5                25  Holy communion cannot be the cause of the spre...   \n",
            "6                61  Lions were freed to keep people off the street...   \n",
            "7                 3             Coronavirus is genetically engineered.   \n",
            "8                40                Cannabis protects against COVID-19.   \n",
            "9                50  It is safe for individuals infected with COVID...   \n",
            "\n",
            "              tweet_id label  \n",
            "0  1233965490948591616    na  \n",
            "1  1233907923765559296    na  \n",
            "2  1233911842910720000    na  \n",
            "3  1233947734094290944    na  \n",
            "4  1233937085297332224    na  \n",
            "5  1233955845756653568    na  \n",
            "6  1233917889557692416    na  \n",
            "7  1233952635725778944    na  \n",
            "8  1233940738439815168    na  \n",
            "9  1233920123183828992    na  \n",
            "\n",
            "Unique labels: ['na' 'neg' 'pos']\n",
            "Counts of labels:\n",
            "label\n",
            "na     0.333333\n",
            "pos    0.333333\n",
            "neg    0.333333\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNsUDJdhAMtW"
      },
      "source": [
        "## Preprocess input data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8PtD24vAMtW"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text)->str:\n",
        "    #Letter-level cleaning\n",
        "    text = text.lower()\n",
        "    valid_asciis = {9, *range(32, 127)}\n",
        "    text = ''.join(filter(lambda x: ord(x) in valid_asciis, text))\n",
        "\n",
        "    #Word/sequence-level cleaning\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess the text\n",
        "for i in range(len(input_text)):\n",
        "    input_text[i] = preprocess_text(input_text[i])"
      ],
      "metadata": {
        "id": "z-l4_oDDUSLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwmzm7pYAMtW"
      },
      "source": [
        "## Tokenize input text data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenize the text\n",
        "\n",
        "input_tokens = [nltk.word_tokenize(text) for text in input_text]\n",
        "\n",
        "# Split tokens based on non-alphanumeric characters\n",
        "final_tokens = []\n",
        "total_tokens = 0\n",
        "for token_set in input_tokens:\n",
        "    final_tkn_set = []\n",
        "    for tk in token_set:\n",
        "        sub_tkns = [c for c in re.split(r\"(\\W+)\", tk) if c]\n",
        "        total_tokens += len(sub_tkns)\n",
        "        final_tkn_set += sub_tkns\n",
        "    final_tokens.append(final_tkn_set)\n",
        "present_list_like(f\"Tokenized sentences({len(final_tokens)} sentences, {total_tokens} tokens)\", final_tokens)"
      ],
      "metadata": {
        "id": "QvKgthj0WYNm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "186dadda-0fb7-42c8-c0a9-9fa36eeb40fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized sentences(18447 sentences, 133252 tokens) peek:\n",
            "  ['coronavirus', 'genetically', 'engineered', '.']\n",
            "  ['blowing', 'conch', 'shells', 'destroys', 'coronavirus', 'potency', '.']\n",
            "  ['swans', 'dolphins', 'swimming', 'venice', 'canals', 'following', 'covid', '-', '19', 'lockdown', '.']\n",
            "  ['cocaine', 'cures', 'coronavirus', '.']\n",
            "  ['observing', 'janata', 'curfew', 'result', 'reduction', 'covid', '-', '19', 'cases', '40', '%', '.']\n",
            "  ['holy', 'communion', 'can', 'not', 'cause', 'spread', 'coronavirus']\n",
            "  ['lions', 'freed', 'keep', 'people', 'streets', 'moscow', '.']\n",
            "  ['coronavirus', 'genetically', 'engineered', '.']\n",
            "  ['cannabis', 'protects', 'covid', '-', '19', '.']\n",
            "  ['safe', 'individuals', 'infected', 'covid', '-', '19', 'go', 'work', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fg2l2lJsAMtX"
      },
      "source": [
        "## Form embeddings for input data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Embed the tokens\n",
        "\n",
        "# Map each token to its frequency in the dataset\n",
        "flat_tokens = [word for token_set in final_tokens for word in token_set]\n",
        "frequencies = Counter(flat_tokens)\n",
        "token_to_idx = {word: idx+1 for idx, (word, _) in enumerate(frequencies.most_common())}\n",
        "vocab_size = len(token_to_idx)\n",
        "print(vocab_size, \"unique tokens\")\n",
        "present_list_like(\"Unique tokens\", list(token_to_idx.keys()))\n",
        "\n",
        "# Embed the tokens\n",
        "freq_indexed = [[token_to_idx[token] for token in token_set] for token_set in final_tokens]\n",
        "\n",
        "# Make embeddings the same size\n",
        "forced_idx_set_size = max(len(idxs) for idxs in freq_indexed)\n",
        "freq_indexed = [\n",
        "    idxs[:forced_idx_set_size] + [0]*(forced_idx_set_size - len(idxs))\n",
        "    for idxs in freq_indexed\n",
        "]\n",
        "present_list_like(f\"\\nFinal Index Sets(Set_Size = {forced_idx_set_size}, {len(freq_indexed)} index sets)\", freq_indexed)"
      ],
      "metadata": {
        "id": "xR1GIMwXbRzb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c56208ad-a018-4a9d-d083-203728affb4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "266 unique tokens\n",
            "Unique tokens peek:\n",
            "  .\n",
            "  -\n",
            "  coronavirus\n",
            "  covid\n",
            "  19\n",
            "  deadly\n",
            "  seasonal\n",
            "  flu\n",
            "  survive\n",
            "  cure\n",
            "\n",
            "Final Index Sets(Set_Size = 19, 18447 index sets) peek:\n",
            "  [3, 15, 16, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "  [134, 135, 136, 137, 3, 138, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "  [165, 166, 167, 99, 100, 62, 4, 2, 5, 63, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "  [168, 30, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "  [241, 242, 243, 244, 245, 4, 2, 5, 246, 247, 248, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "  [22, 23, 17, 18, 24, 19, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "  [169, 170, 171, 172, 96, 173, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "  [3, 15, 16, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "  [174, 66, 4, 2, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "  [108, 109, 74, 4, 2, 5, 110, 111, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YKnA7ShAMtX"
      },
      "source": [
        "## Define and train a GRU model using PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=n_layers, batch_first=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, hidden = self.gru(self.embedding(x))\n",
        "        return self.fc(hidden[-1])"
      ],
      "metadata": {
        "id": "ON_dnwJThucS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training fn\n",
        "def train_model(model, dataloader, optimizer, criterion, device, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        epoch_tps = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(inputs).squeeze()\n",
        "            loss = criterion(predictions, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item() #Track total loss\n",
        "            #Track total accuracy\n",
        "            _, predicted_classes = torch.max(predictions, 1)\n",
        "            epoch_tps += (predicted_classes == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {epoch_loss/len(dataloader):.4f} | Accuracy: {epoch_tps/total_samples:.4f}\")"
      ],
      "metadata": {
        "id": "u0U6Zv2v77Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMnIo7dVAMtX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b22d800-9eaa-4c23-dc43-a9e4d74690a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: GRUModel(\n",
            "  (embedding): Embedding(267, 1000)\n",
            "  (gru): GRU(1000, 128, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (fc): Linear(in_features=128, out_features=3, bias=True)\n",
            ")\n",
            "18447 overall samples of shape torch.Size([18447, 19])\n",
            "14757 training samples of shape torch.Size([14757, 19])\n",
            "3690 validation samples of shape torch.Size([3690, 19])\n"
          ]
        }
      ],
      "source": [
        "#Setup to train\n",
        "\n",
        "# Model and training structure\n",
        "INPUT_DIM = vocab_size + 1\n",
        "EMBEDDING_DIM = 1000\n",
        "HIDDEN_DIM = 128\n",
        "OUTPUT_DIM = orig_label_counts.shape[0]\n",
        "N_LAYERS = 2\n",
        "DROPOUT = 0.5\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 15\n",
        "\n",
        "# Make the model\n",
        "gru_model = GRUModel(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, DROPOUT)\n",
        "print(\"Model:\", gru_model)\n",
        "\n",
        "# Optimization & loss setup\n",
        "optimizer = torch.optim.Adam(gru_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Move model to GPU if possible\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "gru_model = gru_model.to(device)\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "# Setup the training dataset\n",
        "X = torch.tensor(freq_indexed, dtype=torch.long)\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(input_label)\n",
        "y = torch.tensor(y, dtype=torch.long)\n",
        "print(X.size(0), \"overall samples of shape\", X.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.numpy(), y.numpy(), test_size=0.2, random_state=42)\n",
        "X_train, X_test = torch.tensor(X_train, dtype=torch.long), torch.tensor(X_test, dtype=torch.long)\n",
        "y_train, y_test = torch.tensor(y_train, dtype=torch.long), torch.tensor(y_test, dtype=torch.long)\n",
        "print(X_train.size(0), \"training samples of shape\", X_train.shape)\n",
        "print(y_test.size(0), \"validation samples of shape\", X_test.shape)\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the model\n",
        "train_model(gru_model, train_loader, optimizer, criterion, device, EPOCHS)"
      ],
      "metadata": {
        "id": "dGvlx_i27-JI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "012e2082-adba-4f8d-c128-4b5f903189eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15 | Loss: 0.7200 | Accuracy: 0.6970\n",
            "Epoch 2/15 | Loss: 0.6513 | Accuracy: 0.7203\n",
            "Epoch 3/15 | Loss: 0.6450 | Accuracy: 0.7237\n",
            "Epoch 4/15 | Loss: 0.6409 | Accuracy: 0.7256\n",
            "Epoch 5/15 | Loss: 0.6395 | Accuracy: 0.7264\n",
            "Epoch 6/15 | Loss: 0.6372 | Accuracy: 0.7251\n",
            "Epoch 7/15 | Loss: 0.6361 | Accuracy: 0.7268\n",
            "Epoch 8/15 | Loss: 0.6383 | Accuracy: 0.7266\n",
            "Epoch 9/15 | Loss: 0.6367 | Accuracy: 0.7260\n",
            "Epoch 10/15 | Loss: 0.6356 | Accuracy: 0.7268\n",
            "Epoch 11/15 | Loss: 0.6357 | Accuracy: 0.7255\n",
            "Epoch 12/15 | Loss: 0.6341 | Accuracy: 0.7266\n",
            "Epoch 13/15 | Loss: 0.6363 | Accuracy: 0.7250\n",
            "Epoch 14/15 | Loss: 0.6351 | Accuracy: 0.7261\n",
            "Epoch 15/15 | Loss: 0.6340 | Accuracy: 0.7266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWNwH4d3AMtX"
      },
      "source": [
        "## Save Model Weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the model weights\n",
        "torch.save(gru_model.state_dict(), \"gru_model_weights.pth\")\n",
        "print(\"Model weights saved to 'gru_model_weights.pth'\")"
      ],
      "metadata": {
        "id": "nqUf6cLwiUYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b513d0b-2cb0-47ff-8d1e-ffa216fc3d83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights saved to 'gru_model_weights.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5c__mmaAMtX"
      },
      "source": [
        "## Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation functions\n",
        "import typing as tp\n",
        "\n",
        "# Get predictions\n",
        "def get_predictions(\n",
        "    test_loader, model, num_samples,\n",
        "    pred_type: tp.Literal['model', 'baseline', 'random'] = 'model',\n",
        "    device=None,\n",
        "    label_ordering=None, orig_label_counts=None,\n",
        "    num_classes=None\n",
        "):\n",
        "    predictions = []\n",
        "    y_test = []\n",
        "\n",
        "    if pred_type == 'model':\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in test_loader:\n",
        "                y_test.extend(batch_y)\n",
        "\n",
        "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "                batch_size = batch_X.size(0)\n",
        "\n",
        "                outputs = model(batch_X).squeeze()\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                predictions.extend(predicted.cpu())\n",
        "        y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "    elif pred_type == 'baseline':\n",
        "        orig_label_counts = orig_label_counts.sort_index(key=lambda idx: orig_label_counts[idx], inplace=False, ascending=False)\n",
        "        majority_class = list(label_ordering).index(orig_label_counts.index[0])\n",
        "        predictions += [majority_class for _ in range(num_samples)]\n",
        "    else:\n",
        "        predictions += [random.randint(0, num_classes - 1) for _ in range(num_samples)]\n",
        "\n",
        "    predictions = torch.tensor(predictions, dtype=torch.long)\n",
        "    if pred_type == 'model':\n",
        "        return predictions, y_test\n",
        "    return predictions\n",
        "\n",
        "# Calculate per-class metrics\n",
        "def per_class_metrics(labels, predictions, num_classes, label_ordering):\n",
        "    precision_per_class = precision_score(labels, predictions, average=None, labels=np.arange(num_classes), zero_division=0)\n",
        "    recall_per_class = recall_score(labels, predictions, average=None, labels=np.arange(num_classes), zero_division=0)\n",
        "    f1_per_class = f1_score(labels, predictions, average=None, labels=np.arange(num_classes), zero_division=0)\n",
        "\n",
        "    results = []\n",
        "    for metrics in [precision_per_class, recall_per_class, f1_per_class]:\n",
        "        results.append({label_ordering[i]: metrics[i] for i in range(len(metrics))})\n",
        "    return tuple(results)\n",
        "\n",
        "# Calculate Macro metrics\n",
        "def macro_metrics(labels, predictions):\n",
        "    precision_macro = precision_score(labels, predictions, average='macro', zero_division=0)\n",
        "    recall_macro = recall_score(labels, predictions, average='macro', zero_division=0)\n",
        "    f1_macro = f1_score(labels, predictions, average='macro', zero_division=0)\n",
        "\n",
        "    return precision_macro, recall_macro, f1_macro\n",
        "\n",
        "# Calculate Micro metrics\n",
        "def micro_metrics(labels, predictions):\n",
        "    precision_micro = precision_score(labels, predictions, average='micro', zero_division=0)\n",
        "    recall_micro = recall_score(labels, predictions, average='micro', zero_division=0)\n",
        "    f1_micro = f1_score(labels, predictions, average='micro', zero_division=0)\n",
        "\n",
        "    return precision_micro, recall_micro, f1_micro\n",
        "\n",
        "# Get evaluations\n",
        "def evaluate(labels, model_pred, baseline_pred, random_pred, label_ordering):\n",
        "    results = {}\n",
        "\n",
        "    for pred_type, predictions in [('Model', model_pred), ('Baseline', baseline_pred), ('Random', random_pred)]:\n",
        "        curr_results = results[pred_type] = {}\n",
        "\n",
        "        #Calculate metrics\n",
        "        accuracy = (predictions == labels).sum().item() / labels.size(0)\n",
        "        precision_per_class, recall_per_class, f1_per_class = per_class_metrics(labels, predictions, num_classes, label_ordering)\n",
        "        precision_macro, recall_macro, f1_macro = macro_metrics(labels, predictions)\n",
        "        precision_micro, recall_micro, f1_micro = micro_metrics(labels, predictions)\n",
        "\n",
        "        #Save all metrics\n",
        "        curr_results[\"Accuracy\"] = accuracy\n",
        "        curr_results[\"Per-Class Precision\"] = precision_per_class\n",
        "        curr_results[\"Per-Class Recall\"] = recall_per_class\n",
        "        curr_results[\"Per-Class F1\"] = f1_per_class\n",
        "\n",
        "        curr_results[\"Macro Precision\"] = precision_macro\n",
        "        curr_results[\"Macro Recall\"] = recall_macro\n",
        "        curr_results[\"Macro F1\"] = f1_macro\n",
        "\n",
        "        curr_results[\"Micro Precision\"]  = precision_micro\n",
        "        curr_results[\"Micro Recall\"] = recall_micro\n",
        "        curr_results[\"Micro F1\"] = f1_micro\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "R1jhLEJriIV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate and show results\n",
        "\n",
        "# Setup\n",
        "num_classes = OUTPUT_DIM\n",
        "\n",
        "# Get model, baseline, and random predictions\n",
        "#  Use model predictions to get the test labels since the\n",
        "#   test loader shuffles its values and is not in the same order as y_test upon iteration\n",
        "model_pred, labels = get_predictions(test_loader, gru_model, y_test.size(0), pred_type='model', device=device)\n",
        "#  Get other prediction types as normal\n",
        "baseline_pred = get_predictions(\n",
        "    test_loader, gru_model, y_test.size(0), pred_type='baseline',\n",
        "    label_ordering=label_encoder.classes_, orig_label_counts=orig_label_counts\n",
        ")\n",
        "random_pred = get_predictions(test_loader, gru_model, y_test.size(0), pred_type='random', num_classes=num_classes)\n",
        "\n",
        "print()\n",
        "\n",
        "# Print evaluation results\n",
        "pprint.pprint(evaluate(labels, model_pred, baseline_pred, random_pred, label_encoder.classes_))\n",
        "\n",
        "#  Confusion matrix to see misclassifications\n",
        "print(\"\\nModel Predictions confusion matrix:\")\n",
        "conf_matrix = confusion_matrix(labels, model_pred)\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9M-kBL9orNAt",
        "outputId": "a4099291-4c77-4990-a31a-06589b9ef8c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "{'Baseline': {'Accuracy': 0.3311653116531165,\n",
            "              'Macro F1': 0.16585233441910965,\n",
            "              'Macro Precision': 0.11038843721770551,\n",
            "              'Macro Recall': 0.3333333333333333,\n",
            "              'Micro F1': 0.3311653116531165,\n",
            "              'Micro Precision': 0.3311653116531165,\n",
            "              'Micro Recall': 0.3311653116531165,\n",
            "              'Per-Class F1': {'na': 0.497557003257329, 'neg': 0.0, 'pos': 0.0},\n",
            "              'Per-Class Precision': {'na': 0.3311653116531165,\n",
            "                                      'neg': 0.0,\n",
            "                                      'pos': 0.0},\n",
            "              'Per-Class Recall': {'na': 1.0, 'neg': 0.0, 'pos': 0.0}},\n",
            " 'Model': {'Accuracy': 0.7268292682926829,\n",
            "           'Macro F1': 0.7279780224838187,\n",
            "           'Macro Precision': 0.7332609616541305,\n",
            "           'Macro Recall': 0.7267120480263034,\n",
            "           'Micro F1': 0.7268292682926829,\n",
            "           'Micro Precision': 0.7268292682926829,\n",
            "           'Micro Recall': 0.7268292682926829,\n",
            "           'Per-Class F1': {'na': 0.7521968365553603,\n",
            "                            'neg': 0.7259439707673568,\n",
            "                            'pos': 0.7057932601287391},\n",
            "           'Per-Class Precision': {'na': 0.8121442125237192,\n",
            "                                   'neg': 0.7152,\n",
            "                                   'pos': 0.6724386724386724},\n",
            "           'Per-Class Recall': {'na': 0.7004909983633388,\n",
            "                                'neg': 0.7370156636438582,\n",
            "                                'pos': 0.7426294820717132}},\n",
            " 'Random': {'Accuracy': 0.3284552845528455,\n",
            "            'Macro F1': 0.3284502465638522,\n",
            "            'Macro Precision': 0.32846777386254394,\n",
            "            'Macro Recall': 0.32857441208782645,\n",
            "            'Micro F1': 0.3284552845528455,\n",
            "            'Micro Precision': 0.3284552845528455,\n",
            "            'Micro Recall': 0.3284552845528455,\n",
            "            'Per-Class F1': {'na': 0.3241042345276873,\n",
            "                             'neg': 0.33617539585870887,\n",
            "                             'pos': 0.3250711093051605},\n",
            "            'Per-Class Precision': {'na': 0.3225283630470016,\n",
            "                                    'neg': 0.3312,\n",
            "                                    'pos': 0.33167495854063017},\n",
            "            'Per-Class Recall': {'na': 0.32569558101472995,\n",
            "                                 'neg': 0.34130255564715584,\n",
            "                                 'pos': 0.3187250996015936}}}\n",
            "\n",
            "Model Predictions confusion matrix:\n",
            "[[856 126 240]\n",
            " [105 894 214]\n",
            " [ 93 230 932]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}