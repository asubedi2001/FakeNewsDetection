{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM0LA5blhcMIU23MV7kp4AU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asubedi2001/FakeNewsDetection/blob/BiLSTM/BiLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk --upgrade --force-reinstall"
      ],
      "metadata": {
        "id": "3g-a6gmS2FXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"GRUwithRelabling(11).ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1vBZZ-V5_C9Cu1wS4yWpAGUceU8s033H1\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import nltk\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "import torch.optim as optim\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import random\n",
        "import pprint\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "random.seed(184)\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt')\n",
        "\n",
        "\"\"\"## Read in data\"\"\"\n",
        "\n",
        "peek = 20\n",
        "def present_list_like(name, list_like, peek=peek):\n",
        "    print(f\"{name} peek:\")\n",
        "    print('  ' + '\\n  '.join( str(v) for v in list_like[:peek]))\n",
        "\n",
        "columns = [\n",
        "    'id', 'label', 'claim', 'subject', 'speaker', 'speaker_job_title', 'state_info',\n",
        "    'party_affiliation', 'barely_true_counts', 'false_counts',\n",
        "    'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context'\n",
        "]\n",
        "present_list_like(f\"Dataset columns({len(columns)} in total)\", columns, len(columns))\n",
        "def load_data(split):\n",
        "    df = pd.read_csv(f\"./data/{split}.tsv\", sep='\\t', names=columns)\n",
        "    df = df.drop(index=[\n",
        "        idx for idx in df.index if type(df[\"claim\"][idx]) == type(None) or not len(df[\"claim\"][idx])\n",
        "    ])\n",
        "    print(\"The training dataset:\")\n",
        "    df.info()\n",
        "    print(\"\\nData peek:\")\n",
        "    print(df.head(peek))\n",
        "    print()\n",
        "    return df\n",
        "\n",
        "\"\"\"##Tokenize the data\"\"\"\n",
        "\n",
        "pad_tkn = \"<PAD>\"\n",
        "\n",
        "def tokenize_text(input_text, known_vector_size=None, token_to_idx={}):\n",
        "    def preprocess_text(text)->str:\n",
        "        #Letter-level cleaning\n",
        "        text = text.lower()\n",
        "        valid_asciis = {9, *range(32, 127)}\n",
        "        text = ''.join(filter(lambda x: ord(x) in valid_asciis, text))\n",
        "\n",
        "        #Word/sequence-level cleaning\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = re.sub(r'http\\S+', '', text)\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        text = ' '.join(word for word in text.split() if word not in stop_words)\n",
        "        return text\n",
        "\n",
        "    #Preprocess the text\n",
        "    for i in range(len(input_text)):\n",
        "        input_text[i] = preprocess_text(input_text[i])\n",
        "\n",
        "    #Tokenize\n",
        "    final_tokens = input_tokens = [nltk.word_tokenize(text) for text in input_text]\n",
        "    total_tokens = sum(len(tkns) for tkns in final_tokens)\n",
        "\n",
        "    # Make all token sets the same length\n",
        "    forced_tkn_set_size = (\n",
        "        known_vector_size if known_vector_size\n",
        "        else int(np.percentile([len(tkns) for tkns in final_tokens], 80))\n",
        "    )\n",
        "    final_tokens = [\n",
        "        tkns[:forced_tkn_set_size] + [pad_tkn]*(forced_tkn_set_size - len(tkns))\n",
        "        for tkns in final_tokens\n",
        "    ]\n",
        "\n",
        "    # Present results\n",
        "    present_list_like(f\"Tokenized sentences({len(final_tokens)} sentences, {total_tokens} total tokens)\", final_tokens)\n",
        "\n",
        "    #Index the tokens\n",
        "    # Map each token to its frequency in the dataset\n",
        "    if not len(token_to_idx):\n",
        "        flat_tokens = [word for token_set in final_tokens for word in token_set]\n",
        "        frequencies = Counter(flat_tokens)\n",
        "        token_to_idx = {}\n",
        "        for idx, (word, _) in enumerate(frequencies.most_common()):\n",
        "            if idx >= 10000:\n",
        "                break\n",
        "            token_to_idx[word] = idx + 1\n",
        "        if pad_tkn not in token_to_idx:\n",
        "            token_to_idx[pad_tkn] = len(token_to_idx) + 1\n",
        "    vocab_size = len(token_to_idx)\n",
        "    print()\n",
        "    print(vocab_size, \"unique tokens\")\n",
        "    present_list_like(\"Unique tokens\", list(token_to_idx.keys()))\n",
        "\n",
        "    # Index the tokens\n",
        "    freq_indexed = [\n",
        "        [(token_to_idx[token] if token in token_to_idx else 0) for token in token_set]\n",
        "        for token_set in final_tokens\n",
        "    ]\n",
        "\n",
        "    # Present results\n",
        "    present_list_like(f\"\\nFinal Index Sets(Set_Size = {forced_tkn_set_size}, {len(freq_indexed)} index sets)\", freq_indexed)\n",
        "\n",
        "    return freq_indexed, token_to_idx\n",
        "\n",
        "def get_freq_indexed_and_labels(split, known_vector_size=None, token_to_idx={}):\n",
        "    df = load_data(split)\n",
        "    input_text = df[\"claim\"].to_numpy()\n",
        "    #Augment input text with the other columns\n",
        "    other_cols = {\n",
        "        \"context\",\n",
        "        \"subject\",\n",
        "        \"speaker\",\n",
        "        \"speaker_job_title\",\n",
        "        \"state_info\",\n",
        "        \"party_affiliation\",\n",
        "    }\n",
        "    for i in range(len(input_text)):\n",
        "        extra_data = [f\"{col}: {df[col].values[i]}\" for col in other_cols if df[col].values[i]]\n",
        "        input_text[i] += \" | \\n\"*(len(extra_data) > 0) + \" | \\n\".join(extra_data)\n",
        "    input_labels = df[\"label\"].to_numpy()\n",
        "    code_switch = \"\"\"\"\"\"\n",
        "    #Fuse some labels\n",
        "    input_labels = np.array([\n",
        "        \"false\" if x in (\"false\", \"half-true\", \"barely-true\", \"pants-fire\")\n",
        "        else \"true\" if x in (\"true\", \"mostly-true\")\n",
        "        else x\n",
        "        for x in input_labels\n",
        "    ])\n",
        "    #\"\"\"\n",
        "    freq_indexed, token_to_idx = tokenize_text(input_text, known_vector_size, token_to_idx)\n",
        "\n",
        "    return freq_indexed, token_to_idx, input_labels\n",
        "\n",
        "\"\"\"##Turn the data into tensors\"\"\"\n",
        "\n",
        "def as_tensors(split, label_encoder=None, known_vector_size=None, token_to_idx={}):\n",
        "    freq_indexed, token_to_idx, input_labels = get_freq_indexed_and_labels(split, known_vector_size, token_to_idx)\n",
        "    X = torch.tensor(freq_indexed, dtype=torch.long)\n",
        "    label_encoder_existed = (type(label_encoder) != type(None))\n",
        "    label_encoder = (LabelEncoder() if not label_encoder_existed else label_encoder)\n",
        "    y = (\n",
        "        label_encoder.fit_transform(input_labels) if not label_encoder_existed\n",
        "        else label_encoder.transform(input_labels)\n",
        "    )\n",
        "    y = torch.tensor(y, dtype=torch.long)\n",
        "    print(f\"{split.upper()} SPLIT:\", X.size(0), \"overall samples:\", X.shape)\n",
        "\n",
        "    return X, token_to_idx, label_encoder, input_labels, y\n",
        "\n",
        "\"\"\"##Training\"\"\"\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "X_train, token_to_idx, label_encoder, train_input_labels, y_train = as_tensors(\"train\")\n",
        "label_to_idx = {l: i for i, l in enumerate(label_encoder.classes_)}\n",
        "train_vocab_size = len(token_to_idx)\n",
        "input_vector_size = X_train.shape[1]\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "train_label_counts = pd.DataFrame({\"label\": train_input_labels})[\"label\"].value_counts(normalize=True)\n",
        "print(train_label_counts.shape[0], \"labels\\n\")\n",
        "print(train_label_counts)\n",
        "\n",
        "code_switch = \"\\\"\"\"\"\"\n",
        "#Balance if necessary\n",
        "print(f\"TRAIN SPLIT(pre-balancing):\", X_train.size(0), \"overall samples:\", X_train.shape)\n",
        "X_train, y_train = SMOTE(random_state=42).fit_resample(X_train, y_train)\n",
        "X_train = torch.tensor(X_train, dtype=torch.long)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "print()\n",
        "print(f\"TRAIN SPLIT(post-balancing):\", X_train.size(0), \"overall samples:\", X_train.shape)\n",
        "print(pd.DataFrame({\"label\": [label_encoder.classes_[y] for y in y_train]})[\"label\"].value_counts())\n",
        "#\"\"\"\n",
        "\n",
        "def train_model(model, dataloader, optimizer, criterion, device, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        epoch_tps = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(inputs)\n",
        "            loss = criterion(predictions, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item() #Track total loss\n",
        "            #Track total accuracy\n",
        "            _, predicted_classes = torch.max(predictions, 1)\n",
        "            epoch_tps += (predicted_classes == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {epoch_loss/len(dataloader):.4f} | Accuracy: {epoch_tps/total_samples:.4f}\")\n",
        "\n",
        "\"\"\"### The BiLSTM model\"\"\"\n",
        "\n",
        "#Define the model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BiLSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        super(BiLSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=token_to_idx[pad_tkn])\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, batch_first=True, dropout=dropout, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # Multiply by 2 for bidirectional\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, (hidden, cell) = self.lstm(embedded)\n",
        "        # Concatenate the final forward and backward hidden states\n",
        "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
        "        return self.fc(hidden)\n",
        "\n",
        "#Setup to train\n",
        "\n",
        "# Model and training structure\n",
        "INPUT_DIM = train_vocab_size + 1\n",
        "EMBEDDING_DIM = 1000 #Current best: 1000\n",
        "HIDDEN_DIM = 128\n",
        "OUTPUT_DIM = train_label_counts.shape[0]\n",
        "N_LAYERS = 2\n",
        "DROPOUT = 0.3 #Current best: .3\n",
        "EPOCHS = 8 #Current best: 8\n",
        "\n",
        "# Make the model\n",
        "bilstm_model = BiLSTMModel(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, DROPOUT)\n",
        "print(\"Model:\", bilstm_model)\n",
        "\n",
        "# Move model to GPU if possible\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# Check if CUDA (GPU support) is available\n",
        "if torch.cuda.is_available():\n",
        "    # Get the number of available GPUs\n",
        "    num_gpus = torch.cuda.device_count()\n",
        "    print(f\"Number of available GPUs: {num_gpus}\")\n",
        "\n",
        "    # Get the name of each GPU\n",
        "    for i in range(num_gpus):\n",
        "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "\n",
        "    # Verify if a T4 GPU is available\n",
        "    t4_available = any(\"t4\" in torch.cuda.get_device_name(i).lower() for i in range(num_gpus))\n",
        "    print(f\"Is a T4 GPU available? {t4_available}\")\n",
        "\n",
        "    # Set the device to the first available GPU (if any)\n",
        "    device = torch.device('cuda:0')\n",
        "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"No GPU available, using CPU.\")\n",
        "    device = torch.device('cpu')\n",
        "bilstm_model = bilstm_model.to(device)\n",
        "\n",
        "# Optimization & loss setup\n",
        "optimizer = torch.optim.AdamW(bilstm_model.parameters(), lr=0.001)\n",
        "code_switch1 = \"\"\"\"\"\"\n",
        "class_weights = [1 for _ in range(OUTPUT_DIM)]\n",
        "class_weights[label_to_idx['true']] = 1\n",
        "class_weights[label_to_idx['false']] = 2\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.float32).to(device))\n",
        "code_switch2 = \"\"\"\n",
        "criterion = nn.CrossEntropyLoss() #Current best: no weights\n",
        "#\"\"\"\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "#Train the model\n",
        "train_model(bilstm_model, train_loader, optimizer, criterion, device, EPOCHS)\n",
        "\n",
        "\"\"\"## Save Model Weights\"\"\"\n",
        "\n",
        "#Save the model weights\n",
        "torch.save(bilstm_model.state_dict(), \"bilstm_model_weights.pth\")\n",
        "print(\"Model weights saved to 'bilstm_model_weights.pth'\")\n",
        "\n",
        "\"\"\"## Evaluate Model\"\"\"\n",
        "\n",
        "#Evaluation functions\n",
        "import typing as tp\n",
        "\n",
        "# Get predictions\n",
        "def get_predictions(\n",
        "    test_loader, model, num_samples,\n",
        "    pred_type: tp.Literal['model', 'baseline', 'random'] = 'model',\n",
        "    device=None,\n",
        "    label_ordering=None, orig_label_counts=None,\n",
        "    num_classes=None\n",
        "):\n",
        "    predictions = []\n",
        "    y_eval = []\n",
        "\n",
        "    if pred_type == 'model':\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in test_loader:\n",
        "                y_eval.extend(batch_y)\n",
        "\n",
        "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "                batch_size = batch_X.size(0)\n",
        "\n",
        "                outputs = model(batch_X)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                predictions.extend(predicted.cpu())\n",
        "        y_eval = torch.tensor(y_eval, dtype=torch.long)\n",
        "    elif pred_type == 'baseline':\n",
        "        orig_label_counts = orig_label_counts.sort_index(key=lambda idx: orig_label_counts[idx], inplace=False, ascending=False)\n",
        "        majority_class = list(label_ordering).index(orig_label_counts.index[0])\n",
        "        predictions += [majority_class for _ in range(num_samples)]\n",
        "    else:\n",
        "        predictions += [random.randint(0, num_classes - 1) for _ in range(num_samples)]\n",
        "\n",
        "    predictions = torch.tensor(predictions, dtype=torch.long)\n",
        "    if pred_type == 'model':\n",
        "        return predictions, y_eval\n",
        "    return predictions\n",
        "\n",
        "# Calculate per-class metrics\n",
        "def per_class_metrics(labels, predictions, num_classes, label_ordering):\n",
        "    # Ensure labels and predictions are on CPU\n",
        "    labels = labels.cpu().numpy()\n",
        "    predictions = predictions.cpu().numpy()\n",
        "\n",
        "    precision_per_class = precision_score(labels, predictions, average=None, labels=np.arange(num_classes), zero_division=0)\n",
        "    recall_per_class = recall_score(labels, predictions, average=None, labels=np.arange(num_classes), zero_division=0)\n",
        "    f1_per_class = f1_score(labels, predictions, average=None, labels=np.arange(num_classes), zero_division=0)\n",
        "\n",
        "    results = []\n",
        "    for metrics in [precision_per_class, recall_per_class, f1_per_class]:\n",
        "        results.append({label_ordering[i]: metrics[i] for i in range(len(metrics))})\n",
        "    return tuple(results)\n",
        "\n",
        "# Calculate Macro metrics\n",
        "def macro_metrics(labels, predictions):\n",
        "    # Ensure labels and predictions are on CPU\n",
        "    labels = labels.cpu().numpy()\n",
        "    predictions = predictions.cpu().numpy()\n",
        "\n",
        "    precision_macro = precision_score(labels, predictions, average='macro', zero_division=0)\n",
        "    recall_macro = recall_score(labels, predictions, average='macro', zero_division=0)\n",
        "    f1_macro = f1_score(labels, predictions, average='macro', zero_division=0)\n",
        "\n",
        "    return precision_macro, recall_macro, f1_macro\n",
        "\n",
        "# Calculate Micro metrics\n",
        "def micro_metrics(labels, predictions):\n",
        "    # Ensure labels and predictions are on CPU\n",
        "    labels = labels.cpu().numpy()\n",
        "    predictions = predictions.cpu().numpy()\n",
        "\n",
        "    precision_micro = precision_score(labels, predictions, average='micro', zero_division=0)\n",
        "    recall_micro = recall_score(labels, predictions, average='micro', zero_division=0)\n",
        "    f1_micro = f1_score(labels, predictions, average='micro', zero_division=0)\n",
        "\n",
        "    return precision_micro, recall_micro, f1_micro\n",
        "\n",
        "# Get evaluations\n",
        "def evaluate(labels, num_classes, model_pred, baseline_pred, random_pred, label_ordering):\n",
        "    results = {}\n",
        "\n",
        "    for pred_type, predictions in [('Model', model_pred), ('Baseline', baseline_pred), ('Random', random_pred)]:\n",
        "        curr_results = results[pred_type] = {}\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = (predictions == labels).sum().item() / labels.size(0)\n",
        "        precision_per_class, recall_per_class, f1_per_class = per_class_metrics(labels, predictions, num_classes, label_ordering)\n",
        "        precision_macro, recall_macro, f1_macro = macro_metrics(labels, predictions)\n",
        "        precision_micro, recall_micro, f1_micro = micro_metrics(labels, predictions)\n",
        "\n",
        "        # Save all metrics\n",
        "        curr_results[\"Accuracy\"] = accuracy\n",
        "        curr_results[\"Per-Class Precision\"] = precision_per_class\n",
        "        curr_results[\"Per-Class Recall\"] = recall_per_class\n",
        "        curr_results[\"Per-Class F1\"] = f1_per_class\n",
        "\n",
        "        curr_results[\"Macro Precision\"] = precision_macro\n",
        "        curr_results[\"Macro Recall\"] = recall_macro\n",
        "        curr_results[\"Macro F1\"] = f1_macro\n",
        "\n",
        "        curr_results[\"Micro Precision\"] = precision_micro\n",
        "        curr_results[\"Micro Recall\"] = recall_micro\n",
        "        curr_results[\"Micro F1\"] = f1_micro\n",
        "\n",
        "    return results\n",
        "\n",
        "def evaluate_data(model, loader, num_classes, num_instances, label_ordering, orig_label_counts, device):\n",
        "    # Get model, baseline, and random predictions\n",
        "    # Use model predictions to get the labels since the\n",
        "    # loader might shuffle its values and might not be in the same order as y upon iteration\n",
        "    model_pred, labels = get_predictions(loader, model, num_instances, pred_type='model', device=device)\n",
        "    # Get other prediction types as normal\n",
        "    baseline_pred = get_predictions(\n",
        "        loader, model, num_instances, pred_type='baseline',\n",
        "        label_ordering=label_ordering, orig_label_counts=orig_label_counts\n",
        "    )\n",
        "    random_pred = get_predictions(loader, model, num_instances, pred_type='random', num_classes=num_classes)\n",
        "\n",
        "    print()\n",
        "\n",
        "    # Move tensors to CPU before passing to sklearn functions\n",
        "    labels = labels.cpu()\n",
        "    model_pred = model_pred.cpu()\n",
        "    baseline_pred = baseline_pred.cpu()\n",
        "    random_pred = random_pred.cpu()\n",
        "\n",
        "    # Print evaluation results\n",
        "    pprint.pprint(evaluate(labels, num_classes, model_pred, baseline_pred, random_pred, label_ordering))\n",
        "\n",
        "    # Generate confusion matrix and move to CPU\n",
        "    conf_matrix = confusion_matrix(labels.cpu(), model_pred.cpu())\n",
        "    class_labels = label_ordering\n",
        "\n",
        "    # Plot the confusion matrix as a heatmap\n",
        "    def plot_confusion_matrix(conf_matrix, class_labels):\n",
        "        sns.heatmap(\n",
        "            conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
        "            xticklabels=class_labels, yticklabels=class_labels\n",
        "        )\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.xlabel('Predicted Labels')\n",
        "        plt.ylabel('True Labels')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    print(\"\\n\")\n",
        "    plot_confusion_matrix(conf_matrix, class_labels)\n",
        "\n",
        "\"\"\"###Val Set Results\"\"\"\n",
        "\n",
        "X_val, _, _, _, y_val = as_tensors(\"valid\", label_encoder, input_vector_size, token_to_idx)\n",
        "val_dataset = TensorDataset(X_val, y_val)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "evaluate_data(bilstm_model, val_loader, OUTPUT_DIM, y_val.size(0), label_encoder.classes_, train_label_counts, device)\n",
        "\n",
        "\"\"\"###Test Set Results\"\"\"\n",
        "\n",
        "X_test, _, _, _, y_test = as_tensors(\"test\", label_encoder, input_vector_size, token_to_idx)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "evaluate_data(bilstm_model, test_loader, OUTPUT_DIM, y_test.size(0), label_encoder.classes_, train_label_counts, device)"
      ],
      "metadata": {
        "id": "DbCG0mD33hdq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}