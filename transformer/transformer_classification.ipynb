{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if PyTorch recognizes GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import os\n",
    "\n",
    "columns = [\n",
    "    'id', 'label', 'claim', 'subject', 'speaker', 'speaker_job_title', 'state_info',\n",
    "    'party_affiliation', 'barely_true_counts', 'false_counts',\n",
    "    'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context'\n",
    "]\n",
    "\n",
    "# read in original LIAR dataset\n",
    "df_train = pd.read_csv('../data/LIAR/train.tsv', sep='\\t', names=columns).dropna()\n",
    "df_valid = pd.read_csv('../data/LIAR/valid.tsv', sep='\\t', names=columns).dropna()\n",
    "df_test = pd.read_csv('../data/LIAR/test.tsv', sep='\\t', names=columns).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_liar(samples, labels, tokenizer):\n",
    "  tokenized = []\n",
    "  for idx in range(len(samples)):\n",
    "    tokenized_claim = tokenizer(samples[idx], return_tensors='pt')\n",
    "    \n",
    "    n_inst = {\n",
    "      'claim_token': tokenized_claim,\n",
    "      'claim_origin': samples[idx],\n",
    "      'label': labels[idx], \n",
    "      'idx': idx\n",
    "    }\n",
    "    tokenized.append(n_inst)\n",
    "\n",
    "  return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'claim_origin': 'Says the Annies List political group supports '\n",
      "                 'third-trimester abortions on demand.',\n",
      " 'claim_token': {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
      "                 'input_ids': tensor([[  101,  8652,  1116,  1103,  7765,  1116,  5619,  1741,  1372,  6253,\n",
      "          1503,   118, 13373, 12831, 12030,  1116,  1113,  4555,   119,   102]]),\n",
      "                 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])},\n",
      " 'idx': 0,\n",
      " 'label': 'false'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "#LIAR Code:\n",
    "# obtain training samples/label pairs from dataset\n",
    "liar_train_samples = np.array(df_train['claim'])\n",
    "liar_train_labels = np.array(df_train['label'])\n",
    "liar_test_samples = np.array(df_test['claim'])\n",
    "liar_test_labels = np.array(df_test['label'])\n",
    "\n",
    "tokenized_train_dataset = tokenize_liar(liar_train_samples, liar_train_labels, tokenizer)\n",
    "tokenized_test_dataset = tokenize_liar(liar_test_samples, liar_test_labels, tokenizer)\n",
    "pprint.pprint(tokenized_train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define PyTorch Datasets (Augmented using SMOTE & Unaugmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "class LiarDataset(Dataset):\n",
    "    def __init__(self, liar_data):\n",
    "        self.labels = []\n",
    "        self.data = []\n",
    "    \n",
    "        self.label_map = {\n",
    "            'pants-fire': 0,\n",
    "            'false': 0,\n",
    "            'barely-true': 0,\n",
    "            'half-true': 0,\n",
    "            'mostly-true': 1,\n",
    "            'true': 1\n",
    "        }\n",
    "\n",
    "        for idx in range(len(liar_data)):\n",
    "            self.data.append(liar_data[idx]['claim_token'])\n",
    "            self.labels.append(self.label_map[liar_data[idx]['label']])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        claim = {key: torch.tensor(value, dtype=torch.long) for key, value in self.data[idx].items()}\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return claim, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment Dataset into training and test portions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train = [inst['claim_token'] for inst in tokenized_train_dataset]\n",
    "y_train = [inst['label'] for inst in tokenized_train_dataset]\n",
    "X_test = [inst['claim_token'] for inst in tokenized_test_dataset]\n",
    "y_test = [inst['label'] for inst in tokenized_test_dataset]\n",
    "\n",
    "# reconstruct dictionaries using training/test sets\n",
    "train_set = []\n",
    "for claim_token, label in zip(X_train, y_train):\n",
    "    train_inst = {\n",
    "        'claim_token': claim_token,  \n",
    "        'label': label\n",
    "    }\n",
    "    train_set.append(train_inst)\n",
    "\n",
    "test_set = []\n",
    "for claim_token, label in zip(X_test, y_test):\n",
    "    test_inst = {\n",
    "        'claim_token': claim_token,\n",
    "        'label': label\n",
    "    }\n",
    "    test_set.append(test_inst)\n",
    "\n",
    "train_dataset = LiarDataset(train_set)\n",
    "test_dataset = LiarDataset(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model, dataloaders, loss function, collate function, and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to create collate function to pad variable length sequences for input\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # as per cell 6 output, item[0] will look like this:\n",
    "    # 'tweet_token': {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]]),\n",
    "    #                   'input_ids': tensor([[  101, 21887, 23350,  2003, 19345, 13685,  1012,   102]]),\n",
    "    #                   'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]])}}\n",
    "    # item[1] will be a numeric label according to MisinformationDataset's label_map\n",
    "    input_ids = [item[0]['input_ids'].squeeze(0) for item in batch]\n",
    "    attention_masks = [item[0]['attention_mask'].squeeze(0) for item in batch]\n",
    "    labels = [item[1] for item in batch]\n",
    "\n",
    "    # pad sequences for input_ids and attention_masks with 0 values\n",
    "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
    "    attention_masks = pad_sequence(attention_masks, batch_first=True, padding_value=0)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_masks,\n",
    "    }, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: \n",
      "False: 1.5983353151010702\n",
      "True: 2.6713036565977744\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from collections import Counter\n",
    "\n",
    "# change num_labels in accordance with current problem design (binary or multi-class classification)\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "model = model.to(device)\n",
    "\n",
    "# freeze base model layers\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# unfreeze last two layers of base model for fine tuning\n",
    "#for param in model.base_model.encoder.layer[-2:]:\n",
    "#    param.requires_grad = True\n",
    "\n",
    "# attempt to use class weights to offset imbalance of dataset\n",
    "label_counts = Counter(liar_train_labels)\n",
    "label_map = {\n",
    "            'pants-fire': 0,\n",
    "            'false': 0,\n",
    "            'barely-true': 0,\n",
    "            'half-true': 0,\n",
    "            'mostly-true': 1,\n",
    "            'true': 1\n",
    "        }\n",
    "numeric_labels = np.array([label_map[inst['label']] for inst in tokenized_train_dataset])\n",
    "true_count = np.count_nonzero(numeric_labels == 1)\n",
    "false_count = np.count_nonzero(numeric_labels == 0)\n",
    "total_count = len(train_dataset)\n",
    "true_weight = total_count / true_count\n",
    "false_weight = total_count / false_count\n",
    "print(f'Weights: \\nFalse: {false_weight}\\nTrue: {true_weight}')\n",
    "\n",
    "class_weights = torch.tensor([false_weight, true_weight]).to(device)\n",
    "\n",
    "loss_fn = CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "#dev_dataloader = DataLoader(dev_set, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_covid(model, optim, loss_fn, dataloader, epochs):\n",
    "#def train_covid(model, optim, dataloader, epochs):\n",
    "  for epoch in range(epochs):\n",
    "      model.train()\n",
    "      total_loss = 0\n",
    "\n",
    "      for batch_idx, batch in enumerate(dataloader):\n",
    "          optim.zero_grad()\n",
    "          \n",
    "          # unpack batch of form (tweets, labels)\n",
    "          claims, labels = batch\n",
    "          # send tweets dict's values to device\n",
    "          claims = {key: value.to(device) for key, value in claims.items()}\n",
    "          labels = labels.to(device)\n",
    "          \n",
    "          # forward pass on BERT\n",
    "          outputs = model(**claims, labels=labels)\n",
    "          logits = outputs.logits\n",
    "          \n",
    "          # class weighted CrossEntropyLoss\n",
    "          loss = loss_fn(logits, labels)\n",
    "          \n",
    "          # loss provided by model\n",
    "          #loss = outputs.loss \n",
    "\n",
    "          # backwards pass on BERT\n",
    "          loss.backward()\n",
    "          optim.step()\n",
    "\n",
    "          total_loss += loss.item()\n",
    "\n",
    "          print(f\"Epoch {epoch + 1}, Batch {batch_idx + 1}/{len(dataloader)}, Loss: {loss.item()}\")\n",
    "\n",
    "      print(f\"Epoch {epoch + 1}, Loss: {total_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(model.config.num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model for sequence classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 9\n",
    "train_covid(model, optimizer, loss_fn, train_dataloader, epochs)\n",
    "#train_covid(model, optimizer, train_dataloader, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asubedi\\AppData\\Local\\Temp\\ipykernel_280080\\751014086.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  claim = {key: torch.tensor(value, dtype=torch.long) for key, value in self.data[idx].items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 48.30%\n",
      "Per Class Accuracy: {0: 32.95668549905838, 1: 73.6024844720497}\n",
      "Precision: [67.30769231 39.96627319]\n",
      "Recall: [32.9566855  73.60248447]\n",
      "F1: [0.44247788 0.51803279]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            tweets, labels = batch\n",
    "            tweets = {key: value.to(device) for key, value in tweets.items()}\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # run sequences through BERT\n",
    "            outputs = model(**tweets, labels=labels)\n",
    "            \n",
    "            # highest energy class is our prediction\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, 1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    class_labels = [0, 1]\n",
    "    #class_labels = [0, 1, 2, 3, 4, 5]\n",
    "    per_class_accuracy = {}\n",
    "    for class_label in class_labels:\n",
    "        # get indices which match current class_label\n",
    "        class_indices = np.where(np.array(all_labels) == class_label)[0]\n",
    "        \n",
    "        # get predictions of current class label\n",
    "        class_preds = np.array(all_preds)[class_indices]\n",
    "        \n",
    "        # calculate accuracy for current class_label\n",
    "        correct_class_preds = np.sum(class_preds == class_label)\n",
    "        total_class_samples = len(class_indices)\n",
    "        \n",
    "        per_class_accuracy[class_label] = (correct_class_preds / total_class_samples) * 100\n",
    "        \n",
    "    accuracy = 100*accuracy_score(all_labels, all_preds)\n",
    "    precision = 100*precision_score(all_labels, all_preds, labels=class_labels, average=None, zero_division=0)\n",
    "    recall = 100*recall_score(all_labels, all_preds, labels=class_labels, average=None, zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, labels=class_labels, average=None, zero_division=0)\n",
    "\n",
    "    return accuracy, precision, recall, f1, per_class_accuracy\n",
    "\n",
    "\n",
    "# evaluate the model on the test set (unaugmented)\n",
    "accuracy, precision, recall, f1, per_class_accuracy = evaluate_model(model, test_dataloader)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Per Class Accuracy: {per_class_accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'./models/model_weights15-{accuracy:.1f}.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmsc673",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
